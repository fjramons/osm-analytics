{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of OSM installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets a bigger default size for figures\n",
    "plt.rcParams['figure.figsize'] = [14, 8]\n",
    "plt.rcParams['figure.dpi'] = 80 # 100 gives great resolution and 200 gives optimal resolution, but much slower\n",
    "sns.set(rc={'figure.figsize':(12,8)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pio.renderers.default = \"notebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install_events_uri = 'https://osm.etsi.org/stats/install-log.csv'\n",
    "\n",
    "date_first_valid_sample = '2021-11-29'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_export_to_html = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_folder = 'inputs'\n",
    "outputs_folder = 'outputs'\n",
    "outputs_path = Path(outputs_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_releases = [\n",
    "    # '11.0.0rc1',\n",
    "    'ReleaseTWELVE',\n",
    "    'Release TWELVE',\n",
    "    'ReleaseTWELVE-daily',\n",
    "    'Release TWELVE-daily',\n",
    "    'ReleaseELEVEN',\n",
    "    'Release ELEVEN',\n",
    "    'ReleaseELEVEN-daily',\n",
    "    'Release ELEVEN-daily',\n",
    "    'release',\n",
    "    'testing-daily'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_types_of_install_events = [\n",
    "    'start',\n",
    "    'checks',\n",
    "    'prereq',\n",
    "    'docker_ce',\n",
    "    'k8scluster',\n",
    "    'juju',\n",
    "    'docker_images',\n",
    "    'osm_files',\n",
    "    'deploy_osm',\n",
    "    'osmclient',\n",
    "    'healthchecks',\n",
    "    'final_ops',\n",
    "    'end',\n",
    "\n",
    "    # To be sorted\n",
    "    'bootstrap_k8s',\n",
    "    'bootstrap_lxd',\n",
    "    'install_microstack_ok'\n",
    "]\n",
    "\n",
    "events_to_discard = ['hola', 'hola2', 'my-event', 'my-second-event', 'test-event']\n",
    "\n",
    "events_renaming = {\n",
    "    'add_local_k8scluster': 'final_ops',\n",
    "    'after_healthcheck': 'healthchecks',\n",
    "    'checkingroot': 'checks',\n",
    "    'deploy_osm_pla': 'deploy_osm',\n",
    "    'deploy_osm_services_k8s': 'deploy_osm',\n",
    "    'docker_build': 'docker_images',\n",
    "    'env_files': 'osm_files',\n",
    "    'init_k8s': 'k8scluster',\n",
    "    'install_helm': 'k8scluster',\n",
    "    'install_k8s': 'k8scluster',\n",
    "    'juju_controller': 'juju',\n",
    "    'juju_install': 'juju',\n",
    "    'k8s_metallb': 'k8scluster',\n",
    "    'k8s_ready': 'k8scluster',\n",
    "    'k8s_storageclass': 'k8scluster',\n",
    "    'manifest_files': 'osm_files',\n",
    "    'noroot': 'checks',\n",
    "    'osm_unhealthy': 'healthchecks',\n",
    "    'prereqok': 'prereq',\n",
    "    'proceed': 'checks'\n",
    "}\n",
    "\n",
    "sorted_types_of_install_operations = [\n",
    "    'start_ok',\n",
    "    'release',\n",
    "    'docker_tag',\n",
    "    'installation_type',\n",
    "    'checkingroot_ok',\n",
    "    'noroot_ok',\n",
    "    'proceed_ok',\n",
    "    'prereqok_ok',\n",
    "    'docker_ce_ok',\n",
    "    'install_k8s_ok',\n",
    "    'init_k8s_ok',\n",
    "    'install_helm_ok',\n",
    "    'k8s_storageclass_ok',\n",
    "    'k8s_metallb_ok',\n",
    "    'k8s_ready_ok',\n",
    "    'k8scluster_ok',\n",
    "    'juju_install_ok',\n",
    "    'juju_controller_ok',\n",
    "    'juju_ok',\n",
    "    'docker_images_ok',\n",
    "    'manifest_files_ok',\n",
    "    'env_files_ok',\n",
    "    'deploy_charmed_services_ok',\n",
    "    'kube_secrets_ok',\n",
    "    'update_manifest_files_ok',\n",
    "    'namespace_vol_ok',\n",
    "    'deploy_osm_pla_ok',\n",
    "    'deploy_osm_services_k8s_ok',\n",
    "    'osmclient_ok',\n",
    "    'osm_unhealthy',\n",
    "    'after_healthcheck_ok',\n",
    "    'add_local_k8scluster_ok',\n",
    "    'end',\n",
    "    'fatal',\n",
    "\n",
    "    # To be sorted\n",
    "    'apt_proxy_configured_ok',\n",
    "    'install_k8s_monitoring_ok',\n",
    "\n",
    "    'bootstrap_k8s_ok',\n",
    "    'bootstrap_lxd_ok',\n",
    "    'install_microstack_ok'\n",
    "]\n",
    "\n",
    "operations_to_discard = ['start', 'my-op', 'op1', 'op2', 'fatal_my-event', 'test-event', 'fatal_test-event']\n",
    "\n",
    "operations_renaming = {\n",
    "    'apt_proxy_configured': 'apt_proxy_configured_ok',\n",
    "    'checkingroot': 'checkingroot_ok',\n",
    "    'noroot': 'noroot_ok',\n",
    "    'proceed': 'proceed_ok',\n",
    "    'prereqok': 'prereqok_ok',\n",
    "    'docker_ce': 'docker_ce_ok',\n",
    "    'install_k8s': 'install_k8s_ok',\n",
    "    'init_k8s': 'init_k8s_ok',\n",
    "    'install_helm': 'install_helm_ok',\n",
    "    'k8s_storageclass': 'k8s_storageclass_ok',\n",
    "    'k8s_metallb': 'k8s_metallb_ok',\n",
    "    'k8scluster': 'k8scluster_ok',\n",
    "    'juju_controller': 'juju_controller_ok',\n",
    "    'juju': 'juju_ok',\n",
    "    'docker_build': 'docker_images_ok',\n",
    "    'docker_build_ok': 'docker_images_ok',\n",
    "    'manifest_files': 'manifest_files_ok',\n",
    "    'env_files': 'env_files_ok',\n",
    "    'deploy_osm_pla': 'deploy_osm_pla_ok',\n",
    "    'deploy_osm_services_k8s': 'deploy_osm_services_k8s_ok',\n",
    "    'osmclient': 'osmclient_ok',\n",
    "    'after_healthcheck': 'after_healthcheck_ok',\n",
    "    'add_local_k8scluster': 'add_local_k8scluster_ok'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_as_datetime = pd.to_datetime(\"today\")\n",
    "today = today_as_datetime.strftime('%Y-%m-%d')\n",
    "\n",
    "display(Markdown(f'**Date and time of the report:** {today_as_datetime}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and processing installation events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['timestamp', 'location', 'queries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_keyvalues_to_series(df_with_keys):\n",
    "    cols = df_with_keys.columns\n",
    "    df_with_series = df_with_keys.copy()\n",
    "\n",
    "    for col in cols:\n",
    "        # Breaks down each column into 2 columns: keys and values\n",
    "        df = df_with_keys[col].str.split('=', expand=True)\n",
    "\n",
    "        # If there are values, adds them; else, the column should be empty\n",
    "        df_with_series[col] = df[1] if (df.shape[1] == 2) else pd.NA\n",
    "\n",
    "        # New name for the column, from the key name\n",
    "        df_with_series.rename(columns={col: df.iloc[0, 0]}, inplace=True)\n",
    "\n",
    "    return df_with_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_undesired_categories(df, col_name, undesired_categories):\n",
    "    mask = ~ df.loc[:, col_name].isin(undesired_categories)\n",
    "    return df.loc[mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_categories(input_serie, known_categories):\n",
    "    unknown = input_serie[~ input_serie.isin(known_categories)].unique().tolist()\n",
    "    return [known_categories + unknown, unknown]\n",
    "\n",
    "def make_sorted_categorical(sr, known_categories):\n",
    "    extended_categories, unknown_categories = fix_categories(sr, known_categories)\n",
    "    # display(pd.Series(extended_categories).value_counts())\n",
    "    new_category = CategoricalDtype(categories=extended_categories, ordered=True)\n",
    "    if unknown_categories:\n",
    "        print(f\"Unknown categories: {unknown_categories}\")\n",
    "    return sr.astype(new_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_install_events_and_operations():\n",
    "    # df_raw_install_events = pd.read_csv(install_events_uri, sep=';', header=0, names=column_names, skiprows=120)\n",
    "    # df_raw_install_events = pd.read_csv(install_events_uri, sep=';', header=0, names=column_names, skiprows=15139)\n",
    "    df_raw_install_events = pd.read_csv(install_events_uri, sep=';', header=0, names=column_names, skiprows=120, error_bad_lines=False)\n",
    "\n",
    "    return (\n",
    "        df_raw_install_events\n",
    "        .drop(columns='queries')\n",
    "        .join(\n",
    "            (\n",
    "                df_raw_install_events\n",
    "                ['queries']\n",
    "                .str.split('&', expand=True)\n",
    "                .drop(columns=0)    # 1st column should be empty due to `&`\n",
    "                .pipe(convert_keyvalues_to_series)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Empty strings should be NA\n",
    "        .replace(\"\", pd.NA)\n",
    "\n",
    "        # Removes malformed lines ('installation_id' will be missing, among others)\n",
    "        .dropna(subset=['installation_id'])\n",
    "\n",
    "        # Removes lines with undesired 'event' or 'operation' categories\n",
    "        .pipe(drop_undesired_categories, 'event', events_to_discard)\n",
    "        .pipe(drop_undesired_categories, 'operation', operations_to_discard)\n",
    "\n",
    "        # Replaces values of old 'event' or 'operation' categories by their new names\n",
    "        .assign(event = lambda x: x.event.replace(events_renaming))\n",
    "        .assign(operation = lambda x: x.operation.replace(operations_renaming))\n",
    "\n",
    "        # If within the same installation attempt we have a duplicate 'operation', only last sample is kept\n",
    "        .drop_duplicates(subset=['installation_id', 'operation'], keep='last')\n",
    "\n",
    "        # Drops lines with NA in `event` or `operation`\n",
    "        .dropna(subset=['event', 'operation'])\n",
    "\n",
    "        # Fixes data types\n",
    "        # .assign(timestamp = lambda x: pd.to_datetime(x.timestamp))\n",
    "        .assign(timestamp = lambda x: pd.to_datetime(x.timestamp, errors='coerce'))\n",
    "        .dropna(subset=['timestamp'])\n",
    "        .assign(location = lambda x: x.location.astype('category'))\n",
    "        .assign(event = lambda x: make_sorted_categorical(x.event, sorted_types_of_install_events))\n",
    "        .assign(operation = lambda x: make_sorted_categorical(x.operation, sorted_types_of_install_operations))\n",
    "\n",
    "        # .assign(local_ts = lambda x: pd.to_datetime(x.local_ts))\n",
    "        #.assign(local_ts = lambda x: dt.datetime.fromtimestamp(int(x.local_ts)/10**9, dt.timezone.utc))\n",
    "        # .assign(event = lambda x: x.event.astype('category'))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_install_events_and_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_install_events_and_operations = (\n",
    "    load_install_events_and_operations()\n",
    "    .query(\"timestamp >= @date_first_valid_sample\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment For CSV debugging\n",
    "#\n",
    "# !wget -N {install_events_uri}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment To force removal of unknown categories if needed\n",
    "#\n",
    "# mask = df_install_events.event.isin(sorted_types_of_install_events) & df_install_events.operation.isin(sorted_types_of_install_operations)\n",
    "# df_install_events = df_install_events.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_install_events_and_operations.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_install_events_and_operations.location.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_install_events_and_operations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "## 2. Preprocessing\n",
    "##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organization in wide format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_achieved_operations(df):\n",
    "    return (\n",
    "        pd.concat(\n",
    "            [\n",
    "                # All operations that explicitly show progress in the installation\n",
    "                (\n",
    "                    df\n",
    "                    .assign(value = lambda x: x.value.fillna(True))\n",
    "                    .query(\"value == True\")\n",
    "                    .rename(columns={'operation': 'achievement'})\n",
    "                    .drop(columns='value')\n",
    "                ),\n",
    "\n",
    "                # Adds extra rows to flag the beginning of the installation\n",
    "                (\n",
    "                    df\n",
    "                    .query(\"(event == 'start') & (operation == 'release')\")\n",
    "                    .assign(operation = 'start_ok')\n",
    "                    .rename(columns={'operation': 'achievement'})\n",
    "                    .drop(columns='value')\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        .sort_index()\n",
    "        .assign(achievement = lambda x: make_sorted_categorical(x.achievement, sorted_types_of_install_operations).cat.remove_unused_categories())\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_achieved_operations = get_achieved_operations(df_install_events_and_operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_achieved_operations.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_achieved_operations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_axis_to_str(df):\n",
    "    df.columns = df.columns.astype(str)\n",
    "    return df\n",
    "\n",
    "def remove_column_axis_name(df):\n",
    "    df.columns.name = None\n",
    "    return df\n",
    "\n",
    "def get_info_operations_wide(df):\n",
    "    return (\n",
    "        df\n",
    "        .loc[:, ['installation_id', 'operation', 'value']]\n",
    "        .assign(value = lambda x: x.value.fillna(True))\n",
    "        .query(\"value != True\")\n",
    "        .pivot(\n",
    "            index = 'installation_id',\n",
    "            columns = 'operation',\n",
    "            values = 'value'\n",
    "        )\n",
    "        .pipe(cast_axis_to_str)\n",
    "        .pipe(remove_column_axis_name)\n",
    "        .reset_index()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info_operations_wide = get_info_operations_wide(df_install_events_and_operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_info_operations_wide.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_info_operations_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_install_events_and_operations.query(\"operation == 'fatal'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_info_operations_wide[~ df_info_operations_wide.fatal.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_installations_wide = (\n",
    "    df_achieved_operations\n",
    "    .merge(\n",
    "        df_info_operations_wide,\n",
    "        how = 'left',\n",
    "        on = 'installation_id'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to dump the dataframe as Excel file\n",
    "#\n",
    "# df_installations_wide.to_excel('df_installations_wide.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_installations_wide.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_installations_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_installations_wide.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Number of installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to check if external vs. internal installations are distinguished\n",
    "#\n",
    "# df_installations_wide.location.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Number of installations per release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(\n",
    "    # data = df_installations_wide.drop_duplicates(subset='installation_id'),\n",
    "    data = df_installations_wide.drop_duplicates(subset='installation_id').loc[:, 'release'].to_frame(),\n",
    "    x = 'release',\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.title('Number of installations per release')\n",
    "plt.ylabel(None)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Companion table with number of installations per release\n",
    "(\n",
    "    df_installations_wide\n",
    "    .drop_duplicates(subset='installation_id')\n",
    "    .release\n",
    "    .value_counts()\n",
    "    .to_frame()\n",
    "    .reset_index()\n",
    "    .rename(columns={'release': 'INSTALLATIONS', 'index': 'RELEASE'})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Temporal evolution of installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_installations_per_week = (\n",
    "    df_installations_wide\n",
    "    .drop_duplicates(subset='installation_id')\n",
    "    # .resample('W-MON', on='timestamp')\n",
    "    .groupby(\n",
    "        [pd.Grouper(key='timestamp', freq='W-MON'), 'release']\n",
    "    )\n",
    "    .installation_id\n",
    "    .count()\n",
    "    .reset_index()\n",
    "    .rename({'installation_id': 'weekly_installations'}, axis=1)\n",
    "    .assign(total_installations = lambda x: x.groupby('release').weekly_installations.cumsum())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(\n",
    "    data = df_installations_per_week,\n",
    "    x = 'timestamp',\n",
    "    y = 'total_installations',\n",
    "    hue = 'release',\n",
    ")\n",
    "\n",
    "plt.title('Total installations per release')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pointplot(\n",
    "    data = (\n",
    "        df_installations_per_week\n",
    "        .assign(timestamp = lambda x: x.timestamp.astype(str))\n",
    "    ),\n",
    "    x = 'timestamp',\n",
    "    y = 'weekly_installations',\n",
    "    hue = 'release',\n",
    "    scale = 0.5,\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.title('Weekly installations per release')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Companion table of installations\n",
    "df_installations_per_week.groupby('release').last().sort_values('total_installations', ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Progress during installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Overview of successful installation steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ax = sns.catplot(\n",
    "    # data = df_installations_wide,\n",
    "    data = df_installations_wide.loc[:, ['release', 'achievement']],\n",
    "    y = 'achievement',\n",
    "    col = 'release',\n",
    "    col_wrap = 4,\n",
    "    kind = 'count',\n",
    "    sharex = False\n",
    ")\n",
    "\n",
    "ax.fig.suptitle('Installation steps achieved per release\\n\\n', fontsize = 22)\n",
    "ax.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Apply at the beginning of the notebook and adapt next processing steps accordingly\n",
    "name_mappings = {\n",
    "    'ReleaseTWELVE': 'Release TWELVE',\n",
    "    'ReleaseTWELVE-daily': 'Release TWELVE-daily',\n",
    "    'ReleaseELEVEN': 'Release ELEVEN',\n",
    "    'ReleaseELEVEN-daily': 'Release ELEVEN-daily'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pct(df):\n",
    "    return (\n",
    "        df\n",
    "        .assign(percentage =\n",
    "            (\n",
    "                df\n",
    "                .groupby(['release'])['count']\n",
    "\n",
    "                # TODO: Remove if mapping is applied at the beginning of the notebook\n",
    "                .transform(lambda x: x / x.max())\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_installations_wide.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Installation funnels per release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_funnels_per_release(df_installations_wide):\n",
    "    return (\n",
    "        df_installations_wide\n",
    "        .groupby(['achievement', 'release'])\n",
    "        .installation_id\n",
    "        .count()\n",
    "        .reset_index()\n",
    "        .rename(columns={'installation_id': 'count'})\n",
    "        .replace({'release': name_mappings})\n",
    "        .pipe(add_pct)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_funnels_per_release = get_funnels_per_release(df_installations_wide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_funnels_per_release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_funnel(df_funnel, x='count', title=None, filename=None):\n",
    "    fig = px.funnel(\n",
    "        df_funnel.query(\"achievement != 'osm_unhealthy'\"),\n",
    "        x = x,\n",
    "        y = 'achievement',\n",
    "        title = title\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        width = 800,\n",
    "        height = 1200,\n",
    "        title_font_size = 24,\n",
    "        title_font_family = \"Arial\",\n",
    "        # paper_bgcolor=\"LightSteelBlue\",\n",
    "    )\n",
    "\n",
    "    fig.update_traces(\n",
    "        textinfo=\"value+percent initial\",\n",
    "        textposition = \"inside\"\n",
    "    )\n",
    "\n",
    "    if filename:\n",
    "        # TODO:\n",
    "        # fig.write_image(\"images/fig1.png\")\n",
    "        pass\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(pio.templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONS:\n",
    "# - 'ggplot2'\n",
    "# - 'seaborn'\n",
    "# - 'simple_white'\n",
    "# - 'plotly'\n",
    "# - 'plotly_white'\n",
    "# - 'plotly_dark'\n",
    "# - 'presentation'\n",
    "# - 'xgridoff'\n",
    "# - 'ygridoff'\n",
    "# - 'gridon'\n",
    "# - 'none'\n",
    "\n",
    "pio.templates.default = \"seaborn\"\n",
    "# pio.templates.default = \"plotly_white\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_funnels_per_release.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funnels_per_release = df_funnels_per_release.groupby('release')\n",
    "\n",
    "# releases_to_plot = [release for release in df_funnels_per_release.release.unique() if release in relevant_releases]\n",
    "releases_to_plot = [release for release in relevant_releases if release in df_funnels_per_release.release.unique()]\n",
    "\n",
    "for release in releases_to_plot:\n",
    "    df_funnel = funnels_per_release.get_group(release)\n",
    "    display(\n",
    "        _ = plot_funnel(\n",
    "            df_funnel,\n",
    "            x = 'count',\n",
    "            title = f'Funnel of {release} installations'\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Companion table of funnels\n",
    "(\n",
    "    df_funnels_per_release\n",
    "    .query(\"achievement == 'end' or achievement == 'start_ok'\")\n",
    "    .drop(columns='percentage')\n",
    "    .pivot(\n",
    "        index = 'release',\n",
    "        values = 'count',\n",
    "        columns = 'achievement'\n",
    "    )\n",
    "    .pipe(cast_axis_to_str)\n",
    "    .reset_index()\n",
    "    .pipe(remove_column_axis_name)\n",
    "    .rename(columns = {'release': 'RELEASE', 'start_ok': 'TOTAL_INSTALLS', 'end': 'SUCCESSFUL_INSTALLS'})\n",
    "    .assign(SUCCESS_RATIO = lambda x: x.SUCCESSFUL_INSTALLS / x.TOTAL_INSTALLS)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analysis of failed installation attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fatal_errors = (\n",
    "    df_installations_wide\n",
    "    .query(\"event == 'start'\")\n",
    "    [['location', 'release', 'installation_type', 'fatal', 'installation_id']]\n",
    "    .groupby(['location', 'release', 'installation_type', 'fatal'], dropna=False)\n",
    "    .count()\n",
    "    .reset_index()\n",
    "    .rename(columns = {'installation_id': 'count'})\n",
    "    .assign(installation_type = lambda x: x.installation_type.fillna('Other'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fatal_errors.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.catplot(\n",
    "    # data = df_fatal_errors,\n",
    "    data = df_fatal_errors[df_fatal_errors.release.isin(relevant_releases)],\n",
    "    y = 'count',\n",
    "    x = 'fatal',\n",
    "    hue = 'installation_type',\n",
    "    col = 'release',\n",
    "    col_wrap = 2,\n",
    "    kind = 'bar',\n",
    "    sharex = False\n",
    ")\n",
    "\n",
    "ax.fig.suptitle('Root causes of fatal installation errors, per release\\n\\n', fontsize = 22)\n",
    "ax.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Companion table\n",
    "df_fatal_errors.pivot_table(\n",
    "    index = ['location', 'release'],\n",
    "    columns = ['installation_type', 'fatal'],\n",
    "    values = 'count'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unhealthy_installs = (\n",
    "    df_installations_wide\n",
    "    .query(\"event == 'start'\")\n",
    "    [['location', 'release', 'installation_type', 'osm_unhealthy', 'installation_id']]\n",
    "    .groupby(['location', 'release', 'installation_type', 'osm_unhealthy'], dropna=False)\n",
    "    .count()\n",
    "    .reset_index()\n",
    "    .rename(columns = {'installation_id': 'count'})\n",
    "    .assign(installation_type = lambda x: x.installation_type.fillna('Other'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_unhealthy_installs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.catplot(\n",
    "    data = df_unhealthy_installs[df_unhealthy_installs.release.isin(relevant_releases)],\n",
    "    y = 'count',\n",
    "    x = 'osm_unhealthy',\n",
    "    hue = 'installation_type',\n",
    "    col = 'release',\n",
    "    col_wrap = 2,\n",
    "    kind = 'bar',\n",
    "    sharex = False,\n",
    ")\n",
    "\n",
    "ax.fig.suptitle('Causes of unhealthy installations per release\\n\\n', fontsize = 22)\n",
    "\n",
    "ax.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Companion table of unhealthy installations\n",
    "df_unhealthy_installs.pivot_table(\n",
    "    index = ['location', 'release'],\n",
    "    columns = ['installation_type', 'osm_unhealthy'],\n",
    "    values = 'count'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving the notebook as webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_export_to_html:\n",
    "    !jupyter nbconvert --to html --output outputs/installation_analysis.html --TemplateExporter.exclude_input=True installation_analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "436f2814f1f12011c00cf6933038a969dd0edc275127d459a28a14c2140dfae0"
  },
  "kernelspec": {
   "display_name": "osm-analytics",
   "language": "python",
   "name": "osm-analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
