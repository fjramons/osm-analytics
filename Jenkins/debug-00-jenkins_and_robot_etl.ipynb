{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8987bfbc-5d0a-4edc-9a62-507dc07cc878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## ETL preprocessing and loading into database\n",
    "\n",
    "# %%\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jenkins\n",
    "import getpass\n",
    "from jenkins_lib import *\n",
    "from robot_lib import *\n",
    "from jenkins_robot_etl import *\n",
    "import json\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cf8020-e773-4d62-a127-aba78cc4d521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Input parameters\n",
    "\n",
    "# %%\n",
    "# Default values\n",
    "inputs_folder = 'inputs'\n",
    "outputs_folder = 'etl_outputs'\n",
    "url_jenkins_server = 'https://osm.etsi.org/jenkins'\n",
    "input_robot_file = 'output.xml'\n",
    "database_uri = f'sqlite:///{outputs_folder}/test_executions.db'\n",
    "table_known_builds = 'builds_info'\n",
    "table_robot_reports = 'robot_reports'\n",
    "table_robot_reports_extended = 'robot_reports_extended'\n",
    "dump_all_as_spreadsheets = False\n",
    "\n",
    "# %% [markdown]\n",
    "# Tries to bulk load credentials and other environment variables from .env file:\n",
    "\n",
    "# %%\n",
    "# If the '.env' file exists, loads the environment variables\n",
    "load_dotenv();\n",
    "\n",
    "\n",
    "# %%\n",
    "# Retrieves Jenkins credentials from environment, if applicable\n",
    "username = os.environ.get('JENKINS_USER', None) or input('Username: ')\n",
    "password = os.environ.get('JENKINS_PASS', None) or getpass.getpass()\n",
    "\n",
    "# Other environment variables\n",
    "url_jenkins_server = os.environ.get('URL_JENKINS_SERVER', None) or url_jenkins_server\n",
    "database_uri = os.environ.get('DATABASE_URI', None) or database_uri\n",
    "inputs_folder = os.environ.get('INPUTS_FOLDER', None) or inputs_folder\n",
    "outputs_folder = os.environ.get('OUTPUTS_FOLDER', None) or outputs_folder\n",
    "input_robot_file = os.environ.get('INPUT_ROBOT_FILE', None) or input_robot_file\n",
    "table_known_builds = os.environ.get('TABLE_KNOWN_BUILDS', None) or table_known_builds\n",
    "table_robot_reports = os.environ.get('TABLE_ROBOT_REPORTS', None) or table_robot_reports\n",
    "table_robot_reports_extended = os.environ.get('TABLE_ROBOT_REPORTS_EXTENDED', None) or table_robot_reports_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2395f4d2-48b7-41d2-970f-7725221ffff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Populates the database with all builds from a set of relevant jobs\n",
    "\n",
    "# %%\n",
    "job_ids_prefix = 'osm-stage_3-merge/'\n",
    "job_ids_prefix = os.environ.get('JOB_IDS_PREFIX', None) or job_ids_prefix\n",
    "\n",
    "job_ids = ['master', 'v17.0', 'v16.0', 'v15.0', 'v14.0']\n",
    "temp_job_ids = os.environ.get('JOB_IDS', None)\n",
    "\n",
    "if temp_job_ids:\n",
    "    job_ids = json.loads(temp_job_ids.replace(\"'\", \"\"))\n",
    "\n",
    "job_names = ['Master branch', 'Release SEVENTEEN', 'Release SIXTEEN', 'Release FIFTEEN', 'Release FOURTEEN']\n",
    "temp_job_names = os.environ.get('JOB_NAMES', None)\n",
    "if temp_job_names:\n",
    "    job_names = json.loads(temp_job_names.replace(\"'\", \"\"))\n",
    "\n",
    "# relevant_jobs = ['osm-stage_3-merge/' + job_id for job_id in job_ids]\n",
    "relevant_jobs = [job_ids_prefix + job_id for job_id in job_ids]\n",
    "\n",
    "\n",
    "# %%\n",
    "# Connection to the Jenkins server\n",
    "server = jenkins.Jenkins(\n",
    "    url_jenkins_server,\n",
    "    username=username,\n",
    "    password=password\n",
    ")\n",
    "#------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7722277c-e31b-41f1-83ab-686728d657a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03369a77-0211-4706-a2e0-4d87a7aff377",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(database_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b1ead1-112c-4d0b-97fd-daa843227360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Database setup\n",
    "engine = create_engine(database_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aa7ff1-d8fb-4241-b3ba-fc92b39a4eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Getting new builds from: {', '.join(relevant_jobs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec49ce12-552e-4bf3-8d74-860ea81ec240",
   "metadata": {},
   "source": [
    "## Here we replace the original loop by selecting only a job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5840fdb-1c03-48e1-883c-f6e94bb06623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for job in relevant_jobs:\n",
    "#     ingest_update_all_jenkins_job(\n",
    "#         jenkins_server=server,\n",
    "#         job_name=job,\n",
    "#         database_engine=engine,\n",
    "#         robot_report=os.path.join(\n",
    "#             inputs_folder,\n",
    "#             input_robot_file\n",
    "#         ),\n",
    "#         table_known_builds=table_known_builds,\n",
    "#         table_robot_reports=table_robot_reports,\n",
    "#         table_robot_reports_extended=table_robot_reports_extended\n",
    "#     )\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72feeecd-86c8-459a-9a71-41d186289d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = relevant_jobs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed428b27-8d3c-48b0-b869-58825cb94194",
   "metadata": {},
   "outputs": [],
   "source": [
    "jenkins_server=server\n",
    "job_name=job\n",
    "database_engine=engine\n",
    "robot_report=os.path.join(\n",
    "    inputs_folder,\n",
    "    input_robot_file\n",
    ")\n",
    "table_known_builds=table_known_builds\n",
    "table_robot_reports=table_robot_reports\n",
    "table_robot_reports_extended=table_robot_reports_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773469a0-a9e2-48cc-bb57-4923621a4720",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e3f624-ab85-4a74-ac64-7199335e7da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jenkins\n",
    "from jenkins_lib import *\n",
    "from robot_lib import *\n",
    "from sqlalchemy import create_engine\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608b7227-4b71-4a5c-b096-487109a25257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there is historical data about former builds of this job, it is retrieved first (otherwise, it should return an empty dataframe):\n",
    "try:\n",
    "    with database_engine.connect() as connection:\n",
    "        df_known_builds = pd.read_sql_table(table_known_builds, con=connection)\n",
    "except (NameError, ValueError) as e:   # If it does not exist, bootstraps a new dataframe\n",
    "    df_known_builds = pd.DataFrame(columns=['job', 'build', 'timestamp', 'duration', 'build_result', 'test_result', 'pass_count', 'fail_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b6e5f3-c759-4e03-8183-b0bb4f25c7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieves from Jenkins a fresh list of builds of the job:\n",
    "df_builds_of_job = get_all_job_builds(jenkins_server, job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6ed0c6-0926-4fa7-a565-8307c2cc74f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compares the fresh list with the historical one and determines which builds we need to add to our database:\n",
    "known_builds = df_known_builds.loc[df_known_builds.job==job_name, 'build'].tolist()\n",
    "jenkins_builds = df_builds_of_job.loc[:, 'number'].tolist()\n",
    "new_builds = np.setdiff1d(jenkins_builds, known_builds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df5d63e-12b5-4e1a-9a4b-8cea30965239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a new dataframe and appends it to the original one to book the space to save data afterwards:\n",
    "df_unknown_builds = pd.DataFrame(columns=['job', 'build', 'timestamp', 'duration', 'build_result', 'test_result', 'pass_count', 'fail_count'])\n",
    "df_unknown_builds['build'] = new_builds\n",
    "df_unknown_builds['job'] = job_name\n",
    "df_unknown_builds['timestamp'] = pd.to_datetime(df_unknown_builds.timestamp)\n",
    "# df_known_builds = pd.concat([df_known_builds, df_unknown_builds], ignore_index=True)\n",
    "df_known_builds = pd.concat(\n",
    "    [\n",
    "        df.dropna(axis=1, how='all') for df in [df_known_builds, df_unknown_builds]\n",
    "    ],\n",
    "    ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6175fad2-0291-4d29-a183-b57c309add16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starts with empty dataframes\n",
    "df_new_build_reports = pd.DataFrame(columns=['job', 'build', 'id', 'name', 'source', 'status', 'starttime', 'endtime', 'pass', 'fail', 'failed_test_id', 'failed_test_name', 'failed_keyword'])\n",
    "df_new_build_reports_details = pd.DataFrame(columns=['job', 'build', 'suite_id', 'suite_name', 'test_id', 'test_name', 'keyword_name', 'status', 'starttime', 'endtime'])\n",
    "builds_with_missing_info = df_known_builds.loc[(df_known_builds.job==job_name) & (df_known_builds.build_result.isna()), 'build'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ce9892-6520-46c6-bb35-90959effd295",
   "metadata": {},
   "outputs": [],
   "source": [
    "for build_number in builds_with_missing_info:\n",
    "    print(f'Retrieving build {build_number} from \"{job_name}\"...\\t', end='')\n",
    "\n",
    "    # Shortcut to filter this build and job\n",
    "    this_build_and_job = (df_known_builds.job==job_name) & (df_known_builds.build==build_number)\n",
    "\n",
    "    # Retrieves the information about the own build\n",
    "    build_info = get_build_summary(jenkins_server, job_name, build_number)\n",
    "    if build_info['result'] is None:\n",
    "        build_info['result'] = 'FAILURE'\n",
    "    df_known_builds.loc[this_build_and_job, 'build_result'] = build_info['result']\n",
    "    print(f\"Build: {build_info['result']}\\t\", end='')\n",
    "    df_known_builds.loc[this_build_and_job, 'timestamp'] = pd.to_datetime(build_info['timestamp'], unit='ms') # Unit in Jenkins for timestamps\n",
    "    # timestamp_translated = str(df_known_builds.loc[this_build_and_job, 'timestamp'])\n",
    "    #timestamp_translated = df_known_builds.loc[this_build_and_job, 'timestamp'].dt.strftime('%Y-%m-%d')\n",
    "    # print(f\"{timestamp_translated}({build_info['timestamp']})\\t\", end='')\n",
    "    df_known_builds.loc[this_build_and_job, 'duration'] = build_info['duration']\n",
    "\n",
    "    # Retrieves the Robot report, if it exists\n",
    "    try:\n",
    "        robot_report_contents = get_robot_report(jenkins_server, job_name, build_number)\n",
    "        with open(robot_report, 'w', encoding='utf-8') as f:\n",
    "            print(robot_report_contents, file=f)\n",
    "\n",
    "        print('Report available: ', end='')\n",
    "\n",
    "        # Retrieves the rows that need to be added the corresponding database table, and appends them\n",
    "        df_build_report = get_consolidated_results_from_report(robot_report, with_rca=True)\n",
    "        df_build_report_details = get_detailed_results_from_report(robot_report)\n",
    "        # df_new_build_reports = pd.concat([df_new_build_reports, df_build_report], ignore_index=True)\n",
    "        #\n",
    "        ## Comment if this behaviour is undesired. Then, see code into the `with` clause that follows\n",
    "        df_new_build_reports = pd.concat(\n",
    "            [\n",
    "                df.dropna(axis=1, how='all') for df in [df_new_build_reports, df_build_report]\n",
    "            ],\n",
    "            ignore_index=True\n",
    "        )\n",
    "        #####################################################################33\n",
    "\n",
    "        # df_new_build_reports_details = pd.concat([df_new_build_reports_details, df_build_report_details], ignore_index=True)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\n",
    "                \"ignore\",\n",
    "                category=FutureWarning,\n",
    "                message=\"The behavior of DataFrame concatenation with empty or all-NA entries is deprecated*\"\n",
    "            )\n",
    "\n",
    "            # Use only if this behaviour is desired also for the previous dataframe:\n",
    "            # ---------------------------------------------------------------------\n",
    "            # df_new_build_reports = pd.concat(\n",
    "            #     [df_new_build_reports, df_build_report],\n",
    "            #     ignore_index=True\n",
    "            # )\n",
    "\n",
    "            df_new_build_reports_details = pd.concat(\n",
    "                [df_new_build_reports_details, df_build_report_details],\n",
    "                ignore_index=True\n",
    "            )\n",
    "\n",
    "        # Adds the build number to the new rows\n",
    "        ## df_new_build_reports.build.fillna(build_number, inplace=True)\n",
    "        # df_new_build_reports.loc[:, 'build'] = df_new_build_reports.loc[:, 'build'].fillna(build_number)\n",
    "        ## Ensures the column exists, even empty\n",
    "        if 'build' not in df_new_build_reports.columns:\n",
    "            # df_new_build_reports['build'] = pd.NA\n",
    "            df_new_build_reports['build'] = np.nan\n",
    "        ## Fills values accordingly\n",
    "        df_new_build_reports.loc[:, 'build'] = (\n",
    "            df_new_build_reports.loc[:, 'build']\n",
    "            .astype('object')\n",
    "            .infer_objects(copy=False)\n",
    "            .fillna(build_number)\n",
    "        )\n",
    "\n",
    "        ## df_new_build_reports_details.build.fillna(build_number, inplace=True)\n",
    "        # df_new_build_reports_details.loc[:, 'build'] = df_new_build_reports_details.loc[:, 'build'].fillna(build_number)\n",
    "        ## Ensures the column exists, even empty\n",
    "        if 'build' not in df_new_build_reports_details.columns:\n",
    "            df_new_build_reports_details['build'] = pd.NA\n",
    "        ## Fills values accordingly\n",
    "        df_new_build_reports_details.loc[:, 'build'] = (\n",
    "            df_new_build_reports_details.loc[:, 'build']\n",
    "            .astype('object')\n",
    "            .infer_objects(copy=False)\n",
    "            .fillna(build_number)\n",
    "        )\n",
    "\n",
    "        # Records the number of tests passed vs. failed\n",
    "        df_known_builds.loc[this_build_and_job, 'pass_count'] = df_build_report['pass'].sum()\n",
    "        df_known_builds.loc[this_build_and_job, 'fail_count'] = df_build_report['fail'].sum()\n",
    "\n",
    "        # If any test is different from 'PASS', the whole build is marked as 'FAIL'\n",
    "        if len(df_build_report.loc[df_build_report.status!='PASS']):\n",
    "            # Job name will surely match, so there is no need to check it\n",
    "            df_known_builds.loc[this_build_and_job, 'test_result'] = 'FAIL'\n",
    "            print('FAIL')\n",
    "        else:\n",
    "            # Job name will surely match, so there is no need to check it\n",
    "            df_known_builds.loc[this_build_and_job, 'test_result'] = 'PASS'\n",
    "            print('PASS')\n",
    "    except jenkins.NotFoundException as e:\n",
    "        # If the Robot report could not be retrieved, it marks it as unavailable\n",
    "        df_known_builds.loc[this_build_and_job, 'test_result'] = 'UNAVAILABLE'\n",
    "        print('Report unavailable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2af2f7-fa3a-4ead-bcd0-cdff1f0b3c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All new rows should come from the same job\n",
    "\n",
    "## df_new_build_reports.job.fillna(job_name, inplace=True)\n",
    "# df_new_build_reports.loc[:, 'job'] = df_new_build_reports.loc[:, 'job'].fillna(job_name)\n",
    "## Ensures the column exists, even empty\n",
    "if 'job' not in df_new_build_reports.columns:\n",
    "    df_new_build_reports['job'] = pd.NA\n",
    "## Fills values accordingly\n",
    "df_new_build_reports.loc[:, 'job'] = (\n",
    "    df_new_build_reports.loc[:, 'job']\n",
    "    .astype('object')\n",
    "    .infer_objects(copy=False)\n",
    "    .fillna(job_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcd4347-cdff-4e09-9394-18eb803ef1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## df_new_build_reports_details.job.fillna(job_name, inplace=True)\n",
    "# df_new_build_reports_details.loc[:, 'job'] = df_new_build_reports_details.loc[:, 'job'].fillna(job_name)\n",
    "## Ensures the column exists, even empty\n",
    "if 'job' not in df_new_build_reports_details.columns:\n",
    "    df_new_build_reports_details['job'] = pd.NA\n",
    "## Fills values accordingly\n",
    "df_new_build_reports_details.loc[:, 'job'] = (\n",
    "    df_new_build_reports_details.loc[:, 'job']\n",
    "    .astype('object')\n",
    "    .infer_objects(copy=False)\n",
    "    .fillna(job_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb47f8b-3e9d-46af-bcf4-55b25677ca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixes the data types\n",
    "df_new_build_reports['build'] = df_new_build_reports.build.astype('int')\n",
    "df_new_build_reports['status'] = df_new_build_reports.status.astype('category')\n",
    "df_new_build_reports_details['build'] = df_new_build_reports_details.build.astype('int')\n",
    "df_new_build_reports_details['status'] = df_new_build_reports_details.status.astype('category')\n",
    "\n",
    "df_known_builds['build_result'] = df_known_builds.build_result.astype('category')\n",
    "df_known_builds['test_result'] = df_known_builds.test_result.astype('category')\n",
    "df_known_builds['pass_count'] = df_known_builds.pass_count.astype('float')\n",
    "df_known_builds['fail_count'] = df_known_builds.fail_count.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee892365-9d79-4e24-b298-3441e33b82bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(df_known_builds.tail())\n",
    "print()\n",
    "display(df_new_build_reports.tail())\n",
    "print()\n",
    "display(df_new_build_reports_details.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a501ea93-6fb5-4561-a6ec-a58e5845a53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_known_builds.info())\n",
    "display(df_new_build_reports.info())\n",
    "display(df_new_build_reports_details.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8d8f5a-97e1-456a-97e3-09d5c4d362f8",
   "metadata": {},
   "source": [
    "## New code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b726461c-04cd-496b-a304-7d7008308d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "from sqlalchemy.types import BigInteger, String, Float, DateTime, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0260e35-273e-48b9-ab89-293a7086d130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts columns `category` to `str` for each DataFrame\n",
    "## df_known_builds\n",
    "df_known_builds[\"build_result\"] = df_known_builds[\"build_result\"].astype(str)\n",
    "df_known_builds[\"test_result\"] = df_known_builds[\"test_result\"].astype(str)\n",
    "## df_new_build_reports\n",
    "df_new_build_reports[\"status\"] = df_new_build_reports[\"status\"].astype(str)\n",
    "## df_new_build_reports_details\n",
    "df_new_build_reports_details[\"status\"] = df_new_build_reports_details[\"status\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9370733-e943-4c10-b65a-58462d429576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If existing, remove `auto_id` column so that MySQL can generate it automatically\n",
    "if 'auto_id' in df_known_builds.columns:\n",
    "    df_known_builds = df_known_builds.drop(columns=['auto_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f78b0ac-ba9d-4fe5-971a-45803197a761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dtypes for `builds_info`\n",
    "dtype_known_builds = {\n",
    "    \"job\": String(65535),  # TEXT in MySQL allows up to 65535 bytes\n",
    "    \"build\": BigInteger(),\n",
    "    \"timestamp\": DateTime(),\n",
    "    \"duration\": BigInteger(),\n",
    "    \"build_result\": String(65535),\n",
    "    \"test_result\": String(65535),\n",
    "    \"pass_count\": Float(),\n",
    "    \"fail_count\": Float()\n",
    "}\n",
    "\n",
    "# Dtypes for `robot_reports`\n",
    "dtype_robot_reports = {\n",
    "    \"job\": String(65535),\n",
    "    \"build\": BigInteger(),\n",
    "    \"id\": String(65535),\n",
    "    \"name\": String(65535),\n",
    "    \"source\": String(65535),\n",
    "    \"status\": String(65535),\n",
    "    \"starttime\": DateTime(),\n",
    "    \"endtime\": DateTime(),\n",
    "    \"pass\": Integer(),\n",
    "    \"fail\": Integer(),\n",
    "    \"failed_test_id\": String(65535),\n",
    "    \"failed_test_name\": String(65535),\n",
    "    \"failed_keyword\": String(65535),\n",
    "}\n",
    "\n",
    "# Dtypes for `robot_reports_extended`\n",
    "dtype_robot_reports_extended = {\n",
    "    \"job\": String(65535),\n",
    "    \"build\": String(255),  # Seg√∫n tu info es object en df_new_build_reports_details, usar varchar(255)\n",
    "    \"suite_id\": String(65535),\n",
    "    \"suite_name\": String(65535),\n",
    "    \"test_id\": String(65535),\n",
    "    \"test_name\": String(65535),\n",
    "    \"keyword_name\": String(65535),\n",
    "    \"status\": String(65535),\n",
    "    \"starttime\": DateTime(),\n",
    "    \"endtime\": DateTime(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8fb21e-7f96-4aa7-b24d-512c1db82332",
   "metadata": {},
   "outputs": [],
   "source": [
    "with database_engine.begin() as conn:\n",
    "    # Delete and re-create `builds_info` table with the origina schema and `auto_increment`\n",
    "    conn.execute(text(f\"DROP TABLE IF EXISTS {table_known_builds}\"))\n",
    "    conn.execute(text(f\"\"\"\n",
    "        CREATE TABLE {table_known_builds} (\n",
    "            auto_id BIGINT PRIMARY KEY AUTO_INCREMENT,\n",
    "            job TEXT,\n",
    "            build BIGINT,\n",
    "            timestamp DATETIME,\n",
    "            duration BIGINT,\n",
    "            build_result TEXT,\n",
    "            test_result TEXT,\n",
    "            pass_count DOUBLE,\n",
    "            fail_count DOUBLE\n",
    "        ) ENGINE=InnoDB;\n",
    "    \"\"\"))\n",
    "\n",
    "    # Insert data without `auto_id` columns so that MySQL assigns it\n",
    "    df_known_builds.to_sql(\n",
    "        name=table_known_builds,\n",
    "        con=conn,\n",
    "        if_exists='append',\n",
    "        index=False,\n",
    "        dtype=dtype_known_builds,\n",
    "        method='multi'\n",
    "    )\n",
    "\n",
    "    # For `robot_reports`, with remains, we just insert with `append`\n",
    "    df_new_build_reports.to_sql(\n",
    "        name=table_robot_reports,\n",
    "        con=conn,\n",
    "        if_exists='append',\n",
    "        index=False,\n",
    "        dtype=dtype_robot_reports,\n",
    "        method='multi'\n",
    "    )\n",
    "\n",
    "    # For `robot_reports_extended`, we insert with `append` as well\n",
    "    df_new_build_reports_details.to_sql(\n",
    "        name=table_robot_reports_extended,\n",
    "        con=conn,\n",
    "        if_exists='append',\n",
    "        index=False,\n",
    "        dtype=dtype_robot_reports_extended,\n",
    "        method='multi'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eb6321-5a5f-4bae-ac6a-ea6eb5a21567",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb188c7-f565-4970-8fe5-72a145edcf79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
