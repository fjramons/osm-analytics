{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Robot reports from OSM Jenkins (Step 1)\n",
    " \n",
    "## ETL preprocessing and loading into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jenkins\n",
    "import getpass\n",
    "from jenkins_lib import *\n",
    "from robot_lib import *\n",
    "from jenkins_robot_etl import *\n",
    "import json\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_folder = 'inputs'\n",
    "outputs_folder = 'etl_outputs'\n",
    "url_jenkins_server = 'https://osm.etsi.org/jenkins'\n",
    "input_robot_file = 'output.xml'\n",
    "database_uri = f'sqlite:///{outputs_folder}/test_executions.db'\n",
    "table_known_builds = 'builds_info'\n",
    "table_robot_reports = 'robot_reports'\n",
    "table_robot_reports_extended = 'robot_reports_extended'\n",
    "dump_all_as_spreadsheets = False\n",
    "#job_name = 'osm-stage_3-merge/v9.0'\n",
    "job_name = 'osm-stage_3-merge/master'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credentials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the '.env' file exists, loads the environment variables\n",
    "try:\n",
    "    with open('.env', 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            key, value = line.split('=')\n",
    "            os.environ[key] = value\n",
    "except FileNotFoundError as e:\n",
    "    print(\"Environment file ('.env') does not exist. Skipping...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = os.environ.get('JENKINS_USER', None) or input('Username: ')\n",
    "password = os.environ.get('JENKINS_PASS', None) or getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Retrieval of Jenkins jobs info and Robot reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opens session with the Jenkins server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = jenkins.Jenkins(url_jenkins_server, username=username, password=password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests the connection to the Jenkins server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_jenkins_connection(server)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Jobs in the Jenkins server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieves the list of jobs that exist in the Jenkins server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_jenkins_jobs_as_df(server)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Analysis of specific jobs: e.g. v9.0 testing job (`job_name`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_job_status = get_job_summary(server, job_name)\n",
    "my_job_status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Health report of the job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "health = get_job_health(server, job_name)\n",
    "health"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Analysis of builds of the reference job (v9.0 testing job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of historical builds of the job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_builds_of_job = get_all_job_builds(server, job_name)\n",
    "df_builds_of_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_builds_of_job.number.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieves all the information about a specific build:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want the info of latest complete build\n",
    "build_number = my_job_status[\"lastCompletedBuild_number\"]\n",
    "#build_number = 985\n",
    "\n",
    "my_build_summary = get_build_summary(server, job_name, build_number)\n",
    "my_build_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 1.4 Retrieval of Robot results of latest completed build of v9.0 testing job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    robot_report_contents = get_robot_report(server, job_name, build_number)\n",
    "#except requests.HTTPError:\n",
    "except jenkins.NotFoundException:\n",
    "    print(f'Build {build_number} in job {job_name} did not issue any Robot report.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imports info from Robot test report and cleans data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_report = os.path.join(inputs_folder, input_robot_file)\n",
    "with open(robot_report, 'w', encoding='utf-8') as f:\n",
    "    print(robot_report_contents, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Numerical statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_stats = get_stats_from_report(robot_report)\n",
    "df_test_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_stats.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Results per test suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_suites = get_results_from_report(robot_report)\n",
    "df_test_suites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_suites.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Stats and results per test suite (consolidated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consolidated_test_results = get_consolidated_results_from_report(robot_report)\n",
    "df_consolidated_test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Details of the test suites up to the level of keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tests_and_keywords = get_detailed_results_from_report(robot_report)\n",
    "df_tests_and_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tests_and_keywords.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finds the first failure per test suite (which is the most likely root cause):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_root_cause_errors = df_tests_and_keywords.loc[df_tests_and_keywords.status=='FAIL'].groupby('suite_id').first()\n",
    "df_root_cause_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_root_cause_errors.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Enriches consolidated results with likely root cause of failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidated_results_from_report = get_consolidated_results_from_report(robot_report, with_rca=True)\n",
    "consolidated_results_from_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidated_results_from_report.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Populates a database with data from all builds of a job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#job_name = 'osm-stage_3-merge/v9.0'\n",
    "#job_name = 'osm-stage_3-merge/master'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Database connection setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database setup\n",
    "engine = create_engine(database_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is historical data about former builds of this job, it is retrieved first (otherwise, it should return an empty dataframe):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        df_known_builds = pd.read_sql_table(table_known_builds, con=connection)\n",
    "\n",
    "    # Fixes data types\n",
    "    #df_known_builds['duration'] = pd.to_timedelta(df_known_builds.duration, unit='ns')  # 'ns' is the unit in SQLAlchemy\n",
    "except (NameError, ValueError) as e:   # If it does not exist, bootstraps a new dataframe\n",
    "    df_known_builds = pd.DataFrame(columns=['job', 'build', 'timestamp', 'duration', 'build_result', 'test_result', 'pass_count', 'fail_count'])\n",
    "df_known_builds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_known_builds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that `duration` is convertible to `timedelta` format whenever needed:\n",
    "\n",
    "pd.to_timedelta(df_known_builds.duration.astype(float), unit='ms')  # 'ms' is the unit in Jenkins\n",
    "#pd.to_timedelta(df_known_builds.duration, unit='ns')  # 'ns' is the unit in SQLAlchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieves from Jenkins a fresh list of builds of the job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_builds_of_job = get_all_job_builds(server, job_name)\n",
    "df_builds_of_job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compares the fresh list with the historical one and determines which builds we need to add to our database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_builds = df_known_builds.loc[df_known_builds.job==job_name, 'build'].tolist()\n",
    "jenkins_builds = df_builds_of_job.loc[:, 'number'].tolist()\n",
    "new_builds = np.setdiff1d(jenkins_builds, known_builds)\n",
    "new_builds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a new dataframe and appends it to the original one to book the space to save data afterwards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unknown_builds = pd.DataFrame(columns=['job', 'build', 'timestamp', 'duration', 'build_result', 'test_result', 'pass_count', 'fail_count'])\n",
    "df_unknown_builds['build'] = new_builds\n",
    "df_unknown_builds['job'] = job_name\n",
    "df_unknown_builds['timestamp'] = pd.to_datetime(df_unknown_builds.timestamp)\n",
    "df_unknown_builds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_known_builds = pd.concat([df_known_builds, df_unknown_builds], ignore_index=True)\n",
    "df_known_builds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_known_builds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterates to retrieve all the information from unknown builds and, if feasible, their corresponding Robot reports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "robot_report = os.path.join(inputs_folder, input_robot_file)\n",
    "\n",
    "# Starts with empty dataframes\n",
    "df_new_build_reports = pd.DataFrame(columns=['job', 'build', 'id', 'name', 'source', 'status', 'starttime', 'endtime', 'pass', 'fail', 'failed_test_id', 'failed_test_name', 'failed_keyword'])\n",
    "df_new_build_reports_details = pd.DataFrame(columns=['job', 'build', 'suite_id', 'suite_name', 'test_id', 'test_name', 'keyword_name', 'status', 'starttime', 'endtime'])\n",
    "\n",
    "builds_with_missing_info = df_known_builds.loc[(df_known_builds.job==job_name) & (df_known_builds.build_result.isna()), 'build'].tolist()\n",
    "#builds_with_missing_info = builds_with_missing_info[:5]\n",
    "#builds_with_missing_info = [my_job_status[\"lastCompletedBuild_number\"], my_job_status[\"lastCompletedBuild_number\"]-1, 1]\n",
    "#builds_with_missing_info = [my_job_status[\"lastCompletedBuild_number\"]-4, my_job_status[\"lastCompletedBuild_number\"]-5, 3]\n",
    "for build_number in builds_with_missing_info:\n",
    "    print(f'Retrieving build {build_number} from \"{job_name}\"...\\t', end='')\n",
    "\n",
    "    # Shortcut to filter this build and job\n",
    "    this_build_and_job = (df_known_builds.job==job_name) & (df_known_builds.build==build_number)\n",
    "\n",
    "    # Retrieves the information about the own build\n",
    "    build_info = get_build_summary(server, job_name, build_number)\n",
    "    df_known_builds.loc[this_build_and_job, 'build_result'] = build_info['result']\n",
    "    print(f\"Build: {build_info['result']}\\t\", end='')\n",
    "    #df_known_builds.loc[this_build_and_job, 'timestamp'] = int(build_info['timestamp'])\n",
    "    df_known_builds.loc[this_build_and_job, 'timestamp'] = pd.to_datetime(build_info['timestamp'], unit='ms') # Unit in Jenkins for timestamps\n",
    "    timestamp_translated = str(df_known_builds.loc[this_build_and_job, 'timestamp'])\n",
    "    # timestamp_translated = df_known_builds.loc[this_build_and_job, 'timestamp'].dt.strftime('%Y-%m-%d')\n",
    "    print(f\"{timestamp_translated}({build_info['timestamp']})\\t\", end='')\n",
    "    df_known_builds.loc[this_build_and_job, 'duration'] = build_info['duration']\n",
    "    #df_known_builds.loc[this_build_and_job, 'duration'] = pd.to_timedelta(build_info['duration'], unit='ms')  # Unit in Jenkins for timestamps\n",
    "\n",
    "    # Retrieves the Robot report, if it exists\n",
    "    try:\n",
    "        robot_report_contents = get_robot_report(server, job_name, build_number)\n",
    "        with open(robot_report, 'w', encoding='utf-8') as f:\n",
    "            print(robot_report_contents, file=f)\n",
    "\n",
    "        print('Report available: ', end='')\n",
    "\n",
    "        # Retrieves the rows that need to be added the corresponding database table, and appends them\n",
    "        df_build_report = get_consolidated_results_from_report(robot_report, with_rca=True)\n",
    "        df_build_report_details = get_detailed_results_from_report(robot_report)\n",
    "        df_new_build_reports = pd.concat([df_new_build_reports, df_build_report], ignore_index=True)\n",
    "        df_new_build_reports_details = pd.concat([df_new_build_reports_details, df_build_report_details], ignore_index=True)\n",
    "        \n",
    "        # Adds the build number to the new rows\n",
    "        df_new_build_reports.build.fillna(build_number, inplace=True)\n",
    "        df_new_build_reports_details.build.fillna(build_number, inplace=True)\n",
    "\n",
    "        # Records the number of tests passed vs. failed\n",
    "        df_known_builds.loc[this_build_and_job, 'pass_count'] = df_build_report['pass'].sum()\n",
    "        df_known_builds.loc[this_build_and_job, 'fail_count'] = df_build_report['fail'].sum()\n",
    "\n",
    "        # If any test is different from 'PASS', the whole build is marked as 'FAIL'\n",
    "        if len(df_build_report.loc[df_build_report.status!='PASS']):\n",
    "            # Job name will surely match, so there is no need to check it\n",
    "            df_known_builds.loc[this_build_and_job, 'test_result'] = 'FAIL'\n",
    "            print('FAIL')\n",
    "        else:\n",
    "            # Job name will surely match, so there is no need to check it\n",
    "            df_known_builds.loc[this_build_and_job, 'test_result'] = 'PASS'\n",
    "            print('PASS')\n",
    "    except jenkins.NotFoundException as e:\n",
    "        # If the Robot report could not be retrieved, it marks it as unavailable\n",
    "        df_known_builds.loc[this_build_and_job, 'test_result'] = 'UNAVAILABLE'\n",
    "        print('Report unavailable')\n",
    "\n",
    "# All new rows should come from the same job\n",
    "df_new_build_reports.job.fillna(job_name, inplace=True)\n",
    "df_new_build_reports_details.job.fillna(job_name, inplace=True)\n",
    "\n",
    "# Fixes the data types\n",
    "df_new_build_reports['build'] = df_new_build_reports.build.astype('int')\n",
    "df_new_build_reports['status'] = df_new_build_reports.status.astype('category')\n",
    "df_new_build_reports_details['build'] = df_new_build_reports_details.build.astype('int')\n",
    "df_new_build_reports_details['status'] = df_new_build_reports_details.status.astype('category')\n",
    "#df_known_builds['timestamp'] = pd.to_datetime(df_known_builds.timestamp, unit='ms') # Unit in Jenkins for timestamps\n",
    "\n",
    "#----\n",
    "#df_known_builds['timestamp'] = pd.to_datetime(df_known_builds.timestamp)\n",
    "#-----\n",
    "\n",
    "#df_known_builds['duration'] = pd.to_timedelta(df_known_builds.duration, unit='ms')  # Unit in Jenkins for timedeltas\n",
    "df_known_builds['build_result'] = df_known_builds.build_result.astype('category')\n",
    "df_known_builds['test_result'] = df_known_builds.test_result.astype('category')\n",
    "df_known_builds['pass_count'] = df_known_builds.pass_count.astype('float')\n",
    "df_known_builds['fail_count'] = df_known_builds.fail_count.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_known_builds[df_known_builds.timestamp.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_known_builds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saves the results to the database as a single transaction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.begin() as conn:\n",
    "    df_known_builds.to_sql(name=table_known_builds, con=conn, if_exists='replace', index=False)\n",
    "    df_new_build_reports.to_sql(name=table_robot_reports, con=conn, if_exists='append', index=False)\n",
    "    df_new_build_reports_details.to_sql(name=table_robot_reports_extended, con=conn, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, saves the results as .CSV and .XLSX to allow quick access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decides file names\n",
    "csv_known_builds = os.path.join(outputs_folder, table_known_builds) + '.csv'\n",
    "xlsx_known_builds = os.path.join(outputs_folder, table_known_builds) + '.xlsx'\n",
    "\n",
    "df_known_builds.to_csv(csv_known_builds, index=False, sep=';')\n",
    "df_known_builds.to_excel(xlsx_known_builds, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump_all_as_spreadsheets = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dump_all_as_spreadsheets:\n",
    "    # Decides file names\n",
    "    csv_robot_reports = os.path.join(outputs_folder, table_robot_reports) + '.csv'\n",
    "    xlsx_robot_reports = os.path.join(outputs_folder, table_robot_reports) + '.xlsx'\n",
    "    csv_robot_reports_extended = os.path.join(outputs_folder, table_robot_reports_extended) + '.csv'\n",
    "    xlsx_robot_reports_extended = os.path.join(outputs_folder, table_robot_reports_extended) + '.xlsx'\n",
    "\n",
    "    # Retrieves the full tables from the database\n",
    "    with engine.begin() as conn:\n",
    "        df_all_build_reports = pd.read_sql_table(table_robot_reports, con=conn)\n",
    "        df_all_build_reports_details = pd.read_sql_table(table_robot_reports_extended, con=conn)\n",
    "\n",
    "    # Dumps the full tables, now as spreadsheets\n",
    "    df_all_build_reports.to_csv(csv_robot_reports, index=False, sep=';')\n",
    "    df_all_build_reports.to_excel(xlsx_robot_reports, index=False)\n",
    "    df_all_build_reports_details.to_csv(csv_robot_reports_extended, index=False, sep=';')\n",
    "    df_all_build_reports_details.to_excel(xlsx_robot_reports_extended, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Populates the database with all builds from a set of relevant jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_jobs = ['osm-stage_3-merge/v9.0', 'osm-stage_3-merge/master']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection to the Jenkins server\n",
    "server = jenkins.Jenkins(url_jenkins_server, username=username, password=password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database setup\n",
    "engine = create_engine(database_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for job in relevant_jobs:\n",
    "    ingest_update_all_jenkins_job(jenkins_server=server,\n",
    "                                  job_name=job,\n",
    "                                  database_engine=engine,\n",
    "                                  robot_report=os.path.join(inputs_folder, input_robot_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osm-analytics",
   "language": "python",
   "name": "osm-analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
