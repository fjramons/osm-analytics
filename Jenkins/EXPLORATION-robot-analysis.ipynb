{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTERACTIVE - Analysis of Robot reports from OSM Jenkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import xml.etree.ElementTree as et\n",
    "import pandas as pd\n",
    "import requests\n",
    "import jenkins\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_folder = 'inputs'\n",
    "input_robot_file = 'output.xml'\n",
    "job_name = 'osm-stage_3-merge/v9.0'\n",
    "url_jenkins_server = 'https://osm.etsi.org/jenkins'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credentials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the '.env' file exists, loads the environment variables\n",
    "try:\n",
    "    with open('.env', 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            key, value = line.split('=')\n",
    "            os.environ[key] = value\n",
    "except FileNotFoundError as e:\n",
    "    print(\"Environment file ('.env') does not exist. Skipping...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = os.environ.get('JENKINS_USER', None) or input('Username: ')\n",
    "password = os.environ.get('JENKINS_PASS', None) or getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Retrieval of Jenkins jobs info and Robot reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opens session with the Jenkins server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = jenkins.Jenkins(url_jenkins_server, username=username, password=password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests the connection to the Jenkins server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = server.get_whoami()\n",
    "version = server.get_version()\n",
    "print(f'Hello {user[\"fullName\"]} from Jenkins {version}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Jobs in the Jenkins server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieves the list of jobs that exist in the Jenkins server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jenkinsJobs = server.get_all_jobs()\n",
    "df_jobs = pd.DataFrame(jenkinsJobs)\n",
    "df_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Analysis of v9.0 testing job (`job_name`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtains all the raw information about the job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_job = server.get_job_info(job_name, 0, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_fields = [key for key in my_job]\n",
    "job_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Builds a summary table of the selected job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieves all the fields except those that embed complex structures in the JSON\n",
    "composite_fields = ['actions', 'builds', 'firstBuild', 'healthReport', 'lastBuild', 'lastCompletedBuild', 'lastFailedBuild', 'lastStableBuild', 'lastSuccessfulBuild','lastUnstableBuild', 'lastUnsuccessfulBuild', 'property']\n",
    "my_job.get('resumeBlocked')\n",
    "flat_dict = {k: my_job.get(k, None) for k in my_job if k not in composite_fields}\n",
    "flat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_job.get('lastCompletedBuild')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds additional info that was nested in the JSON\n",
    "reference_builds_of_job = ['firstBuild', 'lastBuild', 'lastCompletedBuild', 'lastFailedBuild', 'lastStableBuild', 'lastSuccessfulBuild','lastUnstableBuild', 'lastUnsuccessfulBuild']\n",
    "for k in reference_builds_of_job:\n",
    "    item = my_job.get(k, None)\n",
    "    if item:\n",
    "        flat_dict[k + '_number'] = item.get('number', None)\n",
    "        flat_dict[k + '_url'] = item.get('url', None)\n",
    "flat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of job status\n",
    "#my_job_status = pd.DataFrame(flat_dict, index=[0])\n",
    "#my_job_status = pd.Series(flat_dict)\n",
    "my_job_status = flat_dict\n",
    "my_job_status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Health report of the job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_of_job = my_job.get('healthReport')\r\n",
    "health_of_job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Analysis of builds of the reference job (v9.0 testing job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of historical builds of the job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_builds_of_job = pd.DataFrame(my_job.get('builds')).drop(columns='_class')\n",
    "df_builds_of_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_builds_of_job.number.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieves all the information about a specific build:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want the info of latest complete build\n",
    "build_number = my_job_status[\"lastCompletedBuild_number\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieves raw build data\n",
    "build_info = server.get_build_info(job_name, build_number)\n",
    "build_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in build_info:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of key data of latest completed build\n",
    "relevant_build_fields = ['id', 'number', 'result', 'duration', 'estimatedDuration', 'timestamp', 'url']\n",
    "my_build_summary = {k: build_info.get(k, None) for k in relevant_build_fields}\n",
    "my_build_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Retrieval of Robot results of latest completed build of v9.0 testing job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_results_url = my_build_summary['url'] + 'robot/report/output.xml'\n",
    "robot_results_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieves the contents of the report file\n",
    "req = requests.Request('POST',  robot_results_url)\n",
    "robot_report_contents = server.jenkins_open(req)\n",
    "robot_report_contents[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imports info from Robot test report and cleans data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finds the root of the XML tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#robot_report = os.path.join(inputs_folder, input_robot_file)\n",
    "robot_report = io.StringIO(robot_report_contents)\n",
    "\n",
    "xtree = et.parse(robot_report)\n",
    "xroot = xtree.getroot()\n",
    "timestamp = xroot.attrib['generated']\n",
    "xroot.attrib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Numerical statistics\n",
    "\n",
    "Obtains the section of numerical statistics, which includes the number of passed/failed tests per testsuite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics = xroot.find('statistics')\n",
    "stat_suites = statistics.find('suite')\n",
    "fields = ['id', 'name', 'pass', 'fail']\n",
    "rows = []\n",
    "for stat in stat_suites:\n",
    "    rows.append( {f: stat.attrib[f] for f in fields} )\n",
    "df_test_stats = pd.DataFrame(rows)\n",
    "df_test_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_stats.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_stats['pass'] = df_test_stats['pass'].astype('int64')\n",
    "df_test_stats['fail'] = df_test_stats['fail'].astype('int64')\n",
    "df_test_stats.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes the first row (just summarizes the stats of all the testsuites)\n",
    "df_test_stats = df_test_stats.loc[1:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds a new column with the overall result of the test suite\n",
    "df_test_stats['status'] = 'PASS'\n",
    "df_test_stats.loc[df_test_stats.fail>0, 'status'] = 'FAIL'\n",
    "df_test_stats['status'] = df_test_stats.status.astype('category')\n",
    "df_test_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_stats.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Results per test suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataframe of results of the test suites of the tests of the day \n",
    "all_suites = xroot.find('suite')\n",
    "\n",
    "suite_rows = []\n",
    "status_rows = []\n",
    "for suite in all_suites.findall('suite'):\n",
    "    # suite\n",
    "    suite_rows.append(suite.attrib)\n",
    "\n",
    "    ## suite --> status\n",
    "    status_rows.append(suite.find('status').attrib)\n",
    "\n",
    "df_test_suites = pd.concat([pd.DataFrame(suite_rows), pd.DataFrame(status_rows)], axis=1)\n",
    "df_test_suites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_suites.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_suites['status'] = df_test_suites.status.astype('category')\n",
    "df_test_suites['starttime'] = pd.to_datetime(df_test_suites.starttime)\n",
    "df_test_suites['endtime'] = pd.to_datetime(df_test_suites.endtime)\n",
    "df_test_suites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_suites.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Details of the test suites up to the level of keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe with details of each keyword run in the test\n",
    "all_suites = xroot.find('suite')\n",
    "\n",
    "rows = []\n",
    "for suite in all_suites.findall('suite'):\n",
    "    # suite\n",
    "    suite_id = suite.attrib['id']\n",
    "    suite_name = suite.attrib['name']\n",
    "\n",
    "    ## tests in the suite\n",
    "    for test in suite.findall('test'):\n",
    "        test_id = test.attrib['id']\n",
    "        test_name = test.attrib['name']\n",
    "\n",
    "        for kw in test.findall('kw'):\n",
    "            keyword_name = kw.attrib['name']\n",
    "            resultado = kw.find('status').attrib\n",
    "\n",
    "            line = {'suite_id': suite_id, 'suite_name': suite_name, 'test_id': test_id, 'test_name': test_name, 'keyword_name': keyword_name, **resultado}\n",
    "            rows.append(line)\n",
    "\n",
    "df_tests_and_keywords = pd.DataFrame(rows)\n",
    "df_tests_and_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tests_and_keywords.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tests_and_keywords['status'] = df_tests_and_keywords.status.astype('category')\n",
    "df_tests_and_keywords['starttime'] = pd.to_datetime(df_tests_and_keywords.starttime)\n",
    "df_tests_and_keywords['endtime'] = pd.to_datetime(df_tests_and_keywords.endtime)\n",
    "df_tests_and_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tests_and_keywords.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finds the first failure per test suite (which is the most likely root cause):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_root_cause_errors = df_tests_and_keywords.loc[df_tests_and_keywords.status=='FAIL'].groupby('suite_id').first()\n",
    "df_root_cause_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_root_cause_errors.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('osm-analytics': conda)",
   "name": "python385jvsc74a57bd0436f2814f1f12011c00cf6933038a969dd0edc275127d459a28a14c2140dfae0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
