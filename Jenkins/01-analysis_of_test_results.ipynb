{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Robot reports from OSM Jenkins (Step 2)\n",
    "\n",
    "## Data analysis and reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "#import numpy as np\n",
    "#import jenkins\n",
    "#import getpass\n",
    "#from jenkins_lib import *\n",
    "#from robot_lib import *\n",
    "from sqlalchemy import create_engine\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "inputs_folder = 'etl_outputs'\n",
    "outputs_folder = 'report_outputs'\n",
    "database_uri = f'sqlite:///{inputs_folder}/test_executions.db'\n",
    "table_known_builds = 'builds_info'\n",
    "table_robot_reports = 'robot_reports'\n",
    "table_robot_reports_extended = 'robot_reports_extended'\n",
    "\n",
    "too_old_builds = \"2020-12-15\"\n",
    "job_name = 'osm-stage_3-merge/v9.0'\n",
    "#job_name = 'osm-stage_3-merge/master'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "today = pd.to_datetime(\"today\").strftime('%Y-%m-%d')\n",
    "today"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Information about the latest builds of relevant jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "engine = create_engine(database_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finds latest builds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "query_latest_builds = f'''\n",
    "SELECT main.*\n",
    "FROM {table_known_builds} AS main\n",
    "INNER JOIN (\n",
    "\tSELECT job, MAX(timestamp) as ts\n",
    "\tFROM {table_known_builds}\n",
    "\tWHERE timestamp>DATETIME(\"{too_old_builds}\")\n",
    "\tGROUP BY job\n",
    ") AS latest_build\n",
    "ON main.job=latest_build.job AND main.timestamp=ts\n",
    "'''\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    df_latest_builds = pd.read_sql(query_latest_builds, con=conn)\n",
    "\n",
    "df_latest_builds['timestamp'] = pd.to_datetime(df_latest_builds.timestamp)\n",
    "\n",
    "df_latest_builds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieves reports from latest builds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "table = table_robot_reports\n",
    "\n",
    "query_robot_reports = f'''\n",
    "SELECT details.*\n",
    "FROM {table} AS details\n",
    "INNER JOIN {table_known_builds} AS main\n",
    "ON details.job=main.job AND details.build=main.build\n",
    "INNER JOIN (\n",
    "\tSELECT job, MAX(timestamp) as ts\n",
    "\tFROM {table_known_builds}\n",
    "\tWHERE timestamp>DATETIME(\"{too_old_builds}\")\n",
    "\tGROUP BY job\n",
    ") AS latest_build\n",
    "ON main.job=latest_build.job AND main.timestamp=ts\n",
    "'''\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    df_robot_reports = pd.read_sql(query_robot_reports, con=conn)\n",
    "\n",
    "df_robot_reports['starttime'] = pd.to_datetime(df_robot_reports.starttime)\n",
    "df_robot_reports['endtime'] = pd.to_datetime(df_robot_reports.endtime)\n",
    "\n",
    "df_robot_reports.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieves extended reports from latest builds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "table = table_robot_reports_extended\n",
    "\n",
    "query_robot_reports = f'''\n",
    "SELECT details.*\n",
    "FROM {table} AS details\n",
    "INNER JOIN {table_known_builds} AS main\n",
    "ON details.job=main.job AND details.build=main.build\n",
    "INNER JOIN (\n",
    "\tSELECT job, MAX(timestamp) as ts\n",
    "\tFROM {table_known_builds}\n",
    "\tWHERE timestamp>DATETIME(\"{too_old_builds}\")\n",
    "\tGROUP BY job\n",
    ") AS latest_build\n",
    "ON main.job=latest_build.job AND main.timestamp=ts\n",
    "'''\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    df_robot_reports_extended = pd.read_sql(query_robot_reports, con=conn)\n",
    "\n",
    "df_robot_reports_extended['starttime'] = pd.to_datetime(df_robot_reports_extended.starttime)\n",
    "df_robot_reports_extended['endtime'] = pd.to_datetime(df_robot_reports_extended.endtime)\n",
    "df_robot_reports_extended.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Details of `v9.0` job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "job_name = 'osm-stage_3-merge/v9.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latest `v9.0` build:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_latest_builds[df_latest_builds.job==job_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Failed tests (if they exist):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fails_latest_v9 = df_robot_reports[(df_robot_reports.job==job_name) & (df_robot_reports.status=='FAIL')].drop(columns=['job', 'build', 'source'])\n",
    "fails_latest_v9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details of failed tests (if they exist):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "detailed_fails_latest_v9 = df_robot_reports_extended[(df_robot_reports_extended.job==job_name) & (df_robot_reports_extended.suite_id.isin(fails_latest_v9[\"id\"]))].drop(columns=['job', 'build'])\n",
    "detailed_fails_latest_v9['duration'] = detailed_fails_latest_v9.endtime - detailed_fails_latest_v9.starttime\n",
    "detailed_fails_latest_v9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Details of `master` job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "job_name = 'osm-stage_3-merge/master'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latest `master` build:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_latest_builds[df_latest_builds.job==job_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Failed tests (if they exist):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fails_latest_master = df_robot_reports[(df_robot_reports.job==job_name) & (df_robot_reports.status=='FAIL')].drop(columns=['job', 'build', 'source'])\n",
    "fails_latest_master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details of failed tests (if they exist):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "detailed_fails_latest_master = df_robot_reports_extended[(df_robot_reports_extended.job==job_name) & (df_robot_reports_extended.suite_id.isin(fails_latest_master[\"id\"]))].drop(columns=['job', 'build'])\n",
    "detailed_fails_latest_master['duration'] = detailed_fails_latest_master.endtime - detailed_fails_latest_master.starttime\n",
    "detailed_fails_latest_master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Details of `v10.0` job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "job_name = 'osm-stage_3-merge/v10.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latest `v10.0` build:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_latest_builds[df_latest_builds.job==job_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Failed tests (if they exist):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fails_latest_master = df_robot_reports[(df_robot_reports.job==job_name) & (df_robot_reports.status=='FAIL')].drop(columns=['job', 'build', 'source'])\n",
    "fails_latest_master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details of failed tests (if they exist):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "detailed_fails_latest_master = df_robot_reports_extended[(df_robot_reports_extended.job==job_name) & (df_robot_reports_extended.suite_id.isin(fails_latest_master[\"id\"]))].drop(columns=['job', 'build'])\n",
    "detailed_fails_latest_master['duration'] = detailed_fails_latest_master.endtime - detailed_fails_latest_master.starttime\n",
    "detailed_fails_latest_master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieves all currrent data for aggregate analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "too_old_builds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#query_known_builds = f'SELECT * FROM {table_known_builds} WHERE job=\"{job_name}\" AND timestamp>{too_old_builds}'\n",
    "query_known_builds = f'SELECT * FROM {table_known_builds} WHERE timestamp>DATETIME(\"{too_old_builds}\")'\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    df_known_builds = pd.read_sql(query_known_builds, con=conn)\n",
    "\n",
    "# Fixes some special data types\n",
    "df_known_builds['timestamp'] = pd.to_datetime(df_known_builds.timestamp)\n",
    "df_known_builds['job'] = df_known_builds.job.astype('category')\n",
    "df_known_builds['duration'] = pd.to_timedelta(df_known_builds.duration.astype('float')*1000, unit='us')\n",
    "df_known_builds['build_result'] = df_known_builds.build_result.astype('category')\n",
    "df_known_builds['test_result'] = df_known_builds.test_result.astype('category')\n",
    "\n",
    "# Keeps only timestamps newer than the \"too_old_builds\" threshold\n",
    "# This is needed to circumvent the limitations with dates of too basic databases (e.g. SQLite)\n",
    "#df_known_builds = df_known_builds[df_known_builds.timestamp > too_old_builds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_known_builds[df_known_builds.job=='osm-stage_3-merge/v9.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "query_robot_reports = f'''\n",
    "SELECT main.timestamp, details.*\n",
    "FROM {table_robot_reports} AS details\n",
    "INNER JOIN {table_known_builds} AS main\n",
    "ON details.job=main.job AND details.build=main.build\n",
    "WHERE main.timestamp>DATETIME(\"{too_old_builds}\")\n",
    "ORDER BY details.job, details.build, details.starttime\n",
    "'''\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    df_all_build_reports = pd.read_sql(query_robot_reports, con=conn)\n",
    "\n",
    "# Fixes some special data types\n",
    "df_all_build_reports['timestamp'] = pd.to_datetime(df_all_build_reports.timestamp)\n",
    "df_all_build_reports['job'] = df_all_build_reports.job.astype('category')\n",
    "df_all_build_reports['id'] = df_all_build_reports.id.astype('category')\n",
    "df_all_build_reports['name'] = df_all_build_reports.name.astype('category')\n",
    "df_all_build_reports['source'] = df_all_build_reports.source.astype('category')\n",
    "df_all_build_reports['starttime'] = pd.to_datetime(df_all_build_reports.starttime)\n",
    "df_all_build_reports['endtime'] = pd.to_datetime(df_all_build_reports.endtime)\n",
    "df_all_build_reports['status'] = df_all_build_reports.status.astype('category')\n",
    "df_all_build_reports['failed_test_id'] = df_all_build_reports.failed_test_id.astype('category')\n",
    "df_all_build_reports['failed_test_name'] = df_all_build_reports.failed_test_name.astype('category')\n",
    "df_all_build_reports['failed_keyword'] = df_all_build_reports.failed_keyword.astype('category')\n",
    "\n",
    "df_all_build_reports.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_all_build_reports.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "query_robot_reports_extended = f'''\n",
    "SELECT main.timestamp, details.*\n",
    "FROM {table_robot_reports_extended} AS details\n",
    "INNER JOIN {table_known_builds} AS main\n",
    "ON details.job=main.job AND details.build=main.build\n",
    "WHERE main.timestamp>DATETIME(\"{too_old_builds}\")\n",
    "ORDER BY details.job, details.build, details.starttime\n",
    "'''\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    df_all_build_reports_details = pd.read_sql(query_robot_reports_extended, con=conn)\n",
    "\n",
    "# Fixes some special data types\n",
    "df_all_build_reports_details['timestamp'] = pd.to_datetime(df_all_build_reports_details.timestamp)\n",
    "df_all_build_reports_details['job'] = df_all_build_reports_details.job.astype('category')\n",
    "df_all_build_reports_details['suite_id'] = df_all_build_reports_details.suite_id.astype('category')\n",
    "df_all_build_reports_details['suite_name'] = df_all_build_reports_details.suite_name.astype('category')\n",
    "df_all_build_reports_details['test_id'] = df_all_build_reports_details.test_id.astype('category')\n",
    "df_all_build_reports_details['test_name'] = df_all_build_reports_details.test_name.astype('category')\n",
    "df_all_build_reports_details['keyword_name'] = df_all_build_reports_details.keyword_name.astype('category')\n",
    "df_all_build_reports_details['starttime'] = pd.to_datetime(df_all_build_reports_details.starttime)\n",
    "df_all_build_reports_details['endtime'] = pd.to_datetime(df_all_build_reports_details.endtime)\n",
    "df_all_build_reports_details['status'] = df_all_build_reports_details.status.astype('category')\n",
    "\n",
    "df_all_build_reports_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_all_build_reports_details.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Aggregated analysis of stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data = df_known_builds.copy()\n",
    "\n",
    "# Calculates % of passed/failed sub-tests\n",
    "data['pass_pct'] = data.pass_count / (data.pass_count + data.fail_count)\n",
    "data['pass_pct'].fillna(0, inplace=True)\n",
    "data['fail_pct'] = 1 - data.pass_pct\n",
    "data['pass_pct'].fillna(100, inplace=True)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Finding sequences of successful builds and Robot reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data.build_result.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data.test_result.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the cells right above, varios states are possible for the `build_result` and the `test_result` fields:\n",
    "\n",
    "- `build_result` can be: `SUCCESS`, `FAILURE`, `UNSTABLE` or `ABORTED`.\n",
    "- `test_result` can be: `FAIL`, `UNAVAILABLE` or `PASS`.\n",
    "\n",
    "Based on these two states, 3 types of sequences of success/failure can be identified per build or test:\n",
    "\n",
    "1. Successful builds/failed builds in a row: `grp_build_result`.\n",
    "2. Successful test reports vs. test reports with fails in a row: `grp_test_result`.\n",
    "3. Clean builds and tests vs. failures (of any kind) in a row: `grp_success_fail`.\n",
    "\n",
    "For the identification of these sequences, we will need to check these states and values:\n",
    "\n",
    "| Type of sequence   | Relevant state | OK sequence contains    | NOK sequence contains   | Ignore        |\n",
    "|--------------------|----------------|-------------------------|-------------------------|---------------|\n",
    "| `grp_build_result` | `build_result` | `SUCCESS` or `UNSTABLE` | `FAILURE`               | `ABORTED`     |\n",
    "| `grp_test_result`  | `test_result`  | `PASS`                  | `FAIL`                  | `UNAVAILABLE` |\n",
    "| `grp_success_fail` | `test_result`  | `PASS`                  | `FAIL` or `UNAVAILABLE` | N/A           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detects different grouping of segments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def find_sequence(column_state, test4different, ignored_value='DOES_NOT_EXIST'):\n",
    "    # Determine which rows might lead to a change of sequence (i.e. those that won't be ignored)\n",
    "    relevant_rows = (column_state!=ignored_value)\n",
    "\n",
    "    # Creates an empty series with the same index as source series, \"column_state\"\n",
    "    differences = pd.Series(index=column_state.index, dtype='boolean')\n",
    "\n",
    "    # Tests if two consecutive relevant rows can be considered \"different\". If so, marks the row as \"True\"\n",
    "    differences.loc[relevant_rows] = test4different(column_state.loc[relevant_rows], column_state.loc[relevant_rows].shift())\n",
    "\n",
    "    # Irrelevant rows cannot lead to any change. Therefore, they will be marked as \"False\"\n",
    "    differences.loc[~relevant_rows] = False\n",
    "\n",
    "    # Each sequence will be given a different number as a result of a cumulative sum\n",
    "    return differences.cumsum().astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 1. Sequences for successful builds / failed builds in a row: `grp_build_result`\n",
    "def test_grp_build_result(a, b):\n",
    "    return (a!=b) & ((a=='FAILURE') | (b=='FAILURE'))\n",
    "\n",
    "# 2. Successful test reports vs. test reports with fails in a row: `grp_test_result`\n",
    "def test_grp_test_result(a, b):\n",
    "    return (a!=b)\n",
    "\n",
    "# 3. Clean builds and tests vs. failures (of any kind) in a row: `grp_success_fail`\n",
    "def test_grp_success_fail(a, b):\n",
    "    return (a!=b) & ((a=='PASS') | (b=='PASS'))\n",
    "\n",
    "jobs = data.job.unique().tolist()\n",
    "for job in jobs:\n",
    "    job_data = data.loc[data.job==job, 'build_result']\n",
    "    data.loc[data.job==job, 'grp_build_result'] = find_sequence(job_data, test_grp_build_result, ignored_value='ABORTED')\n",
    "    job_data = data.loc[data.job==job, 'test_result']\n",
    "    data.loc[data.job==job, 'grp_test_result'] = find_sequence(job_data, test_grp_test_result, ignored_value='UNAVAILABLE')\n",
    "    data.loc[data.job==job, 'grp_success_fail'] = find_sequence(job_data, test_grp_success_fail)\n",
    "\n",
    "data[data.job==job].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determines the length of sequences of success or failure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function that summarizes sequences of good results in a row (or with something wrong in a row)\n",
    "def summarize_sequence(data, grouped_columns, aggregations_dict):\n",
    "    sequence_summary = data.groupby(by=grouped_columns).agg(aggregations_dict).dropna().reset_index()\n",
    "    \n",
    "    # Flattens multi-level columns\n",
    "    sequence_summary.columns = ['_'.join((col[1], col[0])) if col[1] else col[0] for col in sequence_summary.columns.values]\n",
    "\n",
    "    return sequence_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Summarizes the 3 types of sequences in different tables\n",
    "\n",
    "def agg_build_result(x):\n",
    "    # If at least one in the sequence is 'FAILURE', the whole sequence is in failure\n",
    "    test = (x=='FAILURE')\n",
    "    return 'FAILURE' if test.sum() else 'SUCCESS'\n",
    "\n",
    "def agg_test_result(x):\n",
    "    # If at least one in the sequence is 'FAIL', the whole sequence is failing tests\n",
    "    test = (x=='FAIL')\n",
    "    return 'FAIL' if test.sum() else 'PASS'\n",
    "\n",
    "def agg_success_fail(x):\n",
    "    # If at least one in the sequence is 'PASS', the whole sequence is passing tests\n",
    "    test = (x=='PASS')\n",
    "    return 'PASS' if test.sum() else 'FAIL'\n",
    "\n",
    "sequence_build_result = summarize_sequence(data, \n",
    "                            grouped_columns=['job', 'grp_build_result'],\n",
    "                            aggregations_dict={'timestamp': ['min', 'max'], 'build': ['min', 'max'], 'build_result': agg_build_result}).rename(columns={agg_build_result.__name__+'_build_result': 'build_result'})\n",
    "sequence_test_result = summarize_sequence(data, \n",
    "                            grouped_columns=['job', 'grp_test_result'],\n",
    "                            aggregations_dict={'timestamp': ['min', 'max'], 'build': ['min', 'max'], 'test_result': agg_test_result}).rename(columns={agg_test_result.__name__+'_test_result': 'test_result'})\n",
    "sequence_success_fail = summarize_sequence(data, \n",
    "                            grouped_columns=['job', 'grp_success_fail'],\n",
    "                            aggregations_dict={'timestamp': ['min', 'max'], 'build': ['min', 'max'], 'test_result': agg_success_fail}).rename(columns={agg_success_fail.__name__+'_test_result': 'success_fail'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#sequence_build_result\n",
    "#sequence_test_result\n",
    "sequence_success_fail.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extends the length of each sequence up to the beginning of the next sequence, when applicable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def extend_sequence_length(min_timestamp, max_timestamp):\n",
    "    # Assumes the entry series are already filtered by job\n",
    "    df = pd.DataFrame({'min_timestamp': min_timestamp, 'next_timestamp': min_timestamp.shift(-1), 'max_timestamp': max_timestamp})\n",
    "    return df.max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for job in jobs:\n",
    "    sequence_build_result.loc[sequence_build_result.job==job, 'max_timestamp'] = extend_sequence_length(\n",
    "                                                                                sequence_build_result.loc[sequence_build_result.job==job, 'min_timestamp'], \n",
    "                                                                                sequence_build_result.loc[sequence_build_result.job==job, 'max_timestamp']\n",
    "                                                                                )\n",
    "    sequence_test_result.loc[sequence_test_result.job==job, 'max_timestamp'] = extend_sequence_length(\n",
    "                                                                                sequence_test_result.loc[sequence_test_result.job==job, 'min_timestamp'], \n",
    "                                                                                sequence_test_result.loc[sequence_test_result.job==job, 'max_timestamp']\n",
    "                                                                                )\n",
    "    sequence_success_fail.loc[sequence_success_fail.job==job, 'max_timestamp'] = extend_sequence_length(\n",
    "                                                                                sequence_success_fail.loc[sequence_success_fail.job==job, 'min_timestamp'], \n",
    "                                                                                sequence_success_fail.loc[sequence_success_fail.job==job, 'max_timestamp']\n",
    "                                                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sequence_success_fail.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Finding sequences of pass/fails per test suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "test_suites_data = df_all_build_reports.copy().drop(columns=['source'])\n",
    "test_suites_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Detects grouping per sequence:\n",
    "jobs = test_suites_data.job.unique().tolist()\n",
    "for job in jobs:\n",
    "    suite_ids = test_suites_data.loc[test_suites_data.job==job, 'id'].unique().tolist()\n",
    "    for id in suite_ids:\n",
    "        cond = (test_suites_data.job==job) & (test_suites_data.id==id)\n",
    "\n",
    "        job_test_suites_data = test_suites_data.loc[cond, 'status']\n",
    "        test_suites_data.loc[cond, 'grp_test_result'] = find_sequence(job_test_suites_data, test_grp_test_result, ignored_value='UNAVAILABLE')\n",
    "\n",
    "test_suites_data[cond].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Summarizes the sequences\n",
    "sequence_test_suites = summarize_sequence(test_suites_data, \n",
    "                            grouped_columns=['job', 'id', 'name', 'grp_test_result'],\n",
    "                            aggregations_dict={'timestamp': ['min', 'max'], 'build': ['min', 'max'], 'status': agg_test_result}).rename(columns={agg_test_result.__name__+'_status': 'test_result'})\n",
    "\n",
    "#sequence_test_suites[(sequence_test_suites.job==job) & (sequence_test_suites.id==id)]\n",
    "sequence_test_suites[(sequence_test_suites.job==job) & (sequence_test_suites.id=='s1-s32')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Extends the sequence lenghts up to the beginning of the next sequence, when applicable\n",
    "jobs = sequence_test_suites.job.unique().tolist()\n",
    "for job in jobs:\n",
    "    suite_ids = sequence_test_suites.loc[sequence_test_suites.job==job, 'id'].unique().tolist()\n",
    "    for id in suite_ids:\n",
    "        cond = (sequence_test_suites.job==job) & (sequence_test_suites.id==id)\n",
    "        sequence_test_suites.loc[cond, 'max_timestamp'] = extend_sequence_length(\n",
    "                                                          sequence_test_suites.loc[cond, 'min_timestamp'], \n",
    "                                                          sequence_test_suites.loc[cond, 'max_timestamp']\n",
    "                                                          )\n",
    "#sequence_test_suites[(sequence_test_suites.job==job) & (sequence_test_suites.id==id)]\n",
    "sequence_test_suites[(sequence_test_suites.job==job) & (sequence_test_suites.id=='s1-s32')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Aggregated success rate por test step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Rel NINE branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data_filtered = data[data.job=='osm-stage_3-merge/v9.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_aggregated_success_rate(data_filtered, title, filename=None):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (12,6))\n",
    "\n",
    "    t = data_filtered.timestamp\n",
    "    pass_pct = 100 * data_filtered.pass_pct\n",
    "    fail_pct = 100 * data_filtered.fail_pct\n",
    "    unavailable = (data_filtered.test_result=='UNAVAILABLE')*100\n",
    "\n",
    "    ax.fill_between(t, fail_pct+pass_pct, pass_pct, color='red', alpha=0.5, label='Failed')\n",
    "    ax.fill_between(t, pass_pct, color='lime', alpha=0.5, label='Passed')\n",
    "    ax.fill_between(t, unavailable, color='dimgray', label='Unsuccessful builds')\n",
    "    ax.axhline(100, color='black', linewidth=2, linestyle='--')\n",
    "\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.legend(fontsize=12, fancybox=True, shadow=True, borderpad=1, bbox_to_anchor = (1, 1))\n",
    "    #ax.legend(fontsize=12, fancybox=True, shadow=True, borderpad=1, bbox_to_anchor = (0.32, 0.4))\n",
    "    fig.autofmt_xdate()\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if (filename):\n",
    "        fig.savefig(filename + '.png', dpi=300)\n",
    "        fig.savefig(filename + '.svg')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_aggregated_success_rate(data_filtered,\n",
    "    'Release NINE - % of successful test steps ('+ today + ')',\n",
    "    os.path.join(outputs_folder, 'fully_successful_builds_v9'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 `master` branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data_filtered = data[data.job=='osm-stage_3-merge/master']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_aggregated_success_rate(data_filtered,\n",
    "    'Master branch - % of successful test steps ('+ today + ')',\n",
    "    os.path.join(outputs_folder, 'fully_successful_builds_master'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Analysis of builds and Robot tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Release NINE branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.1.1 Success of Jenking builds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_aggregated_builds_and_tests(data_filtered, state_col, title, ok_states, nok_states, filename=None):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (12,6))\n",
    "\n",
    "    for index, row in data_filtered.iterrows():\n",
    "        #color = 'red' if row.build_result=='FAILURE' else 'lime'\n",
    "        color = 'red' if row[state_col] in nok_states else 'lime'\n",
    "        ax.axvspan(row.min_timestamp, row.max_timestamp, color=color, alpha=0.5)\n",
    "\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    #ax.legend(fontsize=12, fancybox=True, shadow=True, borderpad=1, bbox_to_anchor = (1, 1))\n",
    "    fig.autofmt_xdate()\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if (filename):\n",
    "        fig.savefig(filename + '.png', dpi=300)\n",
    "        fig.savefig(filename + '.svg')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sequence_build_filtered = sequence_build_result[sequence_build_result.job=='osm-stage_3-merge/v9.0']\n",
    "sequence_build_filtered.iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_aggregated_builds_and_tests(sequence_build_filtered, 'build_result',\n",
    "    'Release NINE branch - build completions and failures ('+ today + ')',\n",
    "    ok_states=['SUCCESS'], nok_states=['FAILURE'],\n",
    "    filename=os.path.join(outputs_folder, 'successful_failed_builds_v9'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "build_durations_filtered = sequence_build_filtered.copy()\n",
    "build_durations_filtered['duration'] = build_durations_filtered.max_timestamp - build_durations_filtered.min_timestamp\n",
    "#build_durations_filtered['duration'] = build_durations_filtered['duration'] / pd.to_timedelta(1, unit='D') # Expressed in days, allowing decimals\n",
    "build_durations_filtered['duration'] = build_durations_filtered['duration'].dt.days\n",
    "\n",
    "build_durations_filtered.drop(columns=['grp_build_result', 'min_timestamp', 'max_timestamp', 'min_build', 'max_build'], inplace=True)\n",
    "#build_durations_filtered.iloc[0:10]\n",
    "\n",
    "builds_ok = build_durations_filtered.loc[build_durations_filtered.build_result=='SUCCESS', 'duration']\n",
    "builds_nok = build_durations_filtered.loc[build_durations_filtered.build_result=='FAILURE', 'duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_density_builds_and_tests(data, title, labels, filename=None):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (12,6))\n",
    "\n",
    "    n_bins = 25\n",
    "    colors = ['green', 'red']\n",
    "    #labels = ['OK', 'NOK']\n",
    "\n",
    "    #ax.hist(data, n_bins, density=True, histtype='bar', color=colors, label=labels)\n",
    "    #ax.hist(data, n_bins, density=True, histtype='bar', rwidth=0.8, label=labels, color=colors)\n",
    "    ax.hist(data, n_bins, density=True, histtype='bar', rwidth=0.8, label=labels, color=colors, alpha=0.5)\n",
    "\n",
    "    #ax.set_title(title, fontsize=20)\n",
    "    fig.suptitle(title, fontsize=20)\n",
    "    ax.set_xlabel('Duration of sequences (days)')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.legend(fontsize=12, fancybox=True, shadow=True, borderpad=1, bbox_to_anchor = (1, 1))\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if (filename):\n",
    "        fig.savefig(filename + '.png', dpi=300)\n",
    "        fig.savefig(filename + '.svg')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_density_builds_and_tests(data=[builds_ok, builds_nok],\n",
    "                              title='Rel NINE branch - Histogram of durations of build states (failure/success) ('+ today + ')',\n",
    "                              labels=['SUCCESS', 'FAILURE'],\n",
    "                              filename=os.path.join(outputs_folder, 'density_build_success_failure_v9'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_kde_builds_and_tests(data, x, hue, colors, title, filename=None):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (12,6))\n",
    "\n",
    "    sns.kdeplot(data=data,\n",
    "                x=x, hue=hue,\n",
    "                cut=0, bw_adjust=0.2,\n",
    "                palette=colors, fill=True, alpha=0.4,\n",
    "                ax=ax)\n",
    "\n",
    "    fig.suptitle(title, fontsize=20)\n",
    "    ax.set_xlabel('Duration of sequences (days)')\n",
    "\n",
    "    if filename:\n",
    "        fig.savefig(filename + '.png', dpi=300)\n",
    "        fig.savefig(filename + '.svg')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_kde_builds_and_tests(data=build_durations_filtered,\n",
    "                          x='duration', hue='build_result', colors=['red', 'green'],\n",
    "                          title='Rel NINE branch - KDE of durations of build states (failure/success) ('+ today + ')',\n",
    "                          filename=os.path.join(outputs_folder, 'kde_build_success_failure_v9'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.1.2 Success of Robot tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sequence_test_filtered = sequence_test_result[sequence_test_result.job=='osm-stage_3-merge/v9.0']\n",
    "sequence_test_filtered.iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_aggregated_builds_and_tests(sequence_test_filtered, 'test_result',\n",
    "    'Rel NINE branch - Robot tests status ('+ today + ')',\n",
    "    ok_states=['PASS'], nok_states=['FAIL'],\n",
    "    filename=os.path.join(outputs_folder, 'global_robot_status_v9'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "test_durations_filtered = sequence_test_filtered.copy()\n",
    "test_durations_filtered['duration'] = test_durations_filtered.max_timestamp - test_durations_filtered.min_timestamp\n",
    "#test_durations_filtered['duration'] = test_durations_filtered['duration'] / pd.to_timedelta(1, unit='D') # Expressed in days, allowing decimals\n",
    "test_durations_filtered['duration'] = test_durations_filtered['duration'].dt.days\n",
    "\n",
    "test_durations_filtered.drop(columns=['grp_test_result', 'min_timestamp', 'max_timestamp', 'min_build', 'max_build'], inplace=True)\n",
    "#test_durations_filtered.iloc[0:10]\n",
    "\n",
    "builds_ok = test_durations_filtered.loc[test_durations_filtered.test_result=='PASS', 'duration']\n",
    "builds_nok = test_durations_filtered.loc[test_durations_filtered.test_result=='FAIL', 'duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_density_builds_and_tests(data=[builds_ok, builds_nok],\n",
    "                              title='Rel NINE branch - Histogram of sequences of passed/failed Robot tests ('+ today + ')',\n",
    "                              labels=['PASS', 'FAIL'],\n",
    "                              filename=os.path.join(outputs_folder, 'density_robot_success_failure_v9'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_kde_builds_and_tests(data=test_durations_filtered,\n",
    "                          x='duration', hue='test_result', colors=['green', 'red'],\n",
    "                          title='Rel NINE branch - KDE of sequences of passed/failed Robot tests ('+ today + ')',\n",
    "                          filename=os.path.join(outputs_folder, 'kde_robot_success_failure_v9'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.1.3 Overall success (both build and Robot are ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sequence_success_filtered = sequence_success_fail[sequence_success_fail.job=='osm-stage_3-merge/v9.0']\n",
    "sequence_success_filtered.iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_aggregated_builds_and_tests(sequence_success_filtered, 'success_fail',\n",
    "    'Rel NINE branch - Stability for point release ('+ today + ')',\n",
    "    ok_states=['PASS'], nok_states=['FAIL'],\n",
    "    filename=os.path.join(outputs_folder, 'global_stability_status_v9'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "success_durations_filtered = sequence_success_filtered.copy()\n",
    "success_durations_filtered['duration'] = success_durations_filtered.max_timestamp - success_durations_filtered.min_timestamp\n",
    "#success_durations_filtered['duration'] = success_durations_filtered['duration'] / pd.to_timedelta(1, unit='D') # Expressed in days, allowing decimals\n",
    "success_durations_filtered['duration'] = success_durations_filtered['duration'].dt.days\n",
    "\n",
    "success_durations_filtered.drop(columns=['grp_success_fail', 'min_timestamp', 'max_timestamp', 'min_build', 'max_build'], inplace=True)\n",
    "#success_durations_filtered.iloc[0:10]\n",
    "\n",
    "builds_ok = success_durations_filtered.loc[success_durations_filtered.success_fail=='PASS', 'duration']\n",
    "builds_nok = success_durations_filtered.loc[success_durations_filtered.success_fail=='FAIL', 'duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_density_builds_and_tests(data=[builds_ok, builds_nok],\n",
    "                              title='Rel NINE branch - Histogram of durations of global success ('+ today + ')',\n",
    "                              labels=['SUCCESS', 'FAILURE'],\n",
    "                              filename=os.path.join(outputs_folder, 'density_global_success_failure_v9'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_kde_builds_and_tests(data=success_durations_filtered,\n",
    "                          x='duration', hue='success_fail', colors=['red', 'green'],\n",
    "                          title='Rel NINE branch - KDE of durations of global success ('+ today + ')',\n",
    "                          filename=os.path.join(outputs_folder, 'kde_global_success_failure_v9'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.1.4 Builds completions and Robot status vs. Overall success (comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_aggregated_stability_sequences(sequences, state_cols, titles, ok_states, nok_states, text=None, suptitle=None, filename=None, figsize=(14,8), tight=False):\n",
    "\n",
    "    #fig, ax = plt.subplots(nrows=3, sharex=True, figsize = (14,8))\n",
    "    fig, ax = plt.subplots(nrows=len(sequences), sharex=True, figsize=figsize)\n",
    "\n",
    "    for i in range(len(sequences)):\n",
    "        for index, row in sequences[i].iterrows():\n",
    "            color = 'red' if row[state_cols[i]] in nok_states[i] else 'lime'\n",
    "            ax[i].axvspan(row.min_timestamp, row.max_timestamp, color=color, alpha=0.5)\n",
    "            if text:\n",
    "                ax[i].text(0.5, 0.5, text[i], dict(size=14),\n",
    "                           horizontalalignment='center', verticalalignment='center', transform=ax[i].transAxes, rasterized=False)\n",
    "\n",
    "        if not text:\n",
    "            ax[i].set_title(titles[i], fontsize=16)\n",
    "        ax[i].set_yticklabels([])\n",
    "        #ax[i].legend(fontsize=12, fancybox=True, shadow=True, borderpad=1, bbox_to_anchor = (1, 1))\n",
    "\n",
    "    fig.autofmt_xdate()\n",
    "\n",
    "    if tight:\n",
    "        fig.tight_layout()\n",
    "    if suptitle:\n",
    "        fig.suptitle(suptitle, fontsize=22)\n",
    "\n",
    "    if (filename):\n",
    "        fig.savefig(filename + '.png', dpi=300)\n",
    "        fig.savefig(filename + '.svg')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_aggregated_stability_sequences(sequences=[sequence_build_filtered, sequence_test_filtered, sequence_success_filtered],\n",
    "                                    state_cols=['build_result', 'test_result', 'success_fail'],\n",
    "                                    titles=['Build completions and failures',\n",
    "                                           'Robot tests status',\n",
    "                                           'Stability for point release'],\n",
    "                                    suptitle='Release NINE branch ('+ today + ')\\n',\n",
    "                                    ok_states=[['SUCCESS'], ['PASS'], ['PASS']],\n",
    "                                    nok_states=[['FAILURE'], ['FAIL'], ['FAIL']],\n",
    "                                    filename=os.path.join(outputs_folder, 'global_compared_stability_status_v9'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.1.5 Sequences of pass/fails per test suites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sequence_suites_filtered = sequence_test_suites[sequence_test_suites.job=='osm-stage_3-merge/v9.0']\n",
    "sequence_suites_filtered.iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sequences = []\n",
    "suites = sequence_suites_filtered.sort_values('name')['name'].unique().tolist()\n",
    "for suite in suites:\n",
    "    sequences.append(sequence_suites_filtered.loc[sequence_suites_filtered.name==suite])\n",
    "\n",
    "sequences[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "n_suites = len(sequences)\n",
    "state_cols = ['test_result'] * n_suites\n",
    "ok_states = ['PASS'] * n_suites\n",
    "nok_states = ['FAIL'] * n_suites\n",
    "len(state_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "text = suites\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_aggregated_stability_sequences(sequences=sequences,\n",
    "                                    state_cols=state_cols,\n",
    "                                    titles= [''] * n_suites,\n",
    "                                    text=text,\n",
    "                                    suptitle='Release NINE branch ('+ today + ')',\n",
    "                                    ok_states=ok_states,\n",
    "                                    nok_states=nok_states,\n",
    "                                    filename=os.path.join(outputs_folder, 'success_per_test_suite_status_v9'),\n",
    "                                    figsize=(18,16),\n",
    "                                    tight=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sequence_suites_filtered.job.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "duration_suites_filtered = sequence_suites_filtered.copy()\n",
    "duration_suites_filtered['duration'] = duration_suites_filtered.max_timestamp - duration_suites_filtered.min_timestamp\n",
    "#duration_suites_filtered.drop(columns=['grp_test_result', 'min_timestamp', 'max_timestamp', 'min_build', 'max_build'], inplace=True)\n",
    "duration_suites_filtered.drop(columns=['id', 'grp_test_result', 'min_timestamp', 'max_timestamp', 'min_build', 'max_build'], inplace=True)\n",
    "duration_suites_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#suites_success = duration_suites_filtered.groupby(by=['job', 'id', 'name', 'test_result']).sum().reset_index()\n",
    "suites_success = duration_suites_filtered.groupby(by=['job', 'name', 'test_result']).sum().reset_index()\n",
    "suites_success.duration = pd.to_timedelta(suites_success.duration)\n",
    "suites_success = suites_success[suites_success.job=='osm-stage_3-merge/v9.0']\n",
    "#suites_success = suites_success.set_index(['job', 'id', 'name', 'test_result'])\n",
    "suites_success = suites_success.set_index(['job', 'name', 'test_result'])\n",
    "#suites_success.columns.droplevel(level=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "suites_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#fail_pass_durations_per_suite = suites_success.unstack().reset_index().drop(columns=['job'])\n",
    "fail_pass_durations_per_suite = suites_success.unstack().reset_index()\n",
    "fail_pass_durations_per_suite.columns = ['_'.join(col) if col[1] else col[0] for col in fail_pass_durations_per_suite.columns]\n",
    "fail_pass_durations_per_suite.drop(columns=['job'], inplace=True)\n",
    "# fail_pass_durations_per_suite['duration_FAIL'] = fail_pass_durations_per_suite['duration_FAIL'] / pd.Timedelta(days=1)\n",
    "# fail_pass_durations_per_suite['duration_PASS'] = fail_pass_durations_per_suite['duration_PASS'] / pd.Timedelta(days=1)\n",
    "fail_pass_durations_per_suite['duration_FAIL'] = fail_pass_durations_per_suite['duration_FAIL'].dt.days\n",
    "fail_pass_durations_per_suite['duration_PASS'] = fail_pass_durations_per_suite['duration_PASS'].dt.days\n",
    "\n",
    "#fail_pass_durations_per_suite = fail_pass_durations_per_suite.sort_values(by='duration_FAIL', ascending=False)\n",
    "fail_pass_durations_per_suite = fail_pass_durations_per_suite.sort_values(by='duration_FAIL')\n",
    "fail_pass_durations_per_suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_days_suites_ok_nok(suites, days_failing, days_passing, title, filename=None):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (12,16))\n",
    "\n",
    "    plt.barh(suites, days_failing, color='red', alpha=0.5, label='Failing')\n",
    "    plt.barh(suites, days_passing, color='lime', alpha=0.5, left=days_failing, label='Passing')\n",
    "\n",
    "    #ax.set_title(title, fontsize=20)\n",
    "    fig.suptitle(title, fontsize=20)\n",
    "    ax.set_xlabel('Number of days')\n",
    "    #ax.legend(fontsize=12, fancybox=True, shadow=True, borderpad=1, bbox_to_anchor = (1, 1))\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if (filename):\n",
    "        fig.savefig(filename + '.png', dpi=300)\n",
    "        fig.savefig(filename + '.svg')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_days_suites_ok_nok(suites=fail_pass_durations_per_suite.name,\n",
    "                        days_failing=fail_pass_durations_per_suite.duration_FAIL,\n",
    "                        days_passing=fail_pass_durations_per_suite.duration_PASS,\n",
    "                        title='Release NINE - Failing days per test suite ('+ today + ')',\n",
    "                        filename=os.path.join(outputs_folder, 'failing_days_per_suite_v9'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 Master branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "reference_job = 'osm-stage_3-merge/master'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.2.1 Success of Jenking builds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sequence_build_filtered = sequence_build_result[sequence_build_result.job==reference_job]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_aggregated_builds_and_tests(sequence_build_filtered, 'build_result',\n",
    "    'Master branch - build completions and failures ('+ today + ')',\n",
    "    ok_states=['SUCCESS'], nok_states=['FAILURE'],\n",
    "    filename=os.path.join(outputs_folder, 'successful_failed_builds_master'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "build_durations_filtered = sequence_build_filtered.copy()\n",
    "build_durations_filtered['duration'] = build_durations_filtered.max_timestamp - build_durations_filtered.min_timestamp\n",
    "build_durations_filtered['duration'] = build_durations_filtered['duration'].dt.days\n",
    "\n",
    "build_durations_filtered.drop(columns=['grp_build_result', 'min_timestamp', 'max_timestamp', 'min_build', 'max_build'], inplace=True)\n",
    "\n",
    "builds_ok = build_durations_filtered.loc[build_durations_filtered.build_result=='SUCCESS', 'duration']\n",
    "builds_nok = build_durations_filtered.loc[build_durations_filtered.build_result=='FAILURE', 'duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_density_builds_and_tests(data=[builds_ok, builds_nok],\n",
    "                              title='Master branch - Histogram of durations of build states (failure/success) ('+ today + ')',\n",
    "                              labels=['SUCCESS', 'FAILURE'],\n",
    "                              filename=os.path.join(outputs_folder, 'density_build_success_failure_master'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_kde_builds_and_tests(data=build_durations_filtered,\n",
    "                          x='duration', hue='build_result', colors=['red', 'green'],\n",
    "                          title='Master branch - KDE of durations of build states (failure/success) ('+ today + ')',\n",
    "                          filename=os.path.join(outputs_folder, 'kde_build_success_failure_master'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.2.2 Success of Robot tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sequence_test_filtered = sequence_test_result[sequence_test_result.job==reference_job]\n",
    "sequence_test_filtered.iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_aggregated_builds_and_tests(sequence_test_filtered, 'test_result',\n",
    "    'Master branch - Robot tests status ('+ today + ')',\n",
    "    ok_states=['PASS'], nok_states=['FAIL'],\n",
    "    filename=os.path.join(outputs_folder, 'global_robot_status_master'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "test_durations_filtered = sequence_test_filtered.copy()\n",
    "test_durations_filtered['duration'] = test_durations_filtered.max_timestamp - test_durations_filtered.min_timestamp\n",
    "test_durations_filtered['duration'] = test_durations_filtered['duration'].dt.days\n",
    "\n",
    "test_durations_filtered.drop(columns=['grp_test_result', 'min_timestamp', 'max_timestamp', 'min_build', 'max_build'], inplace=True)\n",
    "\n",
    "builds_ok = test_durations_filtered.loc[test_durations_filtered.test_result=='PASS', 'duration']\n",
    "builds_nok = test_durations_filtered.loc[test_durations_filtered.test_result=='FAIL', 'duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_density_builds_and_tests(data=[builds_ok, builds_nok],\n",
    "                              title='Master branch - Histogram of sequences of passed/failed Robot tests ('+ today + ')',\n",
    "                              labels=['PASS', 'FAIL'],\n",
    "                              filename=os.path.join(outputs_folder, 'density_robot_success_failure_master'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_kde_builds_and_tests(data=test_durations_filtered,\n",
    "                          x='duration', hue='test_result', colors=['green', 'red'],\n",
    "                          title='Master branch - KDE of sequences of passed/failed Robot tests ('+ today + ')',\n",
    "                          filename=os.path.join(outputs_folder, 'kde_robot_success_failure_master'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.2.3 Overall success (both build and Robot are ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sequence_success_filtered = sequence_success_fail[sequence_success_fail.job==reference_job]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_aggregated_builds_and_tests(sequence_success_filtered, 'success_fail',\n",
    "    'Master branch - Stability for point release ('+ today + ')',\n",
    "    ok_states=['PASS'], nok_states=['FAIL'],\n",
    "    filename=os.path.join(outputs_folder, 'global_stability_status_master'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "success_durations_filtered = sequence_success_filtered.copy()\n",
    "success_durations_filtered['duration'] = success_durations_filtered.max_timestamp - success_durations_filtered.min_timestamp\n",
    "success_durations_filtered['duration'] = success_durations_filtered['duration'].dt.days\n",
    "\n",
    "success_durations_filtered.drop(columns=['grp_success_fail', 'min_timestamp', 'max_timestamp', 'min_build', 'max_build'], inplace=True)\n",
    "\n",
    "builds_ok = success_durations_filtered.loc[success_durations_filtered.success_fail=='PASS', 'duration']\n",
    "builds_nok = success_durations_filtered.loc[success_durations_filtered.success_fail=='FAIL', 'duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_density_builds_and_tests(data=[builds_ok, builds_nok],\n",
    "                              title='Master branch - Histogram of durations of global success ('+ today + ')',\n",
    "                              labels=['SUCCESS', 'FAILURE'],\n",
    "                              filename=os.path.join(outputs_folder, 'density_global_success_failure_master'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_kde_builds_and_tests(data=success_durations_filtered,\n",
    "                          x='duration', hue='success_fail', colors=['red', 'green'],\n",
    "                          title='Master branch - KDE of durations of global success ('+ today + ')',\n",
    "                          filename=os.path.join(outputs_folder, 'kde_global_success_failure_master'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.2.4 Builds completions and Robot status vs. Overall success (comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_aggregated_stability_sequences(sequences=[sequence_build_filtered, sequence_test_filtered, sequence_success_filtered],\n",
    "                                    state_cols=['build_result', 'test_result', 'success_fail'],\n",
    "                                    titles=['Build completions and failures',\n",
    "                                           'Robot tests status',\n",
    "                                           'Stability for point release'],\n",
    "                                    suptitle='Master branch ('+ today + ')\\n',\n",
    "                                    ok_states=[['SUCCESS'], ['PASS'], ['PASS']],\n",
    "                                    nok_states=[['FAILURE'], ['FAIL'], ['FAIL']],\n",
    "                                    filename=os.path.join(outputs_folder, 'global_compared_stability_status_master'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.2.5 Sequences of pass/fails per test suites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sequence_suites_filtered = sequence_test_suites[sequence_test_suites.job==reference_job]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sequences = []\n",
    "suites = sequence_suites_filtered.sort_values('name')['name'].unique().tolist()\n",
    "for suite in suites:\n",
    "    sequences.append(sequence_suites_filtered.loc[sequence_suites_filtered.name==suite])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "text = suites\n",
    "n_suites = len(sequences)\n",
    "state_cols = ['test_result'] * n_suites\n",
    "ok_states = ['PASS'] * n_suites\n",
    "nok_states = ['FAIL'] * n_suites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_aggregated_stability_sequences(sequences=sequences,\n",
    "                                    state_cols=state_cols,\n",
    "                                    titles= [''] * n_suites,\n",
    "                                    text=text,\n",
    "                                    suptitle='Master branch ('+ today + ')',\n",
    "                                    ok_states=ok_states,\n",
    "                                    nok_states=nok_states,\n",
    "                                    filename=os.path.join(outputs_folder, 'success_per_test_suite_status_master'),\n",
    "                                    figsize=(18,16),\n",
    "                                    tight=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "duration_suites_filtered = sequence_suites_filtered.copy()\n",
    "duration_suites_filtered['duration'] = duration_suites_filtered.max_timestamp - duration_suites_filtered.min_timestamp\n",
    "duration_suites_filtered.drop(columns=['id', 'grp_test_result', 'min_timestamp', 'max_timestamp', 'min_build', 'max_build'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "suites_success = duration_suites_filtered.groupby(by=['job', 'name', 'test_result']).sum().reset_index()\n",
    "suites_success.duration = pd.to_timedelta(suites_success.duration)\n",
    "suites_success = suites_success[suites_success.job==reference_job]\n",
    "suites_success = suites_success.set_index(['job', 'name', 'test_result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fail_pass_durations_per_suite = suites_success.unstack().reset_index()\n",
    "fail_pass_durations_per_suite.columns = ['_'.join(col) if col[1] else col[0] for col in fail_pass_durations_per_suite.columns]\n",
    "fail_pass_durations_per_suite.drop(columns=['job'], inplace=True)\n",
    "fail_pass_durations_per_suite['duration_FAIL'] = fail_pass_durations_per_suite['duration_FAIL'].dt.days\n",
    "fail_pass_durations_per_suite['duration_PASS'] = fail_pass_durations_per_suite['duration_PASS'].dt.days\n",
    "\n",
    "fail_pass_durations_per_suite = fail_pass_durations_per_suite.sort_values(by='duration_FAIL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_days_suites_ok_nok(suites=fail_pass_durations_per_suite.name,\n",
    "                        days_failing=fail_pass_durations_per_suite.duration_FAIL,\n",
    "                        days_passing=fail_pass_durations_per_suite.duration_PASS,\n",
    "                        title='Master branch - Failing days per test suite ('+ today + ')',\n",
    "                        filename=os.path.join(outputs_folder, 'failing_days_per_suite_master'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3 Release TEN branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "reference_job = 'osm-stage_3-merge/v10.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.3.1 Success of Jenking builds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sequence_build_filtered = sequence_build_result[sequence_build_result.job==reference_job]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sequence_build_filtered.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_aggregated_builds_and_tests(sequence_build_filtered, 'build_result',\n",
    "    'Release TEN branch - build completions and failures ('+ today + ')',\n",
    "    ok_states=['SUCCESS'], nok_states=['FAILURE'],\n",
    "    filename=os.path.join(outputs_folder, 'successful_failed_builds_v10'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "build_durations_filtered = sequence_build_filtered.copy()\n",
    "build_durations_filtered['duration'] = build_durations_filtered.max_timestamp - build_durations_filtered.min_timestamp\n",
    "build_durations_filtered['duration'] = build_durations_filtered['duration'].dt.days\n",
    "\n",
    "build_durations_filtered.drop(columns=['grp_build_result', 'min_timestamp', 'max_timestamp', 'min_build', 'max_build'], inplace=True)\n",
    "\n",
    "builds_ok = build_durations_filtered.loc[build_durations_filtered.build_result=='SUCCESS', 'duration']\n",
    "builds_nok = build_durations_filtered.loc[build_durations_filtered.build_result=='FAILURE', 'duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_density_builds_and_tests(data=[builds_ok, builds_nok],\n",
    "                              title='Release TEN branch - Histogram of durations of build states (failure/success) ('+ today + ')',\n",
    "                              labels=['SUCCESS', 'FAILURE'],\n",
    "                              filename=os.path.join(outputs_folder, 'density_build_success_failure_v10'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_kde_builds_and_tests(data=build_durations_filtered,\n",
    "                          x='duration', hue='build_result', colors=['red', 'green'],\n",
    "                          title='Release TEN branch - KDE of durations of build states (failure/success) ('+ today + ')',\n",
    "                          filename=os.path.join(outputs_folder, 'kde_build_success_failure_v10'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.3.2 Success of Robot tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sequence_test_filtered = sequence_test_result[sequence_test_result.job==reference_job]\n",
    "sequence_test_filtered.iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_aggregated_builds_and_tests(sequence_test_filtered, 'test_result',\n",
    "    'Release TEN branch - Robot tests status ('+ today + ')',\n",
    "    ok_states=['PASS'], nok_states=['FAIL'],\n",
    "    filename=os.path.join(outputs_folder, 'global_robot_status_v10'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "test_durations_filtered = sequence_test_filtered.copy()\n",
    "test_durations_filtered['duration'] = test_durations_filtered.max_timestamp - test_durations_filtered.min_timestamp\n",
    "test_durations_filtered['duration'] = test_durations_filtered['duration'].dt.days\n",
    "\n",
    "test_durations_filtered.drop(columns=['grp_test_result', 'min_timestamp', 'max_timestamp', 'min_build', 'max_build'], inplace=True)\n",
    "\n",
    "builds_ok = test_durations_filtered.loc[test_durations_filtered.test_result=='PASS', 'duration']\n",
    "builds_nok = test_durations_filtered.loc[test_durations_filtered.test_result=='FAIL', 'duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_density_builds_and_tests(data=[builds_ok, builds_nok],\n",
    "                              title='Release TEN branch - Histogram of sequences of passed/failed Robot tests ('+ today + ')',\n",
    "                              labels=['PASS', 'FAIL'],\n",
    "                              filename=os.path.join(outputs_folder, 'density_robot_success_failure_v10'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_kde_builds_and_tests(data=test_durations_filtered,\n",
    "                          x='duration', hue='test_result', colors=['green', 'red'],\n",
    "                          title='Release TEN branch - KDE of sequences of passed/failed Robot tests ('+ today + ')',\n",
    "                          filename=os.path.join(outputs_folder, 'kde_robot_success_failure_v10'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.3.3 Overall success (both build and Robot are ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sequence_success_filtered = sequence_success_fail[sequence_success_fail.job==reference_job]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_aggregated_builds_and_tests(sequence_success_filtered, 'success_fail',\n",
    "    'Release TEN branch - Stability for point release ('+ today + ')',\n",
    "    ok_states=['PASS'], nok_states=['FAIL'],\n",
    "    filename=os.path.join(outputs_folder, 'global_stability_status_v10'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "success_durations_filtered = sequence_success_filtered.copy()\n",
    "success_durations_filtered['duration'] = success_durations_filtered.max_timestamp - success_durations_filtered.min_timestamp\n",
    "success_durations_filtered['duration'] = success_durations_filtered['duration'].dt.days\n",
    "\n",
    "success_durations_filtered.drop(columns=['grp_success_fail', 'min_timestamp', 'max_timestamp', 'min_build', 'max_build'], inplace=True)\n",
    "\n",
    "builds_ok = success_durations_filtered.loc[success_durations_filtered.success_fail=='PASS', 'duration']\n",
    "builds_nok = success_durations_filtered.loc[success_durations_filtered.success_fail=='FAIL', 'duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_density_builds_and_tests(data=[builds_ok, builds_nok],\n",
    "                              title='Release TEN branch - Histogram of durations of global success ('+ today + ')',\n",
    "                              labels=['SUCCESS', 'FAILURE'],\n",
    "                              filename=os.path.join(outputs_folder, 'density_global_success_failure_v10'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_kde_builds_and_tests(data=success_durations_filtered,\n",
    "                          x='duration', hue='success_fail', colors=['red', 'green'],\n",
    "                          title='Release TEN branch - KDE of durations of global success ('+ today + ')',\n",
    "                          filename=os.path.join(outputs_folder, 'kde_global_success_failure_v10'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.3.4 Builds completions and Robot status vs. Overall success (comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# plot_aggregated_stability_sequences(sequences=[sequence_build_result, sequence_test_result, sequence_success_fail],\n",
    "#                                     state_cols=['build_result', 'test_result', 'success_fail'],\n",
    "#                                     titles=['Build completions and failures',\n",
    "#                                            'Robot tests status',\n",
    "#                                            'Stability for point release'],\n",
    "#                                     suptitle='Release TEN branch\\n',\n",
    "#                                     ok_states=[['SUCCESS'], ['PASS'], ['PASS']],\n",
    "#                                     nok_states=[['FAILURE'], ['FAIL'], ['FAIL']],\n",
    "#                                     filename=os.path.join(outputs_folder, 'global_compared_stability_status_v10'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_aggregated_stability_sequences(sequences=[sequence_build_filtered, sequence_test_filtered, sequence_success_filtered],\n",
    "                                    state_cols=['build_result', 'test_result', 'success_fail'],\n",
    "                                    titles=['Build completions and failures',\n",
    "                                           'Robot tests status',\n",
    "                                           'Stability for point release'],\n",
    "                                    suptitle='Release TEN branch ('+ today + ')\\n',\n",
    "                                    ok_states=[['SUCCESS'], ['PASS'], ['PASS']],\n",
    "                                    nok_states=[['FAILURE'], ['FAIL'], ['FAIL']],\n",
    "                                    filename=os.path.join(outputs_folder, 'global_compared_stability_status_v10'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.3.5 Sequences of pass/fails per test suites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sequence_suites_filtered = sequence_test_suites[sequence_test_suites.job==reference_job]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sequences = []\n",
    "suites = sequence_suites_filtered.sort_values('name')['name'].unique().tolist()\n",
    "for suite in suites:\n",
    "    sequences.append(sequence_suites_filtered.loc[sequence_suites_filtered.name==suite])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "text = suites\n",
    "n_suites = len(sequences)\n",
    "state_cols = ['test_result'] * n_suites\n",
    "ok_states = ['PASS'] * n_suites\n",
    "nok_states = ['FAIL'] * n_suites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_aggregated_stability_sequences(sequences=sequences,\n",
    "                                    state_cols=state_cols,\n",
    "                                    titles= [''] * n_suites,\n",
    "                                    text=text,\n",
    "                                    suptitle='Release TEN branch ('+ today + ')',\n",
    "                                    ok_states=ok_states,\n",
    "                                    nok_states=nok_states,\n",
    "                                    filename=os.path.join(outputs_folder, 'success_per_test_suite_status_v10'),\n",
    "                                    figsize=(18,16),\n",
    "                                    tight=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "duration_suites_filtered = sequence_suites_filtered.copy()\n",
    "duration_suites_filtered['duration'] = duration_suites_filtered.max_timestamp - duration_suites_filtered.min_timestamp\n",
    "duration_suites_filtered.drop(columns=['id', 'grp_test_result', 'min_timestamp', 'max_timestamp', 'min_build', 'max_build'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "suites_success = duration_suites_filtered.groupby(by=['job', 'name', 'test_result']).sum().reset_index()\n",
    "suites_success.duration = pd.to_timedelta(suites_success.duration)\n",
    "suites_success = suites_success[suites_success.job==reference_job]\n",
    "suites_success = suites_success.set_index(['job', 'name', 'test_result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fail_pass_durations_per_suite = suites_success.unstack().reset_index()\n",
    "fail_pass_durations_per_suite.columns = ['_'.join(col) if col[1] else col[0] for col in fail_pass_durations_per_suite.columns]\n",
    "fail_pass_durations_per_suite.drop(columns=['job'], inplace=True)\n",
    "fail_pass_durations_per_suite['duration_FAIL'] = fail_pass_durations_per_suite['duration_FAIL'].dt.days\n",
    "fail_pass_durations_per_suite['duration_PASS'] = fail_pass_durations_per_suite['duration_PASS'].dt.days\n",
    "\n",
    "fail_pass_durations_per_suite = fail_pass_durations_per_suite.sort_values(by='duration_FAIL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_days_suites_ok_nok(suites=fail_pass_durations_per_suite.name,\n",
    "                        days_failing=fail_pass_durations_per_suite.duration_FAIL,\n",
    "                        days_passing=fail_pass_durations_per_suite.duration_PASS,\n",
    "                        title='Release TEN branch - Failing days per test suite ('+ today + ')',\n",
    "                        filename=os.path.join(outputs_folder, 'failing_days_per_suite_v10'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osm-analytics",
   "language": "python",
   "name": "osm-analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
