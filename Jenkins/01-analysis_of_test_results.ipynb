{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Robot reports from OSM Jenkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import json\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 0. Input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Default values:\n",
    "\n",
    "inputs_folder = 'etl_outputs'\n",
    "outputs_folder = 'report_outputs'\n",
    "database_uri = f'sqlite:///{inputs_folder}/test_executions.db'\n",
    "\n",
    "table_known_builds = 'builds_info'\n",
    "table_robot_reports = 'robot_reports'\n",
    "table_robot_reports_extended = 'robot_reports_extended'\n",
    "\n",
    "too_old_builds = \"2020-12-15\"\n",
    "\n",
    "# Comment for analysis of all historical data\n",
    "days_since_today_4_analysis = 21\n",
    "\n",
    "# Links to useful locations in Jenkins web (for reference)\n",
    "link_to_build = \"https://osm.etsi.org/jenkins/view/Robot%20tests/job/{stage}/job/{branch}/{build}/\"\n",
    "link_to_report = \"https://osm.etsi.org/jenkins/view/Robot%20tests/job/{stage}/job/{branch}/{build}/robot/report/report.html\"\n",
    "\n",
    "extended_print = False\n",
    "dump_sequences = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_ids = ['v11.0', 'v10.0', 'master', 'v9.0']\n",
    "job_names = ['Master branch', 'Release ELEVEN', 'Release TEN', 'Release NINE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tries to bulk load credentials and other environment variables from .env file:\n",
    "\n",
    "# %%\n",
    "# If the '.env' file exists, loads the environment variables\n",
    "try:\n",
    "    with open('.env', 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            line = line.strip()\n",
    "            key, value = line.split('=')\n",
    "            os.environ[key] = value\n",
    "except FileNotFoundError as e:\n",
    "    print(\"Environment file ('.env') does not exist. Skipping...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifies input parameters based on environment variables (when applicable)\n",
    "skip_database_update = os.environ.get('SKIP_DATABASE_UPDATE', None)\n",
    "skip_export_to_html = os.environ.get('SKIP_EXPORT_TO_HTML', None)\n",
    "database_uri = os.environ.get('DATABASE_URI', None) or database_uri\n",
    "inputs_folder = os.environ.get('INPUTS_FOLDER', None) or inputs_folder\n",
    "outputs_folder = os.environ.get('OUTPUTS_FOLDER', None) or outputs_folder\n",
    "table_known_builds = os.environ.get('TABLE_KNOWN_BUILDS', None) or table_known_builds\n",
    "table_robot_reports = os.environ.get('TABLE_ROBOT_REPORTS', None) or table_robot_reports\n",
    "table_robot_reports_extended = os.environ.get('TABLE_ROBOT_REPORTS_EXTENDED', None) or table_robot_reports_extended\n",
    "link_to_build = os.environ.get('LINK_TO_BUILD', None) or link_to_build\n",
    "link_to_report = os.environ.get('LINK_TO_REPORT', None) or link_to_report\n",
    "too_old_builds = os.environ.get('TOO_OLD_BUILDS', None) or too_old_builds\n",
    "days_since_today_4_analysis = os.environ.get('DAYS_SINCE_TODAY_4_ANALYSIS', None) or days_since_today_4_analysis\n",
    "days_since_today_4_analysis = int(days_since_today_4_analysis)\n",
    "\n",
    "temp_job_ids = os.environ.get('JOB_IDS', None)\n",
    "if temp_job_ids:\n",
    "    job_ids = json.loads(temp_job_ids.replace(\"'\", \"\"))\n",
    "\n",
    "temp_job_names = os.environ.get('JOB_NAMES', None)\n",
    "if temp_job_names:\n",
    "    job_names = json.loads(temp_job_names.replace(\"'\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_jobs = ['osm-stage_3-merge/' + job_id for job_id in job_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "today_as_datetime = pd.to_datetime(\"today\")\n",
    "today = today_as_datetime.strftime('%Y-%m-%d')\n",
    "\n",
    "display(Markdown(f'**Date and time of the report:** {today_as_datetime}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'days_since_today_4_analysis' in locals():\n",
    "    first_date_as_datetime = today_as_datetime - dt.timedelta(days=days_since_today_4_analysis)\n",
    "    first_date = first_date_as_datetime.strftime('%Y-%m-%d')\n",
    "else:\n",
    "    first_date = too_old_builds # Unconstrained\n",
    "\n",
    "last_date = today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case there were specific environment variables, they should override these dates\n",
    "first_date = os.environ.get('FIRST_DATE', None) or first_date\n",
    "last_date = os.environ.get('LAST_DATE', None) or last_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to set the window of analysis manually\n",
    "#\n",
    "# first_date = \"2021-08-01\"\n",
    "# last_date = \"2021-08-20\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f'**Analysed period:** {first_date} to {last_date}.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Retrieval of all currrent data for aggregate analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Database update:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to update the database from this notebook\n",
    "# %run 00-script-jenkins_and_robot_etl.py\n",
    "if skip_database_update:\n",
    "    print('Skipping...')\n",
    "else:\n",
    "    !python ./00-script-jenkins_and_robot_etl.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_known_builds(engine, too_old_builds='1980-12-15'):\n",
    "\n",
    "    query_known_builds = f'SELECT * FROM {table_known_builds} WHERE timestamp>\"{too_old_builds}\"'\n",
    "\n",
    "    with engine.begin() as conn:\n",
    "        df_known_builds = pd.read_sql(query_known_builds, con=conn)\n",
    "\n",
    "    # Fixes some special data types\n",
    "    df_known_builds['timestamp'] = pd.to_datetime(df_known_builds.timestamp)\n",
    "    df_known_builds['job'] = df_known_builds.job.astype('category')\n",
    "    df_known_builds['duration'] = pd.to_timedelta(df_known_builds.duration.astype('float')*1000, unit='us')\n",
    "    df_known_builds['build_result'] = df_known_builds.build_result.astype('category')\n",
    "    df_known_builds['test_result'] = df_known_builds.test_result.astype('category')\n",
    "\n",
    "    return df_known_builds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_build_reports(engine, too_old_builds='1980-12-15'):\n",
    "\n",
    "    query_robot_reports = f'''\n",
    "    SELECT main.timestamp, details.*\n",
    "    FROM {table_robot_reports} AS details\n",
    "    INNER JOIN {table_known_builds} AS main\n",
    "    ON details.job=main.job AND details.build=main.build\n",
    "    WHERE main.timestamp>\"{too_old_builds}\"\n",
    "    ORDER BY details.job, details.build, details.starttime\n",
    "    '''\n",
    "\n",
    "    with engine.begin() as conn:\n",
    "        df_all_build_reports = pd.read_sql(query_robot_reports, con=conn)\n",
    "\n",
    "    # Fixes some special data types\n",
    "    df_all_build_reports['timestamp'] = pd.to_datetime(df_all_build_reports.timestamp)\n",
    "    df_all_build_reports['job'] = df_all_build_reports.job.astype('category')\n",
    "    df_all_build_reports['id'] = df_all_build_reports.id.astype('category')\n",
    "    df_all_build_reports['name'] = df_all_build_reports.name.astype('category')\n",
    "    df_all_build_reports['source'] = df_all_build_reports.source.astype('category')\n",
    "    df_all_build_reports['starttime'] = pd.to_datetime(df_all_build_reports.starttime)\n",
    "    df_all_build_reports['endtime'] = pd.to_datetime(df_all_build_reports.endtime)\n",
    "    df_all_build_reports['status'] = df_all_build_reports.status.astype('category')\n",
    "    df_all_build_reports['failed_test_id'] = df_all_build_reports.failed_test_id.astype('category')\n",
    "    df_all_build_reports['failed_test_name'] = df_all_build_reports.failed_test_name.astype('category')\n",
    "    df_all_build_reports['failed_keyword'] = df_all_build_reports.failed_keyword.astype('category')\n",
    "\n",
    "    return df_all_build_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_build_reports_details(engine, too_old_builds='1980-12-15'):\n",
    "\n",
    "    query_robot_reports_extended = f'''\n",
    "    SELECT main.timestamp, details.*\n",
    "    FROM {table_robot_reports_extended} AS details\n",
    "    INNER JOIN {table_known_builds} AS main\n",
    "    ON details.job=main.job AND details.build=main.build\n",
    "    WHERE main.timestamp>\"{too_old_builds}\"\n",
    "    ORDER BY details.job, details.build, details.starttime\n",
    "    '''\n",
    "\n",
    "    with engine.begin() as conn:\n",
    "        df_all_build_reports_details = pd.read_sql(query_robot_reports_extended, con=conn)\n",
    "\n",
    "    # Fixes some special data types\n",
    "    df_all_build_reports_details['timestamp'] = pd.to_datetime(df_all_build_reports_details.timestamp)\n",
    "    df_all_build_reports_details['job'] = df_all_build_reports_details.job.astype('category')\n",
    "    df_all_build_reports_details['suite_id'] = df_all_build_reports_details.suite_id.astype('category')\n",
    "    df_all_build_reports_details['suite_name'] = df_all_build_reports_details.suite_name.astype('category')\n",
    "    df_all_build_reports_details['test_id'] = df_all_build_reports_details.test_id.astype('category')\n",
    "    df_all_build_reports_details['test_name'] = df_all_build_reports_details.test_name.astype('category')\n",
    "    df_all_build_reports_details['keyword_name'] = df_all_build_reports_details.keyword_name.astype('category')\n",
    "    df_all_build_reports_details['starttime'] = pd.to_datetime(df_all_build_reports_details.starttime)\n",
    "    df_all_build_reports_details['endtime'] = pd.to_datetime(df_all_build_reports_details.endtime)\n",
    "    df_all_build_reports_details['status'] = df_all_build_reports_details.status.astype('category')\n",
    "\n",
    "    return df_all_build_reports_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Retrieving from database...\\t' , end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(database_uri)\n",
    "\n",
    "df_known_builds = load_known_builds(engine, too_old_builds=too_old_builds)\n",
    "df_all_build_reports = load_all_build_reports(engine, too_old_builds=too_old_builds)\n",
    "df_all_build_reports_details = load_all_build_reports_details(engine, too_old_builds=too_old_builds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds columns with % of passed/failed sub-tests\n",
    "df_known_builds = (\n",
    "    df_known_builds\n",
    "    .copy()\n",
    "    .assign(pass_pct = lambda x: x.pass_count / (x.pass_count + x.fail_count))\n",
    "    .fillna({'pass_pct': 0})\n",
    "    .assign(fail_pct = lambda x: 1- x.pass_pct)\n",
    "    .fillna({'fail_pct': 100})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_known_builds.query('test_result==\"PASS\"').groupby('job').last()\n",
    "# df_all_build_reports.info()\n",
    "# df_all_build_reports_details.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Aggregated analysis of stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Restricts data to time window for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenient alias to allow time masks\n",
    "\n",
    "#data = df_known_builds.query('(timestamp>\"2021-08-01\") & (timestamp<\"2021-08-20\")').copy()\n",
    "data = df_known_builds\n",
    "\n",
    "if 'first_date' in locals():\n",
    "    data = data.query('timestamp>=@first_date')\n",
    "\n",
    "if 'last_date' in locals():\n",
    "    # Needs to include latest hour of the last day\n",
    "    last_timestamp = pd.Timestamp(last_date) + dt.timedelta(days=1)\n",
    "    data = data.query('timestamp<@last_timestamp')\n",
    "\n",
    "data = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Finding sequences of successful builds and Robot reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aligns markdown tables to the left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {align:left;display:block}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two values retrieved from the build are key to determine the state of the jubs and test suites at a given moment:\n",
    "\n",
    "- `build_result` is the outcome of the build, reported by Jenkins. It can be: `SUCCESS`, `FAILURE`, `UNSTABLE` or `ABORTED`.\n",
    "- `test_result` is the summary of the concerned Robot tests. It can be: `FAIL`, `UNAVAILABLE` or `PASS`.\n",
    "\n",
    "Based on these two states, 3 types of temporal sequences of success/failure are identified per builds and test suites:\n",
    "\n",
    "1. Successful builds/failed builds in a row: `grp_build_result`.\n",
    "2. Successful test reports vs. test reports with fails in a row: `grp_test_result`.\n",
    "3. Clean builds and tests vs. failures (of any kind) in a row: `grp_success_fail`.\n",
    "\n",
    "For the identification of these sequences, the following mapping applies:\n",
    "\n",
    "| Type of sequence   | Relevant state | OK sequence contains    | NOK sequence contains   | Ignore        |\n",
    "|--------------------|----------------|-------------------------|-------------------------|---------------|\n",
    "| `grp_build_result` | `build_result` | `SUCCESS` or `UNSTABLE` | `FAILURE`               | `ABORTED`     |\n",
    "| `grp_test_result`  | `test_result`  | `PASS`                  | `FAIL`                  | `UNAVAILABLE` |\n",
    "| `grp_success_fail` | `test_result`  | `PASS`                  | `FAIL` or `UNAVAILABLE` | N/A           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different groupings of segments are detected and a label is added to each sample..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_build_result = {\n",
    "    'SUCCESS': True,\n",
    "    'UNSTABLE': True,\n",
    "    'FAILURE': False\n",
    "    # 'ABORTED' will yield 'N/A'\n",
    "}\n",
    "\n",
    "mapping_test_result = {\n",
    "    'PASS': True,\n",
    "    'FAIL': False\n",
    "    # 'UNAVAILABLE' will yield 'N/A'\n",
    "}\n",
    "\n",
    "mapping_success_fail = {\n",
    "    'PASS': True,\n",
    "    'FAIL': False,\n",
    "    'UNAVAILABLE': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sequence_number(df, relevant_col, mapping, grouping=['job']):\n",
    "\n",
    "    there_is_change = lambda x: x != x.shift()\n",
    "\n",
    "    return df.groupby(grouping)[relevant_col].transform(\n",
    "        lambda x: (\n",
    "            x\n",
    "            .map(mapping)\n",
    "            .fillna(method='ffill')\n",
    "            .fillna(method='bfill')  # Extrapolation if first samples are inconclusive (i.e. should be ignored)\n",
    "            .pipe(there_is_change)\n",
    "            .cumsum()\n",
    "            .astype(int)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds columns with groups labels\n",
    "data = (\n",
    "    data\n",
    "    .assign(\n",
    "        grp_build_result = lambda x: find_sequence_number(x, relevant_col='build_result', mapping=mapping_build_result),\n",
    "        grp_test_result = lambda x: find_sequence_number(x, relevant_col='test_result', mapping=mapping_test_result),\n",
    "        grp_success_fail = lambda x: find_sequence_number(x, relevant_col='test_result', mapping=mapping_success_fail)\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the duration of each of the sequences of success/failure is determined and a specific dataframe is built summarizing such sequences, to ease their representation and analysis..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions to extract sequences from a dataframe with test samples\n",
    "\n",
    "def show_me(df):\n",
    "    display(df)\n",
    "    return df\n",
    "\n",
    "def flatten_multi_level(df, outcome_name):\n",
    "\n",
    "    temp_name = list(df.columns.values)[-1][0]\n",
    "    df.columns = ['_'.join((col[1], col[0])) if (col[1] and col[0]!=temp_name) else col[0] for col in df.columns.values]\n",
    "    df.rename(columns={temp_name: outcome_name}, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def extend_sequence(df, agg):\n",
    "    df = df.copy()\n",
    "\n",
    "    left_shifted = df.groupby(agg).min_timestamp.shift(-1)\n",
    "    not_null = ~ left_shifted.isna()\n",
    "\n",
    "    df.loc[not_null, 'max_timestamp'] = left_shifted.loc[not_null]\n",
    "\n",
    "    return df\n",
    "\n",
    "def extend_last_sample_per_group(df, agg):\n",
    "    df = df.copy()\n",
    "\n",
    "    max_right_edge = max(df.min_timestamp.max(), df.max_timestamp.max())\n",
    "\n",
    "    last_item_indexes = df.groupby(agg).tail(1).index\n",
    "    df.loc[last_item_indexes, 'max_timestamp'] = max_right_edge\n",
    "\n",
    "    return df\n",
    "\n",
    "def extend_lastest_build_per_job(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Finds indices of rows generated from latest build of each job\n",
    "    indices_latest_build_per_job = (\n",
    "        df.groupby('job')\n",
    "        .max_build\n",
    "        .transform(lambda col: (col==col.max()))\n",
    "    )\n",
    "\n",
    "    # In those samples, changes 'max_timestamp' to the maximum of:\n",
    "    # - Current max_timestamp + 12 hours\n",
    "    # - Now\n",
    "    df.loc[indices_latest_build_per_job, 'max_timestamp'] = (\n",
    "        (\n",
    "            df.loc[indices_latest_build_per_job, ['max_timestamp']] + dt.timedelta(hours=12)\n",
    "        )\n",
    "        .assign(now = pd.to_datetime(\"now\"))\n",
    "    ).max(axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "# TODO: Remove if proven impossible after prior extrapolations:\n",
    "# # Fixes the last sample of the sequence if we have made extrapolations\n",
    "# def correct_extrapolations(df):\n",
    "#     df = df.copy()\n",
    "\n",
    "#     cond = (df.min_timestamp > df.max_timestamp)\n",
    "#     df.loc[cond, 'max_timestamp'] = df.loc[cond, 'min_timestamp']\n",
    "\n",
    "#     return df\n",
    "\n",
    "# Main function\n",
    "def create_sequence(df, grp_cols, agg_outcome, result_name):\n",
    "\n",
    "    aggregations_dict = {'timestamp': ['min', 'max'], 'build': ['min', 'max']}\n",
    "    aggregations_dict = {**aggregations_dict, **agg_outcome}\n",
    "\n",
    "    return (\n",
    "        df\n",
    "        .groupby(by=grp_cols)\n",
    "        .agg(aggregations_dict)\n",
    "        .dropna()\n",
    "\n",
    "        # Fixes column headers after complex `groupby`:\n",
    "        .pipe(flatten_multi_level, result_name)\n",
    "\n",
    "        .astype({'min_build': int, 'max_build': int})\n",
    "        .reset_index()\n",
    "\n",
    "        # Extends the length of each sequence up to the beginning of the next sequence:\n",
    "        .pipe(extend_sequence, agg=grp_cols[:-1]) # We have already aggregated by the last 'grp_*' ID.\n",
    "\n",
    "        # Extend the right edge of the last sample of each group to the end of the observed period\n",
    "        .pipe(extend_last_sample_per_group, agg=grp_cols[:-1])\n",
    "\n",
    "        # Extend the sequences from the last build of each job to have some extra width to be visible\n",
    "        .pipe(extend_lastest_build_per_job)\n",
    "\n",
    "        # TODO: Remove if proven impossible after prior extrapolations:\n",
    "        # # If we have made extrapolations, the last sample of the sequence may also need re-adjustment at its end (`max_timestamp`)\n",
    "        # .pipe(correct_extrapolations)\n",
    "\n",
    "        # Add column with the duration of each period\n",
    "        .assign(duration = lambda x: (x.max_timestamp - x.min_timestamp))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Summarizes the conditions for the 3 types of sequences in different tables\n",
    "\n",
    "# Was the build successful?: If at least one in the sequence is 'FAILURE', the whole sequence is in failure\n",
    "agg_build_result = lambda x: 'FAILURE' if (x=='FAILURE').any() else 'SUCCESS'\n",
    "\n",
    "# Were all Robot tests successful?: If at least one in the sequence is 'FAIL', the whole sequence is failing\n",
    "agg_test_result = lambda x: 'FAIL' if (x=='FAIL').any() else 'PASS'\n",
    "\n",
    "# Was all the building and testing successful?: If at least one in the sequence is 'PASS', the whole sequence is passing tests\n",
    "agg_success_fail = lambda x: 'PASS' if (x=='PASS').any() else 'FAIL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_build_result = create_sequence(data, grp_cols=['job', 'grp_build_result'], agg_outcome={'build_result': agg_build_result}, result_name='build_result')\n",
    "sequence_test_result = create_sequence(data, grp_cols=['job', 'grp_test_result'], agg_outcome={'test_result': agg_test_result}, result_name='test_result')\n",
    "sequence_success_fail = create_sequence(data, grp_cols=['job', 'grp_success_fail'], agg_outcome={'test_result': agg_success_fail}, result_name='success_fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes, Jenkins is able to create a test report, but it is unable to complete a proper build and image upload\n",
    "# This function allows to discount this effect\n",
    "def makes_stricter(df, change_to='UNAVAILABLE'):\n",
    "    df = df.copy()\n",
    "\n",
    "    cond = (df.build_result=='FAILURE') & (df.test_result=='PASS')\n",
    "    df.loc[cond, 'test_result'] = change_to\n",
    "\n",
    "    return df\n",
    "\n",
    "sequence_test_result_strict = create_sequence(data.pipe(makes_stricter), grp_cols=['job', 'grp_test_result'], agg_outcome={'test_result': agg_test_result}, result_name='test_result')\n",
    "sequence_success_fail_strict = create_sequence(data.pipe(makes_stricter, 'FAIL'), grp_cols=['job', 'grp_success_fail'], agg_outcome={'test_result': agg_success_fail}, result_name='success_fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #display(data)\n",
    "# display(sequence_build_result.head(15))\n",
    "# display(sequence_test_result.head(15))\n",
    "# display(sequence_success_fail.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Finding sequences of pass/fails per test suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Convenient alias to allow time masks\n",
    "\n",
    "# test_suites_data = df_all_build_reports.query('(timestamp>\"2021-08-01\") & (timestamp<\"2021-08-20\")').copy().drop(columns=['source'])\n",
    "test_suites_data = df_all_build_reports\n",
    "\n",
    "if 'first_date' in locals():\n",
    "    test_suites_data = test_suites_data.query('timestamp>=@first_date')\n",
    "\n",
    "if 'last_date' in locals():\n",
    "    # Needs to include latest hour of the last day\n",
    "    last_timestamp = pd.Timestamp(last_date) + dt.timedelta(days=1)\n",
    "    test_suites_data = test_suites_data.query('timestamp<@last_timestamp')\n",
    "\n",
    "test_suites_data = test_suites_data.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds columns with groups labels\n",
    "test_suites_data = (\n",
    "    test_suites_data\n",
    "    .assign(\n",
    "        grp_test_result = lambda x: find_sequence_number(x, relevant_col='status', mapping=mapping_test_result, grouping=['job', 'name']),\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_test_suites = create_sequence(test_suites_data, grp_cols=['job', 'name', 'grp_test_result'], agg_outcome={'status': agg_test_result}, result_name='test_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequence_test_suites.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If requested, it also dumps all the calculated sequences\n",
    "\n",
    "if dump_sequences:\n",
    "    filename = os.path.join(outputs_folder, 'sequences_dump.xlsx')\n",
    "    with pd.ExcelWriter(filename, engine='xlsxwriter') as writer:\n",
    "        sequence_build_result.to_excel(writer, index=False, sheet_name='sequence_build_result')\n",
    "        sequence_test_result.to_excel(writer, index=False, sheet_name='sequence_test_result')\n",
    "        sequence_success_fail.to_excel(writer, index=False, sheet_name='sequence_success_fail')\n",
    "        sequence_test_suites.to_excel(writer, index=False, sheet_name='sequence_test_suites')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Aggregated success rate per test step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_aggregated_success_rate(data_filtered, title, filename=None):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (12,6))\n",
    "\n",
    "    t = data_filtered.timestamp\n",
    "    pass_pct = 100 * data_filtered.pass_pct\n",
    "    fail_pct = 100 * data_filtered.fail_pct\n",
    "    #unavailable = (data_filtered.test_result=='UNAVAILABLE')*100\n",
    "    unavailable = (\n",
    "        data_filtered.test_result.map({'UNAVAILABLE': 100})\n",
    "        .fillna(method='ffill', limit=1)\n",
    "        .fillna(method='bfill', limit=1)\n",
    "    )\n",
    "\n",
    "    ax.fill_between(t, fail_pct+pass_pct, pass_pct, color='red', alpha=0.5, label='Failed')\n",
    "    ax.fill_between(t, pass_pct, color='lime', alpha=0.5, label='Passed')\n",
    "    ax.fill_between(t, unavailable, color='dimgray', label='Unsuccessful builds')\n",
    "    ax.axhline(100, color='black', linewidth=2, linestyle='--')\n",
    "\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.legend(fontsize=12, fancybox=True, shadow=True, borderpad=1, bbox_to_anchor = (1, 1))\n",
    "    #ax.legend(fontsize=12, fancybox=True, shadow=True, borderpad=1, bbox_to_anchor = (0.32, 0.4))\n",
    "    fig.autofmt_xdate()\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if (filename):\n",
    "        fig.savefig(filename + '.png', dpi=300)\n",
    "        fig.savefig(filename + '.svg')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_names = ['fully_successful_builds_v11', 'fully_successful_builds_v10', 'fully_successful_builds_master', 'fully_successful_builds_v9']\n",
    "file_names = ['fully_successful_builds_' + job_id for job_id in job_ids]\n",
    "\n",
    "for relevant_job, job_name, file_name in zip(relevant_jobs, job_names, file_names):\n",
    "    display(\n",
    "        _ = plot_aggregated_success_rate(\n",
    "            data.query(\"job==@relevant_job\"),\n",
    "            f'{job_name} - % of successful test steps ({today})',\n",
    "            os.path.join(outputs_folder, file_name)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Overall success of Jenkins builds and Robot tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_aggregated_builds_and_tests(data_filtered, state_col, title, ok_states, nok_states, filename=None):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (12,6))\n",
    "\n",
    "    for index, row in data_filtered.iterrows():\n",
    "        #color = 'red' if row.build_result=='FAILURE' else 'lime'\n",
    "        color = 'red' if row[state_col] in nok_states else 'lime'\n",
    "        ax.axvspan(row.min_timestamp, row.max_timestamp, color=color, alpha=0.5)\n",
    "\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    #ax.legend(fontsize=12, fancybox=True, shadow=True, borderpad=1, bbox_to_anchor = (1, 1))\n",
    "    fig.autofmt_xdate()\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if (filename):\n",
    "        fig.savefig(filename + '.png', dpi=300)\n",
    "        fig.savefig(filename + '.svg')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if extended_print:\n",
    "\n",
    "    # file_names = ['successful_failed_builds_v11', 'successful_failed_builds_v10', 'successful_failed_builds_master', 'successful_failed_builds_v9']\n",
    "    file_names = ['successful_failed_builds_' + job_id for job_id in job_ids]\n",
    "\n",
    "    for relevant_job, job_name, file_name in zip(relevant_jobs, job_names, file_names):\n",
    "        display(\n",
    "            _ = plot_aggregated_builds_and_tests(\n",
    "                sequence_build_result.query(\"job==@relevant_job\"),\n",
    "                'build_result',\n",
    "                f'{job_name} - Build completions and failures ({today})',\n",
    "                ok_states=['SUCCESS'], nok_states=['FAILURE'],\n",
    "                filename=os.path.join(outputs_folder, file_name)\n",
    "                )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if extended_print:\n",
    "\n",
    "    # file_names = ['global_robot_status_v11', 'global_robot_status_v10', 'global_robot_status_master', 'global_robot_status_v9']\n",
    "    file_names = ['global_robot_status_' + job_id for job_id in job_ids]\n",
    "\n",
    "    for relevant_job, job_name, file_name in zip(relevant_jobs, job_names, file_names):\n",
    "        display(\n",
    "            _ = plot_aggregated_builds_and_tests(\n",
    "                sequence_test_result.query(\"job==@relevant_job\"),\n",
    "                'test_result',\n",
    "                f'{job_name} - Robot tests status ({today})',\n",
    "                ok_states=['PASS'], nok_states=['FAIL'],\n",
    "                filename=os.path.join(outputs_folder, file_name)\n",
    "                )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if extended_print:\n",
    "\n",
    "    # file_names = ['global_stability_status_v11', 'global_stability_status_v10', 'global_stability_status_master', 'global_stability_status_v9']\n",
    "    file_names = ['global_stability_status_' + job_id for job_id in job_ids]\n",
    "\n",
    "    for relevant_job, job_name, file_name in zip(relevant_jobs, job_names, file_names):\n",
    "        display(\n",
    "            _ = plot_aggregated_builds_and_tests(\n",
    "                sequence_success_fail.query(\"job==@relevant_job\"),\n",
    "                'success_fail',\n",
    "                f'{job_name} - Stability for point release ({today})',\n",
    "                ok_states=['PASS'], nok_states=['FAIL'],\n",
    "                filename=os.path.join(outputs_folder, file_name)\n",
    "                )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_aggregated_stability_sequences(sequences, state_cols, titles, ok_states, nok_states, text=None, suptitle=None, filename=None, figsize=(14,8), tight=False):\n",
    "\n",
    "    #fig, ax = plt.subplots(nrows=3, sharex=True, figsize = (14,8))\n",
    "    fig, ax = plt.subplots(nrows=len(sequences), sharex=True, figsize=figsize)\n",
    "\n",
    "    for i in range(len(sequences)):\n",
    "        for index, row in sequences[i].iterrows():\n",
    "            color = 'red' if row[state_cols[i]] in nok_states[i] else 'lime'\n",
    "            ax[i].axvspan(row.min_timestamp, row.max_timestamp, color=color, alpha=0.5)\n",
    "            if text:\n",
    "                ax[i].text(0.5, 0.5, text[i], dict(size=14),\n",
    "                           horizontalalignment='center', verticalalignment='center', transform=ax[i].transAxes, rasterized=False)\n",
    "\n",
    "        if not text:\n",
    "            ax[i].set_title(titles[i], fontsize=16)\n",
    "        ax[i].set_yticklabels([])\n",
    "        #ax[i].legend(fontsize=12, fancybox=True, shadow=True, borderpad=1, bbox_to_anchor = (1, 1))\n",
    "\n",
    "    fig.autofmt_xdate()\n",
    "\n",
    "    if tight:\n",
    "        fig.tight_layout()\n",
    "    if suptitle:\n",
    "        fig.suptitle(suptitle, fontsize=22)\n",
    "\n",
    "    if (filename):\n",
    "        fig.savefig(filename + '.png', dpi=300)\n",
    "        fig.savefig(filename + '.svg')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_names = ['global_compared_stability_status_v11', 'global_compared_stability_status_v10', 'global_compared_stability_status_master', 'global_compared_stability_status_v9']\n",
    "file_names = ['global_compared_stability_status_' + job_id for job_id in job_ids]\n",
    "\n",
    "for relevant_job, job_name, file_name in zip(relevant_jobs, job_names, file_names):\n",
    "    display(\n",
    "        _ = plot_aggregated_stability_sequences(\n",
    "            sequences=[\n",
    "                sequence_build_result.query(\"job==@relevant_job\"),\n",
    "                #sequence_test_result.query(\"job==@relevant_job\"),\n",
    "                sequence_test_result_strict.query(\"job==@relevant_job\"),\n",
    "                #sequence_success_fail.query(\"job==@relevant_job\")\n",
    "                sequence_success_fail_strict.query(\"job==@relevant_job\")\n",
    "            ],\n",
    "            state_cols=['build_result', 'test_result', 'success_fail'],\n",
    "            titles=[\n",
    "                'Build completions and failures',\n",
    "                'Robot tests status',\n",
    "                'Stability for point release'\n",
    "            ],\n",
    "            suptitle=f'{job_name} - Robot tests status ({today})\\n',\n",
    "            ok_states=[['SUCCESS'], ['PASS'], ['PASS']],\n",
    "            nok_states=[['FAILURE'], ['FAIL'], ['FAIL']],\n",
    "            filename=os.path.join(outputs_folder, file_name)\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(sequence_build_result.query(\"job==@relevant_jobs[0]\"))\n",
    "# display(sequence_test_result.query(\"job==@relevant_jobs[0]\"))\n",
    "# display(sequence_success_fail.query(\"job==@relevant_jobs[0]\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Sequences of pass/fails per test suites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearranges the sequence as a list of sequences per 'job' x 'suite'\n",
    "def prepare_suite_sequences_for_plotting(df_suites):\n",
    "\n",
    "    jobs = []\n",
    "    suites = []\n",
    "    sequences = []\n",
    "    for name, group in df_suites.groupby(['job', 'name']):\n",
    "        jobs.append(name[0])\n",
    "        suites.append(name[1])\n",
    "        sequences.append(group)\n",
    "\n",
    "    return jobs, suites, sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_names = ['success_per_test_suite_status_v11', 'success_per_test_suite_status_v10', 'success_per_test_suite_status_master', 'success_per_test_suite_status_v9']\n",
    "file_names = ['success_per_test_suite_status_' + job_id for job_id in job_ids]\n",
    "\n",
    "for relevant_job, job_name, file_name in zip(relevant_jobs, job_names, file_names):\n",
    "\n",
    "    sequence_suites_filtered = sequence_test_suites.query('job==@relevant_job')\n",
    "    _, suites, sequences = prepare_suite_sequences_for_plotting(sequence_suites_filtered)\n",
    "\n",
    "    display(\n",
    "        _ = plot_aggregated_stability_sequences(\n",
    "            sequences=sequences,\n",
    "            state_cols = ['test_result'] * len(sequences),\n",
    "            titles = [''] * len(sequences),\n",
    "            text = suites,\n",
    "            suptitle = f'{job_name} ({today})',\n",
    "            ok_states = ['PASS'] * len(sequences),\n",
    "            nok_states = ['FAIL'] * len(sequences),\n",
    "            filename = os.path.join(outputs_folder, file_name),\n",
    "            figsize = (18,16),\n",
    "            tight = False\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Failing days per test suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_days_suites_ok_nok(suites, days_failing, days_passing, title, filename=None):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (12,16))\n",
    "\n",
    "    plt.barh(suites, days_failing, color='red', alpha=0.5, label='Failing')\n",
    "    plt.barh(suites, days_passing, color='lime', alpha=0.5, left=days_failing, label='Passing')\n",
    "\n",
    "    #ax.set_title(title, fontsize=20)\n",
    "    fig.suptitle(title, fontsize=20)\n",
    "    ax.set_xlabel('Number of days')\n",
    "    #ax.legend(fontsize=12, fancybox=True, shadow=True, borderpad=1, bbox_to_anchor = (1, 1))\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if (filename):\n",
    "        fig.savefig(filename + '.png', dpi=300)\n",
    "        fig.savefig(filename + '.svg')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_to_days(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    df['FAIL'] = pd.to_timedelta(df.FAIL) / pd.Timedelta(days=1)\n",
    "    df['PASS'] = pd.to_timedelta(df.PASS) / pd.Timedelta(days=1)\n",
    "\n",
    "    # # Round to whole days\n",
    "    # df['FAIL'] = df.FAIL.round(0).astype(int)\n",
    "    # df['PASS'] = df.PASS.round(0).astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_names = ['failing_days_per_suite_v11', 'failing_days_per_suite_v10', 'failing_days_per_suite_master', 'failing_days_per_suite_v9']\n",
    "file_names = ['failing_days_per_suite_' + job_id for job_id in job_ids]\n",
    "\n",
    "for relevant_job, job_name, file_name in zip(relevant_jobs, job_names, file_names):\n",
    "\n",
    "    sequence_suites_filtered = sequence_test_suites.query('job==@relevant_job')\n",
    "\n",
    "    fail_pass_durations_per_suite = (\n",
    "        sequence_suites_filtered\n",
    "        .assign(duration = lambda x: x.duration / pd.Timedelta(days=1))\n",
    "        .pivot_table(\n",
    "            index = 'name',\n",
    "            columns = 'test_result',\n",
    "            values = 'duration',\n",
    "            aggfunc = 'sum'\n",
    "        )\n",
    "        .fillna(0)\n",
    "        .reset_index()\n",
    "        .sort_values(['FAIL', 'PASS'])\n",
    "        # .pipe(round_to_days)\n",
    "    )\n",
    "\n",
    "    display(\n",
    "        _ = plot_days_suites_ok_nok(\n",
    "            suites=fail_pass_durations_per_suite.name,\n",
    "            days_failing=fail_pass_durations_per_suite.FAIL,\n",
    "            days_passing=fail_pass_durations_per_suite.PASS,\n",
    "            title=f'{job_name} - Failing days per test suite ({today})',\n",
    "            filename=os.path.join(outputs_folder, file_name)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Information about the latest builds of relevant jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to use external notebook\n",
    "#%run 001-analysis_latest_build.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_latest_builds_all_jobs(engine, too_old_builds='1980-12-15'):\n",
    "\t'''\n",
    "\tFrom each of the known jobs, retrieves their latest build.\n",
    "\tReturns a dataframe with a row per job.\n",
    "\n",
    "\tUsage:\n",
    "\n",
    "\tload_latest_builds(engine, too_old_builds='1980-12-15')\n",
    "\n",
    "\t- `engine`: Database engine to use for the connection.\n",
    "\t- `too_old_builds`: Limits the query to builds not older than a date. By default, it does not limit in practice (1980!).\n",
    "\t'''\n",
    "\n",
    "\ttable_known_builds = 'builds_info'\n",
    "\n",
    "\tquery_latest_builds = f'''\n",
    "\tSELECT main.*\n",
    "\tFROM {table_known_builds} AS main\n",
    "\tINNER JOIN (\n",
    "\t\tSELECT job, MAX(timestamp) as ts\n",
    "\t\tFROM {table_known_builds}\n",
    "\t\tWHERE timestamp>\"{too_old_builds}\"\n",
    "\t\tGROUP BY job\n",
    "\t) AS latest_build\n",
    "\tON main.job=latest_build.job AND main.timestamp=ts\n",
    "\t'''\n",
    "\n",
    "\twith engine.begin() as conn:\n",
    "\t\tdf_latest_builds = pd.read_sql(query_latest_builds, con=conn)\n",
    "\n",
    "\tdf_latest_builds['timestamp'] = pd.to_datetime(df_latest_builds.timestamp)\n",
    "\n",
    "\treturn df_latest_builds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_latest_report_all_jobs(engine, too_old_builds='1980-12-15'):\n",
    "\t'''\n",
    "\tFrom each of the known jobs, retrieves the report from their latest build.\n",
    "\tReturns a dataframe with a row per suite per job (in case the latest build of the job generated a report).\n",
    "\n",
    "\tUsage:\n",
    "\n",
    "\tload_latest_report_all_jobs(engine, too_old_builds='1980-12-15')\n",
    "\n",
    "\t- `engine`: Database engine to use for the connection.\n",
    "\t- `too_old_builds`: Limits the query to builds not older than a date. By default, it does not limit in practice (1980!).\n",
    "\n",
    "\t'''\n",
    "\ttable =  'robot_reports'\n",
    "\ttable_known_builds = 'builds_info'\n",
    "\n",
    "\tquery_robot_reports = f'''\n",
    "\tSELECT details.*\n",
    "\tFROM {table} AS details\n",
    "\tINNER JOIN {table_known_builds} AS main\n",
    "\tON details.job=main.job AND details.build=main.build\n",
    "\tINNER JOIN (\n",
    "\t\tSELECT job, MAX(timestamp) as ts\n",
    "\t\tFROM {table_known_builds}\n",
    "\t\tWHERE timestamp>\"{too_old_builds}\"\n",
    "\t\tGROUP BY job\n",
    "\t) AS latest_build\n",
    "\tON main.job=latest_build.job AND main.timestamp=ts\n",
    "\t'''\n",
    "\n",
    "\twith engine.begin() as conn:\n",
    "\t\tdf_robot_reports = pd.read_sql(query_robot_reports, con=conn)\n",
    "\n",
    "\tdf_robot_reports['starttime'] = pd.to_datetime(df_robot_reports.starttime)\n",
    "\tdf_robot_reports['endtime'] = pd.to_datetime(df_robot_reports.endtime)\n",
    "\n",
    "\treturn df_robot_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_latest_extended_report_all_jobs(engine, too_old_builds='1980-12-15'):\n",
    "\t'''\n",
    "\tFrom each of the known jobs, retrieves the extended report from their latest build.\n",
    "\tReturns a dataframe with a row per test per suite per job (in case the latest build of the job generated a report).\n",
    "\n",
    "\tUsage:\n",
    "\n",
    "\tload_latest_extendend_report_all_jobs(engine, too_old_builds='1980-12-15')\n",
    "\n",
    "\t- `engine`: Database engine to use for the connection.\n",
    "\t- `too_old_builds`: Limits the query to builds not older than a date. By default, it does not limit in practice (1980!).\n",
    "\t'''\n",
    "\n",
    "\ttable = 'robot_reports_extended'\n",
    "\ttable_known_builds = 'builds_info'\n",
    "\n",
    "\tquery_robot_reports = f'''\n",
    "\tSELECT details.*\n",
    "\tFROM {table} AS details\n",
    "\tINNER JOIN {table_known_builds} AS main\n",
    "\tON details.job=main.job AND details.build=main.build\n",
    "\tINNER JOIN (\n",
    "\t\tSELECT job, MAX(timestamp) as ts\n",
    "\t\tFROM {table_known_builds}\n",
    "\t\tWHERE timestamp>\"{too_old_builds}\"\n",
    "\t\tGROUP BY job\n",
    "\t) AS latest_build\n",
    "\tON main.job=latest_build.job AND main.timestamp=ts\n",
    "\t'''\n",
    "\n",
    "\twith engine.begin() as conn:\n",
    "\t\tdf_robot_reports_extended = pd.read_sql(query_robot_reports, con=conn)\n",
    "\n",
    "\tdf_robot_reports_extended['starttime'] = pd.to_datetime(df_robot_reports_extended.starttime)\n",
    "\tdf_robot_reports_extended['endtime'] = pd.to_datetime(df_robot_reports_extended.endtime)\n",
    "\n",
    "\treturn df_robot_reports_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "engine = create_engine(database_uri)\n",
    "\n",
    "sorted_categorical_builds = CategoricalDtype(categories=relevant_jobs, ordered=True)\n",
    "df_latest_builds_all_jobs = (\n",
    "    load_latest_builds_all_jobs(engine, too_old_builds=too_old_builds)\n",
    "    .assign(job = lambda x: x.job.astype(sorted_categorical_builds))\n",
    "    .sort_values('job')\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "df_latest_report_all_jobs = load_latest_report_all_jobs(engine, too_old_builds=too_old_builds)\n",
    "df_latest_extended_report_all_jobs = load_latest_extended_report_all_jobs(engine, too_old_builds=too_old_builds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latest build of each job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_latest_builds_all_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for job_name, build in zip(df_latest_builds_all_jobs.job, df_latest_builds_all_jobs.build):\n",
    "    stage, branch = job_name.split('/')\n",
    "    link = link_to_build.format(stage=stage, branch=branch, build=build)\n",
    "    display(Markdown(f'[Click to see the details of **build {build} of {job_name}**]({link})'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Failed test suites per job (if any):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_failed = (\n",
    "    df_latest_report_all_jobs\n",
    "    .query(\"status=='FAIL'\")\n",
    ")\n",
    "\n",
    "for job_name in relevant_jobs:\n",
    "    stage, branch = job_name.split('/')\n",
    "    build = (\n",
    "        df_latest_builds_all_jobs\n",
    "        .query('job==@job_name')\n",
    "        ['build']\n",
    "        .to_list()[0]\n",
    "    )\n",
    "\n",
    "    link = link_to_report.format(stage=stage, branch=branch, build=build)\n",
    "    display(\n",
    "        Markdown(f'**{job_name}:** ([full report]({link}))')\n",
    "    )\n",
    "    display(\n",
    "        df_failed\n",
    "        .query('job==@job_name')\n",
    "        .drop(columns=['build', 'source', 'job', 'id', 'failed_test_id'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Details of failed tests into failing test suites (if any):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_details_failed = (\n",
    "    df_latest_extended_report_all_jobs\n",
    "    .merge(\n",
    "        df_failed[['job', 'build', 'name']],\n",
    "        how='inner',\n",
    "        left_on=['job', 'build', 'suite_name'],\n",
    "        right_on=['job', 'build', 'name']\n",
    "        )\n",
    "    .drop(columns=['suite_id', 'test_id', 'name'])\n",
    "    .query('status==\"FAIL\"')\n",
    ")\n",
    "\n",
    "for job_name in relevant_jobs:\n",
    "    stage, branch = job_name.split('/')\n",
    "    build = (\n",
    "        df_latest_builds_all_jobs\n",
    "        .query('job==@job_name')\n",
    "        ['build']\n",
    "        .to_list()[0]\n",
    "    )\n",
    "\n",
    "    link = link_to_report.format(stage=stage, branch=branch, build=build)\n",
    "    display(\n",
    "        Markdown(f'**{job_name}:** ([full report]({link}))')\n",
    "    )\n",
    "    display(\n",
    "        df_details_failed\n",
    "        .query('job==@job_name')\n",
    "        .drop(columns=['job', 'build'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not skip_export_to_html:\n",
    "    !jupyter nbconvert --to html --output report_outputs/analysis_of_test_results.html --TemplateExporter.exclude_input=True 01-analysis_of_test_results.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANNEX: Samples of density plots (for future use)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sequence_build_filtered = sequence_build_result[sequence_build_result.job=='osm-stage_3-merge/v9.0']\n",
    "#sequence_build_filtered.iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_density_builds_and_tests(data, title, labels, filename=None):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (12,6))\n",
    "\n",
    "    n_bins = 25\n",
    "    colors = ['green', 'red']\n",
    "    #labels = ['OK', 'NOK']\n",
    "\n",
    "    #ax.hist(data, n_bins, density=True, histtype='bar', color=colors, label=labels)\n",
    "    #ax.hist(data, n_bins, density=True, histtype='bar', rwidth=0.8, label=labels, color=colors)\n",
    "    ax.hist(data, n_bins, density=True, histtype='bar', rwidth=0.8, label=labels, color=colors, alpha=0.5)\n",
    "\n",
    "    #ax.set_title(title, fontsize=20)\n",
    "    fig.suptitle(title, fontsize=20)\n",
    "    ax.set_xlabel('Duration of sequences (days)')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.legend(fontsize=12, fancybox=True, shadow=True, borderpad=1, bbox_to_anchor = (1, 1))\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if (filename):\n",
    "        fig.savefig(filename + '.png', dpi=300)\n",
    "        fig.savefig(filename + '.svg')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "build_durations_filtered = sequence_build_filtered.copy()\n",
    "build_durations_filtered['duration'] = build_durations_filtered.max_timestamp - build_durations_filtered.min_timestamp\n",
    "#build_durations_filtered['duration'] = build_durations_filtered['duration'] / pd.to_timedelta(1, unit='D') # Expressed in days, allowing decimals\n",
    "build_durations_filtered['duration'] = build_durations_filtered['duration'].dt.days\n",
    "\n",
    "build_durations_filtered.drop(columns=['grp_build_result', 'min_timestamp', 'max_timestamp', 'min_build', 'max_build'], inplace=True)\n",
    "\n",
    "builds_ok = build_durations_filtered.loc[build_durations_filtered.build_result=='SUCCESS', 'duration']\n",
    "builds_nok = build_durations_filtered.loc[build_durations_filtered.build_result=='FAILURE', 'duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# plot_density_builds_and_tests(data=[builds_ok, builds_nok],\n",
    "#                               title='Rel NINE branch - Histogram of durations of build states (failure/success) ('+ today + ')',\n",
    "#                               labels=['SUCCESS', 'FAILURE'],\n",
    "#                               filename=os.path.join(outputs_folder, 'density_build_success_failure_v9'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_kde_builds_and_tests(data, x, hue, colors, title, filename=None):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (12,6))\n",
    "\n",
    "    sns.kdeplot(data=data,\n",
    "                x=x, hue=hue,\n",
    "                cut=0, bw_adjust=0.2,\n",
    "                palette=colors, fill=True, alpha=0.4,\n",
    "                ax=ax)\n",
    "\n",
    "    fig.suptitle(title, fontsize=20)\n",
    "    ax.set_xlabel('Duration of sequences (days)')\n",
    "\n",
    "    if filename:\n",
    "        fig.savefig(filename + '.png', dpi=300)\n",
    "        fig.savefig(filename + '.svg')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# plot_kde_builds_and_tests(data=build_durations_filtered,\n",
    "#                           x='duration', hue='build_result', colors=['red', 'green'],\n",
    "#                           title='Rel NINE branch - KDE of durations of build states (failure/success) ('+ today + ')',\n",
    "#                           filename=os.path.join(outputs_folder, 'kde_build_success_failure_v9'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "436f2814f1f12011c00cf6933038a969dd0edc275127d459a28a14c2140dfae0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('osm-analytics': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
