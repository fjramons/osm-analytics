{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Robot reports from OSM Jenkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import datetime as dt\r\n",
    "#import getpass\r\n",
    "from sqlalchemy import create_engine\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "import seaborn as sns\r\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to update the database from this notebook\r\n",
    "%run 00-script-jenkins_and_robot_etl.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "inputs_folder = 'etl_outputs'\r\n",
    "outputs_folder = 'report_outputs'\r\n",
    "database_uri = f'sqlite:///{inputs_folder}/test_executions.db'\r\n",
    "\r\n",
    "too_old_builds = \"2020-12-15\"\r\n",
    "\r\n",
    "# Comment for analysis of all historical data\r\n",
    "days_since_today_4_analysis = 21\r\n",
    "\r\n",
    "extended_print = False\r\n",
    "dump_sequences = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_jobs = ['osm-stage_3-merge/v10.0', 'osm-stage_3-merge/master', 'osm-stage_3-merge/v9.0']\r\n",
    "job_names = ['Release TEN', 'Master branch', 'Release NINE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "today_as_datetime = pd.to_datetime(\"today\")\r\n",
    "today = today_as_datetime.strftime('%Y-%m-%d')\r\n",
    "\r\n",
    "display(Markdown(f'**Date and time of the report:** {today_as_datetime}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'days_since_today_4_analysis' in locals():\r\n",
    "    first_date_as_datetime = today_as_datetime - dt.timedelta(days=days_since_today_4_analysis)\r\n",
    "    first_date = first_date_as_datetime.strftime('%Y-%m-%d')\r\n",
    "else:\r\n",
    "    first_date = too_old_builds # Unconstrained\r\n",
    "\r\n",
    "last_date = today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to set the window of analysis manually\r\n",
    "#\r\n",
    "# first_date = \"2021-08-01\"\r\n",
    "# last_date = \"2021-08-20\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f'**Analysed period:** {first_date} to {last_date}.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Retrieval of all currrent data for aggregate analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_known_builds(engine, too_old_builds='1980-12-15'):\r\n",
    "\r\n",
    "    table_known_builds = 'builds_info'\r\n",
    "\r\n",
    "    query_known_builds = f'SELECT * FROM {table_known_builds} WHERE timestamp>DATETIME(\"{too_old_builds}\")'\r\n",
    "\r\n",
    "    with engine.begin() as conn:\r\n",
    "        df_known_builds = pd.read_sql(query_known_builds, con=conn)\r\n",
    "\r\n",
    "    # Fixes some special data types\r\n",
    "    df_known_builds['timestamp'] = pd.to_datetime(df_known_builds.timestamp)\r\n",
    "    df_known_builds['job'] = df_known_builds.job.astype('category')\r\n",
    "    df_known_builds['duration'] = pd.to_timedelta(df_known_builds.duration.astype('float')*1000, unit='us')\r\n",
    "    df_known_builds['build_result'] = df_known_builds.build_result.astype('category')\r\n",
    "    df_known_builds['test_result'] = df_known_builds.test_result.astype('category')\r\n",
    "\r\n",
    "    return df_known_builds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_build_reports(engine, too_old_builds='1980-12-15'):\r\n",
    "\r\n",
    "    table_known_builds = 'builds_info'\r\n",
    "    table_robot_reports = 'robot_reports'\r\n",
    "\r\n",
    "    query_robot_reports = f'''\r\n",
    "    SELECT main.timestamp, details.*\r\n",
    "    FROM {table_robot_reports} AS details\r\n",
    "    INNER JOIN {table_known_builds} AS main\r\n",
    "    ON details.job=main.job AND details.build=main.build\r\n",
    "    WHERE main.timestamp>DATETIME(\"{too_old_builds}\")\r\n",
    "    ORDER BY details.job, details.build, details.starttime\r\n",
    "    '''\r\n",
    "\r\n",
    "    with engine.begin() as conn:\r\n",
    "        df_all_build_reports = pd.read_sql(query_robot_reports, con=conn)\r\n",
    "\r\n",
    "    # Fixes some special data types\r\n",
    "    df_all_build_reports['timestamp'] = pd.to_datetime(df_all_build_reports.timestamp)\r\n",
    "    df_all_build_reports['job'] = df_all_build_reports.job.astype('category')\r\n",
    "    df_all_build_reports['id'] = df_all_build_reports.id.astype('category')\r\n",
    "    df_all_build_reports['name'] = df_all_build_reports.name.astype('category')\r\n",
    "    df_all_build_reports['source'] = df_all_build_reports.source.astype('category')\r\n",
    "    df_all_build_reports['starttime'] = pd.to_datetime(df_all_build_reports.starttime)\r\n",
    "    df_all_build_reports['endtime'] = pd.to_datetime(df_all_build_reports.endtime)\r\n",
    "    df_all_build_reports['status'] = df_all_build_reports.status.astype('category')\r\n",
    "    df_all_build_reports['failed_test_id'] = df_all_build_reports.failed_test_id.astype('category')\r\n",
    "    df_all_build_reports['failed_test_name'] = df_all_build_reports.failed_test_name.astype('category')\r\n",
    "    df_all_build_reports['failed_keyword'] = df_all_build_reports.failed_keyword.astype('category')\r\n",
    "\r\n",
    "    return df_all_build_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_build_reports_details(engine, too_old_builds='1980-12-15'):\r\n",
    "\r\n",
    "    query_robot_reports_extended = f'''\r\n",
    "    SELECT main.timestamp, details.*\r\n",
    "    FROM {table_robot_reports_extended} AS details\r\n",
    "    INNER JOIN {table_known_builds} AS main\r\n",
    "    ON details.job=main.job AND details.build=main.build\r\n",
    "    WHERE main.timestamp>DATETIME(\"{too_old_builds}\")\r\n",
    "    ORDER BY details.job, details.build, details.starttime\r\n",
    "    '''\r\n",
    "\r\n",
    "    with engine.begin() as conn:\r\n",
    "        df_all_build_reports_details = pd.read_sql(query_robot_reports_extended, con=conn)\r\n",
    "\r\n",
    "    # Fixes some special data types\r\n",
    "    df_all_build_reports_details['timestamp'] = pd.to_datetime(df_all_build_reports_details.timestamp)\r\n",
    "    df_all_build_reports_details['job'] = df_all_build_reports_details.job.astype('category')\r\n",
    "    df_all_build_reports_details['suite_id'] = df_all_build_reports_details.suite_id.astype('category')\r\n",
    "    df_all_build_reports_details['suite_name'] = df_all_build_reports_details.suite_name.astype('category')\r\n",
    "    df_all_build_reports_details['test_id'] = df_all_build_reports_details.test_id.astype('category')\r\n",
    "    df_all_build_reports_details['test_name'] = df_all_build_reports_details.test_name.astype('category')\r\n",
    "    df_all_build_reports_details['keyword_name'] = df_all_build_reports_details.keyword_name.astype('category')\r\n",
    "    df_all_build_reports_details['starttime'] = pd.to_datetime(df_all_build_reports_details.starttime)\r\n",
    "    df_all_build_reports_details['endtime'] = pd.to_datetime(df_all_build_reports_details.endtime)\r\n",
    "    df_all_build_reports_details['status'] = df_all_build_reports_details.status.astype('category')\r\n",
    "\r\n",
    "    return df_all_build_reports_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Retrieving from database...\\t' , end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(database_uri)\r\n",
    "\r\n",
    "df_known_builds = load_known_builds(engine, too_old_builds=too_old_builds)\r\n",
    "df_all_build_reports = load_all_build_reports(engine, too_old_builds=too_old_builds)\r\n",
    "df_all_build_reports_details = load_all_build_reports_details(engine, too_old_builds=too_old_builds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds columns with % of passed/failed sub-tests\r\n",
    "df_known_builds = (\r\n",
    "    df_known_builds\r\n",
    "    .copy()\r\n",
    "    .assign(pass_pct = lambda x: x.pass_count / (x.pass_count + x.fail_count))\r\n",
    "    .fillna({'pass_pct': 0})\r\n",
    "    .assign(fail_pct = lambda x: 1- x.pass_pct)\r\n",
    "    .fillna({'fail_pct': 100})\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_known_builds.query('test_result==\"PASS\"').groupby('job').last()\r\n",
    "# df_all_build_reports.info()\r\n",
    "# df_all_build_reports_details.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Aggregated analysis of stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Restricts data to time window for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenient alias to allow time masks\r\n",
    "\r\n",
    "#data = df_known_builds.query('(timestamp>\"2021-08-01\") & (timestamp<\"2021-08-20\")').copy()\r\n",
    "data = df_known_builds\r\n",
    "\r\n",
    "if 'first_date' in locals():\r\n",
    "    data = data.query('timestamp>=@first_date')\r\n",
    "\r\n",
    "if 'last_date' in locals():\r\n",
    "    # Needs to include latest hour of the last day\r\n",
    "    last_timestamp = pd.Timestamp(last_date) + dt.timedelta(days=1)\r\n",
    "    data = data.query('timestamp<@last_timestamp')\r\n",
    "\r\n",
    "data = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Finding sequences of successful builds and Robot reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aligns markdown tables to the left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\r\n",
    "<style>\r\n",
    "table {align:left;display:block}\r\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two values retrieved from the build are key to determine the state of the jubs and test suites at a given moment:\r\n",
    "\r\n",
    "- `build_result` is the outcome of the build, reported by Jenkins. It can be: `SUCCESS`, `FAILURE`, `UNSTABLE` or `ABORTED`.\r\n",
    "- `test_result` is the summary of the concerned Robot tests. It can be: `FAIL`, `UNAVAILABLE` or `PASS`.\r\n",
    "\r\n",
    "Based on these two states, 3 types of temporal sequences of success/failure are identified per builds and test suites:\r\n",
    "\r\n",
    "1. Successful builds/failed builds in a row: `grp_build_result`.\r\n",
    "2. Successful test reports vs. test reports with fails in a row: `grp_test_result`.\r\n",
    "3. Clean builds and tests vs. failures (of any kind) in a row: `grp_success_fail`.\r\n",
    "\r\n",
    "For the identification of these sequences, the following mapping applies:\r\n",
    "\r\n",
    "| Type of sequence   | Relevant state | OK sequence contains    | NOK sequence contains   | Ignore        |\r\n",
    "|--------------------|----------------|-------------------------|-------------------------|---------------|\r\n",
    "| `grp_build_result` | `build_result` | `SUCCESS` or `UNSTABLE` | `FAILURE`               | `ABORTED`     |\r\n",
    "| `grp_test_result`  | `test_result`  | `PASS`                  | `FAIL`                  | `UNAVAILABLE` |\r\n",
    "| `grp_success_fail` | `test_result`  | `PASS`                  | `FAIL` or `UNAVAILABLE` | N/A           |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different groupings of segments are detected and a label is added to each sample..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_build_result = {\r\n",
    "    'SUCCESS': True,\r\n",
    "    'UNSTABLE': True,\r\n",
    "    'FAILURE': False\r\n",
    "    # 'ABORTED' will yield 'N/A'\r\n",
    "}\r\n",
    "\r\n",
    "mapping_test_result = {\r\n",
    "    'PASS': True,\r\n",
    "    'FAIL': False\r\n",
    "    # 'UNAVAILABLE' will yield 'N/A'\r\n",
    "}\r\n",
    "\r\n",
    "mapping_success_fail = {\r\n",
    "    'PASS': True,\r\n",
    "    'FAIL': False,\r\n",
    "    'UNAVAILABLE': False\r\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sequence_number(df, relevant_col, mapping, grouping=['job']):\r\n",
    "\r\n",
    "    there_is_change = lambda x: x != x.shift()\r\n",
    "\r\n",
    "    return df.groupby(grouping)[relevant_col].transform(\r\n",
    "        lambda x: (\r\n",
    "            x\r\n",
    "            .map(mapping)\r\n",
    "            .fillna(method='ffill')\r\n",
    "            .fillna(method='bfill')  # Extrapolation if first samples are inconclusive (i.e. should be ignored)\r\n",
    "            .pipe(there_is_change)\r\n",
    "            .cumsum()\r\n",
    "            .astype(int)\r\n",
    "        )\r\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds columns with groups labels\r\n",
    "data = (\r\n",
    "    data\r\n",
    "    .assign(\r\n",
    "        grp_build_result = lambda x: find_sequence_number(x, relevant_col='build_result', mapping=mapping_build_result),\r\n",
    "        grp_test_result = lambda x: find_sequence_number(x, relevant_col='test_result', mapping=mapping_test_result),\r\n",
    "        grp_success_fail = lambda x: find_sequence_number(x, relevant_col='test_result', mapping=mapping_success_fail)\r\n",
    "        )\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the duration of each of the sequences of success/failure is determined and a specific dataframe is built summarizing such sequences, to ease their representation and analysis..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions to extract sequences from a dataframe with test samples\r\n",
    "\r\n",
    "def show_me(df):\r\n",
    "    display(df)\r\n",
    "    return df\r\n",
    "\r\n",
    "def flatten_multi_level(df, outcome_name):\r\n",
    "\r\n",
    "    temp_name = list(df.columns.values)[-1][0]\r\n",
    "    df.columns = ['_'.join((col[1], col[0])) if (col[1] and col[0]!=temp_name) else col[0] for col in df.columns.values]\r\n",
    "    df.rename(columns={temp_name: outcome_name}, inplace=True)\r\n",
    "\r\n",
    "    return df\r\n",
    "\r\n",
    "def extend_sequence(df, agg):\r\n",
    "    df = df.copy()\r\n",
    "\r\n",
    "    left_shifted = df.groupby(agg).min_timestamp.shift(-1)\r\n",
    "    not_null = ~ left_shifted.isna()\r\n",
    "\r\n",
    "    df.loc[not_null, 'max_timestamp'] = left_shifted.loc[not_null]\r\n",
    "\r\n",
    "    return df\r\n",
    "\r\n",
    "def extend_last_sample_per_group(df, agg):\r\n",
    "    df = df.copy()\r\n",
    "\r\n",
    "    max_right_edge = max(df.min_timestamp.max(), df.max_timestamp.max())\r\n",
    "\r\n",
    "    last_item_indexes = df.groupby(agg).tail(1).index\r\n",
    "    df.loc[last_item_indexes, 'max_timestamp'] = max_right_edge\r\n",
    "\r\n",
    "    return df\r\n",
    "\r\n",
    "def extend_lastest_build_per_job(df):\r\n",
    "    df = df.copy()\r\n",
    "\r\n",
    "    # Finds indices of rows generated from latest build of each job\r\n",
    "    indices_latest_build_per_job = (\r\n",
    "        df.groupby('job')\r\n",
    "        .max_build\r\n",
    "        .transform(lambda col: (col==col.max()))\r\n",
    "    )\r\n",
    "\r\n",
    "    # In those samples, changes 'max_timestamp' to the maximum of:\r\n",
    "    # - Current max_timestamp + 12 hours\r\n",
    "    # - Now\r\n",
    "    df.loc[indices_latest_build_per_job, 'max_timestamp'] = (\r\n",
    "        (\r\n",
    "            df.loc[indices_latest_build_per_job, ['max_timestamp']] + dt.timedelta(hours=12)\r\n",
    "        )\r\n",
    "        .assign(now = pd.to_datetime(\"now\"))\r\n",
    "    ).max(axis=1)\r\n",
    "\r\n",
    "    return df\r\n",
    "\r\n",
    "# TODO: Remove if proven impossible after prior extrapolations:\r\n",
    "# # Fixes the last sample of the sequence if we have made extrapolations\r\n",
    "# def correct_extrapolations(df):\r\n",
    "#     df = df.copy()\r\n",
    "\r\n",
    "#     cond = (df.min_timestamp > df.max_timestamp)\r\n",
    "#     df.loc[cond, 'max_timestamp'] = df.loc[cond, 'min_timestamp']\r\n",
    "\r\n",
    "#     return df\r\n",
    "\r\n",
    "# Main function\r\n",
    "def create_sequence(df, grp_cols, agg_outcome, result_name):\r\n",
    "\r\n",
    "    aggregations_dict = {'timestamp': ['min', 'max'], 'build': ['min', 'max']}\r\n",
    "    aggregations_dict = {**aggregations_dict, **agg_outcome}\r\n",
    "\r\n",
    "    return (\r\n",
    "        df\r\n",
    "        .groupby(by=grp_cols)\r\n",
    "        .agg(aggregations_dict)\r\n",
    "        .dropna()\r\n",
    "\r\n",
    "        # Fixes column headers after complex `groupby`:\r\n",
    "        .pipe(flatten_multi_level, result_name)\r\n",
    "\r\n",
    "        .astype({'min_build': int, 'max_build': int})\r\n",
    "        .reset_index()\r\n",
    "\r\n",
    "        # Extends the length of each sequence up to the beginning of the next sequence:\r\n",
    "        .pipe(extend_sequence, agg=grp_cols[:-1]) # We have already aggregated by the last 'grp_*' ID.\r\n",
    "\r\n",
    "        # Extend the right edge of the last sample of each group to the end of the observed period\r\n",
    "        .pipe(extend_last_sample_per_group, agg=grp_cols[:-1])\r\n",
    "\r\n",
    "        # Extend the sequences from the last build of each job to have some extra width to be visible\r\n",
    "        .pipe(extend_lastest_build_per_job)\r\n",
    "\r\n",
    "        # TODO: Remove if proven impossible after prior extrapolations:\r\n",
    "        # # If we have made extrapolations, the last sample of the sequence may also need re-adjustment at its end (`max_timestamp`)\r\n",
    "        # .pipe(correct_extrapolations)\r\n",
    "\r\n",
    "        # Add column with the duration of each period\r\n",
    "        .assign(duration = lambda x: (x.max_timestamp - x.min_timestamp))\r\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Summarizes the conditions for the 3 types of sequences in different tables\r\n",
    "\r\n",
    "# Was the build successful?: If at least one in the sequence is 'FAILURE', the whole sequence is in failure\r\n",
    "agg_build_result = lambda x: 'FAILURE' if (x=='FAILURE').any() else 'SUCCESS'\r\n",
    "\r\n",
    "# Were all Robot tests successful?: If at least one in the sequence is 'FAIL', the whole sequence is failing\r\n",
    "agg_test_result = lambda x: 'FAIL' if (x=='FAIL').any() else 'PASS'\r\n",
    "\r\n",
    "# Was all the building and testing successful?: If at least one in the sequence is 'PASS', the whole sequence is passing tests\r\n",
    "agg_success_fail = lambda x: 'PASS' if (x=='PASS').any() else 'FAIL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_build_result = create_sequence(data, grp_cols=['job', 'grp_build_result'], agg_outcome={'build_result': agg_build_result}, result_name='build_result')\r\n",
    "sequence_test_result = create_sequence(data, grp_cols=['job', 'grp_test_result'], agg_outcome={'test_result': agg_test_result}, result_name='test_result')\r\n",
    "sequence_success_fail = create_sequence(data, grp_cols=['job', 'grp_success_fail'], agg_outcome={'test_result': agg_success_fail}, result_name='success_fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes, Jenkins is able to create a test report, but it is unable to complete a proper build and image upload\r\n",
    "# This function allows to discount this effect\r\n",
    "def makes_stricter(df, change_to='UNAVAILABLE'):\r\n",
    "    df = df.copy()\r\n",
    "\r\n",
    "    cond = (df.build_result=='FAILURE') & (df.test_result=='PASS')\r\n",
    "    df.loc[cond, 'test_result'] = change_to\r\n",
    "\r\n",
    "    return df\r\n",
    "\r\n",
    "sequence_test_result_strict = create_sequence(data.pipe(makes_stricter), grp_cols=['job', 'grp_test_result'], agg_outcome={'test_result': agg_test_result}, result_name='test_result')\r\n",
    "sequence_success_fail_strict = create_sequence(data.pipe(makes_stricter, 'FAIL'), grp_cols=['job', 'grp_success_fail'], agg_outcome={'test_result': agg_success_fail}, result_name='success_fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #display(data)\r\n",
    "# display(sequence_build_result.head(15))\r\n",
    "# display(sequence_test_result.head(15))\r\n",
    "# display(sequence_success_fail.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Finding sequences of pass/fails per test suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Convenient alias to allow time masks\r\n",
    "\r\n",
    "# test_suites_data = df_all_build_reports.query('(timestamp>\"2021-08-01\") & (timestamp<\"2021-08-20\")').copy().drop(columns=['source'])\r\n",
    "test_suites_data = df_all_build_reports\r\n",
    "\r\n",
    "if 'first_date' in locals():\r\n",
    "    test_suites_data = test_suites_data.query('timestamp>=@first_date')\r\n",
    "\r\n",
    "if 'last_date' in locals():\r\n",
    "    # Needs to include latest hour of the last day\r\n",
    "    last_timestamp = pd.Timestamp(last_date) + dt.timedelta(days=1)\r\n",
    "    test_suites_data = test_suites_data.query('timestamp<@last_timestamp')\r\n",
    "\r\n",
    "test_suites_data = test_suites_data.copy()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds columns with groups labels\r\n",
    "test_suites_data = (\r\n",
    "    test_suites_data\r\n",
    "    .assign(\r\n",
    "        grp_test_result = lambda x: find_sequence_number(x, relevant_col='status', mapping=mapping_test_result, grouping=['job', 'name']),\r\n",
    "        )\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_test_suites = create_sequence(test_suites_data, grp_cols=['job', 'name', 'grp_test_result'], agg_outcome={'status': agg_test_result}, result_name='test_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequence_test_suites.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If requested, it also dumps all the calculated sequences\r\n",
    "\r\n",
    "if dump_sequences:\r\n",
    "    filename = os.path.join(outputs_folder, 'sequences_dump.xlsx')\r\n",
    "    with pd.ExcelWriter(filename, engine='xlsxwriter') as writer:\r\n",
    "        sequence_build_result.to_excel(writer, index=False, sheet_name='sequence_build_result')\r\n",
    "        sequence_test_result.to_excel(writer, index=False, sheet_name='sequence_test_result')\r\n",
    "        sequence_success_fail.to_excel(writer, index=False, sheet_name='sequence_success_fail')\r\n",
    "        sequence_test_suites.to_excel(writer, index=False, sheet_name='sequence_test_suites')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Aggregated success rate per test step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_aggregated_success_rate(data_filtered, title, filename=None):\r\n",
    "\r\n",
    "    fig, ax = plt.subplots(figsize = (12,6))\r\n",
    "\r\n",
    "    t = data_filtered.timestamp\r\n",
    "    pass_pct = 100 * data_filtered.pass_pct\r\n",
    "    fail_pct = 100 * data_filtered.fail_pct\r\n",
    "    #unavailable = (data_filtered.test_result=='UNAVAILABLE')*100\r\n",
    "    unavailable = (\r\n",
    "        data_filtered.test_result.map({'UNAVAILABLE': 100})\r\n",
    "        .fillna(method='ffill', limit=1)\r\n",
    "        .fillna(method='bfill', limit=1)\r\n",
    "    )\r\n",
    "\r\n",
    "    ax.fill_between(t, fail_pct+pass_pct, pass_pct, color='red', alpha=0.5, label='Failed')\r\n",
    "    ax.fill_between(t, pass_pct, color='lime', alpha=0.5, label='Passed')\r\n",
    "    ax.fill_between(t, unavailable, color='dimgray', label='Unsuccessful builds')\r\n",
    "    ax.axhline(100, color='black', linewidth=2, linestyle='--')\r\n",
    "\r\n",
    "    ax.set_title(title, fontsize=16)\r\n",
    "    ax.legend(fontsize=12, fancybox=True, shadow=True, borderpad=1, bbox_to_anchor = (1, 1))\r\n",
    "    #ax.legend(fontsize=12, fancybox=True, shadow=True, borderpad=1, bbox_to_anchor = (0.32, 0.4))\r\n",
    "    fig.autofmt_xdate()\r\n",
    "\r\n",
    "    fig.tight_layout()\r\n",
    "\r\n",
    "    if (filename):\r\n",
    "        fig.savefig(filename + '.png', dpi=300)\r\n",
    "        fig.savefig(filename + '.svg')\r\n",
    "\r\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = ['fully_successful_builds_v10', 'fully_successful_builds_master', 'fully_successful_builds_v9']\r\n",
    "\r\n",
    "for relevant_job, job_name, file_name in zip(relevant_jobs, job_names, file_names):\r\n",
    "    display(\r\n",
    "        _ = plot_aggregated_success_rate(\r\n",
    "            data.query(\"job==@relevant_job\"),\r\n",
    "            f'{job_name} - % of successful test steps ({today})',\r\n",
    "            os.path.join(outputs_folder, file_name)\r\n",
    "        )\r\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Overall success of Jenkins builds and Robot tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_aggregated_builds_and_tests(data_filtered, state_col, title, ok_states, nok_states, filename=None):\r\n",
    "\r\n",
    "    fig, ax = plt.subplots(figsize = (12,6))\r\n",
    "\r\n",
    "    for index, row in data_filtered.iterrows():\r\n",
    "        #color = 'red' if row.build_result=='FAILURE' else 'lime'\r\n",
    "        color = 'red' if row[state_col] in nok_states else 'lime'\r\n",
    "        ax.axvspan(row.min_timestamp, row.max_timestamp, color=color, alpha=0.5)\r\n",
    "\r\n",
    "    ax.set_title(title, fontsize=16)\r\n",
    "    #ax.legend(fontsize=12, fancybox=True, shadow=True, borderpad=1, bbox_to_anchor = (1, 1))\r\n",
    "    fig.autofmt_xdate()\r\n",
    "\r\n",
    "    fig.tight_layout()\r\n",
    "\r\n",
    "    if (filename):\r\n",
    "        fig.savefig(filename + '.png', dpi=300)\r\n",
    "        fig.savefig(filename + '.svg')\r\n",
    "\r\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if extended_print:\r\n",
    "\r\n",
    "    file_names = ['successful_failed_builds_v10', 'successful_failed_builds_master', 'successful_failed_builds_v9']\r\n",
    "\r\n",
    "    for relevant_job, job_name, file_name in zip(relevant_jobs, job_names, file_names):\r\n",
    "        display(\r\n",
    "            _ = plot_aggregated_builds_and_tests(\r\n",
    "                sequence_build_result.query(\"job==@relevant_job\"),\r\n",
    "                'build_result',\r\n",
    "                f'{job_name} - Build completions and failures ({today})',\r\n",
    "                ok_states=['SUCCESS'], nok_states=['FAILURE'],\r\n",
    "                filename=os.path.join(outputs_folder, file_name)\r\n",
    "                )\r\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if extended_print:\r\n",
    "\r\n",
    "    file_names = ['global_robot_status_v10', 'global_robot_status_master', 'global_robot_status_v9']\r\n",
    "\r\n",
    "    for relevant_job, job_name, file_name in zip(relevant_jobs, job_names, file_names):\r\n",
    "        display(\r\n",
    "            _ = plot_aggregated_builds_and_tests(\r\n",
    "                sequence_test_result.query(\"job==@relevant_job\"),\r\n",
    "                'test_result',\r\n",
    "                f'{job_name} - Robot tests status ({today})',\r\n",
    "                ok_states=['PASS'], nok_states=['FAIL'],\r\n",
    "                filename=os.path.join(outputs_folder, file_name)\r\n",
    "                )\r\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if extended_print:\r\n",
    "\r\n",
    "    file_names = ['global_stability_status_v10', 'global_stability_status_master', 'global_stability_status_v9']\r\n",
    "\r\n",
    "    for relevant_job, job_name, file_name in zip(relevant_jobs, job_names, file_names):\r\n",
    "        display(\r\n",
    "            _ = plot_aggregated_builds_and_tests(\r\n",
    "                sequence_success_fail.query(\"job==@relevant_job\"),\r\n",
    "                'success_fail',\r\n",
    "                f'{job_name} - Stability for point release ({today})',\r\n",
    "                ok_states=['PASS'], nok_states=['FAIL'],\r\n",
    "                filename=os.path.join(outputs_folder, file_name)\r\n",
    "                )\r\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_aggregated_stability_sequences(sequences, state_cols, titles, ok_states, nok_states, text=None, suptitle=None, filename=None, figsize=(14,8), tight=False):\r\n",
    "\r\n",
    "    #fig, ax = plt.subplots(nrows=3, sharex=True, figsize = (14,8))\r\n",
    "    fig, ax = plt.subplots(nrows=len(sequences), sharex=True, figsize=figsize)\r\n",
    "\r\n",
    "    for i in range(len(sequences)):\r\n",
    "        for index, row in sequences[i].iterrows():\r\n",
    "            color = 'red' if row[state_cols[i]] in nok_states[i] else 'lime'\r\n",
    "            ax[i].axvspan(row.min_timestamp, row.max_timestamp, color=color, alpha=0.5)\r\n",
    "            if text:\r\n",
    "                ax[i].text(0.5, 0.5, text[i], dict(size=14),\r\n",
    "                           horizontalalignment='center', verticalalignment='center', transform=ax[i].transAxes, rasterized=False)\r\n",
    "\r\n",
    "        if not text:\r\n",
    "            ax[i].set_title(titles[i], fontsize=16)\r\n",
    "        ax[i].set_yticklabels([])\r\n",
    "        #ax[i].legend(fontsize=12, fancybox=True, shadow=True, borderpad=1, bbox_to_anchor = (1, 1))\r\n",
    "\r\n",
    "    fig.autofmt_xdate()\r\n",
    "\r\n",
    "    if tight:\r\n",
    "        fig.tight_layout()\r\n",
    "    if suptitle:\r\n",
    "        fig.suptitle(suptitle, fontsize=22)\r\n",
    "\r\n",
    "    if (filename):\r\n",
    "        fig.savefig(filename + '.png', dpi=300)\r\n",
    "        fig.savefig(filename + '.svg')\r\n",
    "\r\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = ['global_compared_stability_status_v10', 'global_compared_stability_status_master', 'global_compared_stability_status_v9']\r\n",
    "\r\n",
    "for relevant_job, job_name, file_name in zip(relevant_jobs, job_names, file_names):\r\n",
    "    display(\r\n",
    "        _ = plot_aggregated_stability_sequences(\r\n",
    "            sequences=[\r\n",
    "                sequence_build_result.query(\"job==@relevant_job\"),\r\n",
    "                #sequence_test_result.query(\"job==@relevant_job\"),\r\n",
    "                sequence_test_result_strict.query(\"job==@relevant_job\"),\r\n",
    "                #sequence_success_fail.query(\"job==@relevant_job\")\r\n",
    "                sequence_success_fail_strict.query(\"job==@relevant_job\")\r\n",
    "            ],\r\n",
    "            state_cols=['build_result', 'test_result', 'success_fail'],\r\n",
    "            titles=[\r\n",
    "                'Build completions and failures',\r\n",
    "                'Robot tests status',\r\n",
    "                'Stability for point release'\r\n",
    "            ],\r\n",
    "            suptitle=f'{job_name} - Robot tests status ({today})\\n',\r\n",
    "            ok_states=[['SUCCESS'], ['PASS'], ['PASS']],\r\n",
    "            nok_states=[['FAILURE'], ['FAIL'], ['FAIL']],\r\n",
    "            filename=os.path.join(outputs_folder, file_name)\r\n",
    "        )\r\n",
    "    )\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(sequence_build_result.query(\"job==@relevant_jobs[0]\"))\r\n",
    "# display(sequence_test_result.query(\"job==@relevant_jobs[0]\"))\r\n",
    "# display(sequence_success_fail.query(\"job==@relevant_jobs[0]\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Sequences of pass/fails per test suites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearranges the sequence as a list of sequences per 'job' x 'suite'\r\n",
    "def prepare_suite_sequences_for_plotting(df_suites):\r\n",
    "\r\n",
    "    jobs = []\r\n",
    "    suites = []\r\n",
    "    sequences = []\r\n",
    "    for name, group in df_suites.groupby(['job', 'name']):\r\n",
    "        jobs.append(name[0])\r\n",
    "        suites.append(name[1])\r\n",
    "        sequences.append(group)\r\n",
    "\r\n",
    "    return jobs, suites, sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = ['success_per_test_suite_status_v10', 'success_per_test_suite_status_master', 'success_per_test_suite_status_v9']\r\n",
    "\r\n",
    "for relevant_job, job_name, file_name in zip(relevant_jobs, job_names, file_names):\r\n",
    "\r\n",
    "    sequence_suites_filtered = sequence_test_suites.query('job==@relevant_job')\r\n",
    "    _, suites, sequences = prepare_suite_sequences_for_plotting(sequence_suites_filtered)\r\n",
    "\r\n",
    "    display(\r\n",
    "        _ = plot_aggregated_stability_sequences(\r\n",
    "            sequences=sequences,\r\n",
    "            state_cols = ['test_result'] * len(sequences),\r\n",
    "            titles = [''] * len(sequences),\r\n",
    "            text = suites,\r\n",
    "            suptitle = f'{job_name} ({today})',\r\n",
    "            ok_states = ['PASS'] * len(sequences),\r\n",
    "            nok_states = ['FAIL'] * len(sequences),\r\n",
    "            filename = os.path.join(outputs_folder, file_name),\r\n",
    "            figsize = (18,16),\r\n",
    "            tight = False\r\n",
    "        )\r\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Failing days per test suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_days_suites_ok_nok(suites, days_failing, days_passing, title, filename=None):\r\n",
    "\r\n",
    "    fig, ax = plt.subplots(figsize = (12,16))\r\n",
    "\r\n",
    "    plt.barh(suites, days_failing, color='red', alpha=0.5, label='Failing')\r\n",
    "    plt.barh(suites, days_passing, color='lime', alpha=0.5, left=days_failing, label='Passing')\r\n",
    "\r\n",
    "    #ax.set_title(title, fontsize=20)\r\n",
    "    fig.suptitle(title, fontsize=20)\r\n",
    "    ax.set_xlabel('Number of days')\r\n",
    "    #ax.legend(fontsize=12, fancybox=True, shadow=True, borderpad=1, bbox_to_anchor = (1, 1))\r\n",
    "\r\n",
    "    fig.tight_layout()\r\n",
    "\r\n",
    "    if (filename):\r\n",
    "        fig.savefig(filename + '.png', dpi=300)\r\n",
    "        fig.savefig(filename + '.svg')\r\n",
    "\r\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_to_days(df):\r\n",
    "    df = df.copy()\r\n",
    "\r\n",
    "    df['FAIL'] = pd.to_timedelta(df.FAIL) / pd.Timedelta(days=1)\r\n",
    "    df['PASS'] = pd.to_timedelta(df.PASS) / pd.Timedelta(days=1)\r\n",
    "\r\n",
    "    # # Round to whole days\r\n",
    "    # df['FAIL'] = df.FAIL.round(0).astype(int)\r\n",
    "    # df['PASS'] = df.PASS.round(0).astype(int)\r\n",
    "\r\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = ['failing_days_per_suite_v10', 'failing_days_per_suite_master', 'failing_days_per_suite_v9']\r\n",
    "\r\n",
    "for relevant_job, job_name, file_name in zip(relevant_jobs, job_names, file_names):\r\n",
    "\r\n",
    "    sequence_suites_filtered = sequence_test_suites.query('job==@relevant_job')\r\n",
    "\r\n",
    "    fail_pass_durations_per_suite = (\r\n",
    "        sequence_suites_filtered\r\n",
    "        .pivot_table(\r\n",
    "            index = 'name',\r\n",
    "            columns = 'test_result',\r\n",
    "            values = 'duration',\r\n",
    "            aggfunc = 'sum'\r\n",
    "        )\r\n",
    "        .fillna(0)\r\n",
    "        .reset_index()\r\n",
    "        .sort_values(['FAIL', 'PASS'])\r\n",
    "        .pipe(round_to_days)\r\n",
    "    )\r\n",
    "\r\n",
    "    display(\r\n",
    "        _ = plot_days_suites_ok_nok(\r\n",
    "            suites=fail_pass_durations_per_suite.name,\r\n",
    "            days_failing=fail_pass_durations_per_suite.FAIL,\r\n",
    "            days_passing=fail_pass_durations_per_suite.PASS,\r\n",
    "            title=f'{job_name} - Failing days per test suite ({today})',\r\n",
    "            filename=os.path.join(outputs_folder, file_name)\r\n",
    "        )\r\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Information about the latest builds of relevant jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to use external notebook\r\n",
    "#%run 001-analysis_latest_build.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_latest_builds_all_jobs(engine, too_old_builds='1980-12-15'):\r\n",
    "\t'''\r\n",
    "\tFrom each of the known jobs, retrieves their latest build.\r\n",
    "\tReturns a dataframe with a row per job.\r\n",
    "\r\n",
    "\tUsage:\r\n",
    "\r\n",
    "\tload_latest_builds(engine, too_old_builds='1980-12-15')\r\n",
    "\r\n",
    "\t- `engine`: Database engine to use for the connection.\r\n",
    "\t- `too_old_builds`: Limits the query to builds not older than a date. By default, it does not limit in practice (1980!).\r\n",
    "\t'''\r\n",
    "\r\n",
    "\ttable_known_builds = 'builds_info'\r\n",
    "\r\n",
    "\tquery_latest_builds = f'''\r\n",
    "\tSELECT main.*\r\n",
    "\tFROM {table_known_builds} AS main\r\n",
    "\tINNER JOIN (\r\n",
    "\t\tSELECT job, MAX(timestamp) as ts\r\n",
    "\t\tFROM {table_known_builds}\r\n",
    "\t\tWHERE timestamp>DATETIME(\"{too_old_builds}\")\r\n",
    "\t\tGROUP BY job\r\n",
    "\t) AS latest_build\r\n",
    "\tON main.job=latest_build.job AND main.timestamp=ts\r\n",
    "\t'''\r\n",
    "\r\n",
    "\twith engine.begin() as conn:\r\n",
    "\t\tdf_latest_builds = pd.read_sql(query_latest_builds, con=conn)\r\n",
    "\r\n",
    "\tdf_latest_builds['timestamp'] = pd.to_datetime(df_latest_builds.timestamp)\r\n",
    "\r\n",
    "\treturn df_latest_builds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_latest_report_all_jobs(engine, too_old_builds='1980-12-15'):\r\n",
    "\t'''\r\n",
    "\tFrom each of the known jobs, retrieves the report from their latest build.\r\n",
    "\tReturns a dataframe with a row per suite per job (in case the latest build of the job generated a report).\r\n",
    "\r\n",
    "\tUsage:\r\n",
    "\r\n",
    "\tload_latest_report_all_jobs(engine, too_old_builds='1980-12-15')\r\n",
    "\r\n",
    "\t- `engine`: Database engine to use for the connection.\r\n",
    "\t- `too_old_builds`: Limits the query to builds not older than a date. By default, it does not limit in practice (1980!).\r\n",
    "\r\n",
    "\t'''\r\n",
    "\ttable =  'robot_reports'\r\n",
    "\ttable_known_builds = 'builds_info'\r\n",
    "\r\n",
    "\tquery_robot_reports = f'''\r\n",
    "\tSELECT details.*\r\n",
    "\tFROM {table} AS details\r\n",
    "\tINNER JOIN {table_known_builds} AS main\r\n",
    "\tON details.job=main.job AND details.build=main.build\r\n",
    "\tINNER JOIN (\r\n",
    "\t\tSELECT job, MAX(timestamp) as ts\r\n",
    "\t\tFROM {table_known_builds}\r\n",
    "\t\tWHERE timestamp>DATETIME(\"{too_old_builds}\")\r\n",
    "\t\tGROUP BY job\r\n",
    "\t) AS latest_build\r\n",
    "\tON main.job=latest_build.job AND main.timestamp=ts\r\n",
    "\t'''\r\n",
    "\r\n",
    "\twith engine.begin() as conn:\r\n",
    "\t\tdf_robot_reports = pd.read_sql(query_robot_reports, con=conn)\r\n",
    "\r\n",
    "\tdf_robot_reports['starttime'] = pd.to_datetime(df_robot_reports.starttime)\r\n",
    "\tdf_robot_reports['endtime'] = pd.to_datetime(df_robot_reports.endtime)\r\n",
    "\r\n",
    "\treturn df_robot_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_latest_extended_report_all_jobs(engine, too_old_builds='1980-12-15'):\r\n",
    "\t'''\r\n",
    "\tFrom each of the known jobs, retrieves the extended report from their latest build.\r\n",
    "\tReturns a dataframe with a row per test per suite per job (in case the latest build of the job generated a report).\r\n",
    "\r\n",
    "\tUsage:\r\n",
    "\r\n",
    "\tload_latest_extendend_report_all_jobs(engine, too_old_builds='1980-12-15')\r\n",
    "\r\n",
    "\t- `engine`: Database engine to use for the connection.\r\n",
    "\t- `too_old_builds`: Limits the query to builds not older than a date. By default, it does not limit in practice (1980!).\r\n",
    "\t'''\r\n",
    "\r\n",
    "\ttable = 'robot_reports_extended'\r\n",
    "\ttable_known_builds = 'builds_info'\r\n",
    "\r\n",
    "\tquery_robot_reports = f'''\r\n",
    "\tSELECT details.*\r\n",
    "\tFROM {table} AS details\r\n",
    "\tINNER JOIN {table_known_builds} AS main\r\n",
    "\tON details.job=main.job AND details.build=main.build\r\n",
    "\tINNER JOIN (\r\n",
    "\t\tSELECT job, MAX(timestamp) as ts\r\n",
    "\t\tFROM {table_known_builds}\r\n",
    "\t\tWHERE timestamp>DATETIME(\"{too_old_builds}\")\r\n",
    "\t\tGROUP BY job\r\n",
    "\t) AS latest_build\r\n",
    "\tON main.job=latest_build.job AND main.timestamp=ts\r\n",
    "\t'''\r\n",
    "\r\n",
    "\twith engine.begin() as conn:\r\n",
    "\t\tdf_robot_reports_extended = pd.read_sql(query_robot_reports, con=conn)\r\n",
    "\r\n",
    "\tdf_robot_reports_extended['starttime'] = pd.to_datetime(df_robot_reports_extended.starttime)\r\n",
    "\tdf_robot_reports_extended['endtime'] = pd.to_datetime(df_robot_reports_extended.endtime)\r\n",
    "\r\n",
    "\treturn df_robot_reports_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "engine = create_engine(database_uri)\r\n",
    "\r\n",
    "df_latest_builds_all_jobs = load_latest_builds_all_jobs(engine, too_old_builds=too_old_builds)\r\n",
    "df_latest_report_all_jobs = load_latest_report_all_jobs(engine, too_old_builds=too_old_builds)\r\n",
    "df_latest_extended_report_all_jobs = load_latest_extended_report_all_jobs(engine, too_old_builds=too_old_builds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latest build of each job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_latest_builds_all_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for job_name, build in zip(df_latest_builds_all_jobs.job, df_latest_builds_all_jobs.build):\r\n",
    "    stage, branch = job_name.split('/')\r\n",
    "    link = f'https://osm.etsi.org/jenkins/view/Robot%20tests/job/{stage}/job/{branch}/{build}/'\r\n",
    "    display(Markdown(f'[Click to see the details of **build {build} of {job_name}**]({link})'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Failed test suites per job (if any):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_failed = (\r\n",
    "    df_latest_report_all_jobs\r\n",
    "    .query(\"status=='FAIL'\")\r\n",
    ")\r\n",
    "\r\n",
    "for job_name in relevant_jobs:\r\n",
    "    stage, branch = job_name.split('/')\r\n",
    "    link = f'https://osm.etsi.org/jenkins/view/Robot%20tests/job/{stage}/job/{branch}/{build}/robot/report/report.html'\r\n",
    "    display(\r\n",
    "        Markdown(f'**{job_name}:** ([full report]({link}))')\r\n",
    "    )\r\n",
    "    display(\r\n",
    "        df_failed\r\n",
    "        .query('job==@job_name')\r\n",
    "        .drop(columns=['build', 'source', 'job', 'id', 'failed_test_id'])\r\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Details of failed tests into failing test suites (if any):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_details_failed = (\r\n",
    "    df_latest_extended_report_all_jobs\r\n",
    "    .merge(\r\n",
    "        df_failed[['job', 'build', 'name']],\r\n",
    "        how='inner',\r\n",
    "        left_on=['job', 'build', 'suite_name'],\r\n",
    "        right_on=['job', 'build', 'name']\r\n",
    "        )\r\n",
    "    .drop(columns=['suite_id', 'test_id', 'name'])\r\n",
    "    .query('status==\"FAIL\"')\r\n",
    ")\r\n",
    "\r\n",
    "for job_name in relevant_jobs:\r\n",
    "    #display(job_name)\r\n",
    "    stage, branch = job_name.split('/')\r\n",
    "    link = f'https://osm.etsi.org/jenkins/view/Robot%20tests/job/{stage}/job/{branch}/{build}/robot/report/report.html'\r\n",
    "    display(\r\n",
    "        Markdown(f'**{job_name}:** ([full report]({link}))')\r\n",
    "    )\r\n",
    "    display(\r\n",
    "        df_details_failed\r\n",
    "        .query('job==@job_name')\r\n",
    "        .drop(columns=['job', 'build'])\r\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to html --output report_outputs/analysis_of_test_results.html --TemplateExporter.exclude_input=True 01-analysis_of_test_results.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\r\n",
    "\r\n",
    "---\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANNEX: Samples of density plots (for future use)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sequence_build_filtered = sequence_build_result[sequence_build_result.job=='osm-stage_3-merge/v9.0']\r\n",
    "#sequence_build_filtered.iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_density_builds_and_tests(data, title, labels, filename=None):\r\n",
    "\r\n",
    "    fig, ax = plt.subplots(figsize = (12,6))\r\n",
    "\r\n",
    "    n_bins = 25\r\n",
    "    colors = ['green', 'red']\r\n",
    "    #labels = ['OK', 'NOK']\r\n",
    "\r\n",
    "    #ax.hist(data, n_bins, density=True, histtype='bar', color=colors, label=labels)\r\n",
    "    #ax.hist(data, n_bins, density=True, histtype='bar', rwidth=0.8, label=labels, color=colors)\r\n",
    "    ax.hist(data, n_bins, density=True, histtype='bar', rwidth=0.8, label=labels, color=colors, alpha=0.5)\r\n",
    "\r\n",
    "    #ax.set_title(title, fontsize=20)\r\n",
    "    fig.suptitle(title, fontsize=20)\r\n",
    "    ax.set_xlabel('Duration of sequences (days)')\r\n",
    "    ax.set_ylabel('Density')\r\n",
    "    ax.legend(fontsize=12, fancybox=True, shadow=True, borderpad=1, bbox_to_anchor = (1, 1))\r\n",
    "\r\n",
    "    fig.tight_layout()\r\n",
    "\r\n",
    "    if (filename):\r\n",
    "        fig.savefig(filename + '.png', dpi=300)\r\n",
    "        fig.savefig(filename + '.svg')\r\n",
    "\r\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "build_durations_filtered = sequence_build_filtered.copy()\r\n",
    "build_durations_filtered['duration'] = build_durations_filtered.max_timestamp - build_durations_filtered.min_timestamp\r\n",
    "#build_durations_filtered['duration'] = build_durations_filtered['duration'] / pd.to_timedelta(1, unit='D') # Expressed in days, allowing decimals\r\n",
    "build_durations_filtered['duration'] = build_durations_filtered['duration'].dt.days\r\n",
    "\r\n",
    "build_durations_filtered.drop(columns=['grp_build_result', 'min_timestamp', 'max_timestamp', 'min_build', 'max_build'], inplace=True)\r\n",
    "\r\n",
    "builds_ok = build_durations_filtered.loc[build_durations_filtered.build_result=='SUCCESS', 'duration']\r\n",
    "builds_nok = build_durations_filtered.loc[build_durations_filtered.build_result=='FAILURE', 'duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# plot_density_builds_and_tests(data=[builds_ok, builds_nok],\r\n",
    "#                               title='Rel NINE branch - Histogram of durations of build states (failure/success) ('+ today + ')',\r\n",
    "#                               labels=['SUCCESS', 'FAILURE'],\r\n",
    "#                               filename=os.path.join(outputs_folder, 'density_build_success_failure_v9'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_kde_builds_and_tests(data, x, hue, colors, title, filename=None):\r\n",
    "\r\n",
    "    fig, ax = plt.subplots(figsize = (12,6))\r\n",
    "\r\n",
    "    sns.kdeplot(data=data,\r\n",
    "                x=x, hue=hue,\r\n",
    "                cut=0, bw_adjust=0.2,\r\n",
    "                palette=colors, fill=True, alpha=0.4,\r\n",
    "                ax=ax)\r\n",
    "\r\n",
    "    fig.suptitle(title, fontsize=20)\r\n",
    "    ax.set_xlabel('Duration of sequences (days)')\r\n",
    "\r\n",
    "    if filename:\r\n",
    "        fig.savefig(filename + '.png', dpi=300)\r\n",
    "        fig.savefig(filename + '.svg')\r\n",
    "\r\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# plot_kde_builds_and_tests(data=build_durations_filtered,\r\n",
    "#                           x='duration', hue='build_result', colors=['red', 'green'],\r\n",
    "#                           title='Rel NINE branch - KDE of durations of build states (failure/success) ('+ today + ')',\r\n",
    "#                           filename=os.path.join(outputs_folder, 'kde_build_success_failure_v9'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "436f2814f1f12011c00cf6933038a969dd0edc275127d459a28a14c2140dfae0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('osm-analytics': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
